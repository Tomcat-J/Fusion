/home/backup/lh/anaconda3/bin/python3 /home/backup/lh/KD/mae_lite/tools/train.py 
2026-01-29 14:34:56.166 | INFO     | __main__:main_worker:227 - gpuid: 0, args: <>Namespace(dist_backend='nccl', dist_url=None, batch_size=32, max_epoch=100, devices='1', eval=True, exp_file='/home/backup/lh/KD/projects/eval_tools/finetuning_progressive_v4_exp.py', ckpt='/home/backup/lh/KD/outputs/HiFuse_Small_1e-5-0.05/ft_progressive_v3_eval/88.4last_epoch_best_ckpt.checkpoints.tar', amp=False, exp_options=None, world_size=1)
/home/backup/lh/KD/mae_lite/tools/train.py:228: DeprecationWarning: The 'ansi' parameter is deprecated, please use 'colors' instead
  logger.opt(ansi=True).info(
2026-01-29 14:34:56.170 | INFO     | __main__:main_worker:228 - Used experiment configs:
======================  =========================================================================================================
config key              value
======================  =========================================================================================================
batch_size              32
max_epoch               100
seed                    0
data_format             image
clip_grad               1.0
clip_mode               norm
output_dir              /home/backup/lh/KD/outputs
print_interval          10
dump_interval           5
eval_interval           1
enable_tensorboard      True
dataset                 MyDataSet
transform               typical_imagenet_transform
image_size              224
encoder_arch            HiFuse_Small
pretrained              False
num_classes             3
global_pool             True
img_size                224
input_size              <class 'NoneType'>
crop_pct                <class 'NoneType'>
mean                    <class 'NoneType'>
std                     <class 'NoneType'>
interpolation
validation_batch_size   <class 'NoneType'>
validation_dataset      MyDataSet
test_dataset            MyDataSet
test_batch_size         <class 'NoneType'>
opt                     adamw
opt_eps                 1e-08
opt_betas               (0.9, 0.999)
momentum                0.9
weight_decay            0.05
sched                   warmcos
basic_lr_per_img        3.125e-06
lr_noise                <class 'NoneType'>
lr_noise_pct            0.67
lr_noise_std            1.0
lr_cycle_mul            1.0
lr_cycle_decay          0.5
lr_cycle_limit          1
lr_k_decay              1.0
warmup_lr_per_img       3.125e-06
min_lr_per_img          3.125e-07
epochs                  100
epoch_repeats           0
start_epoch             <class 'NoneType'>
decay_epochs            <class 'NoneType'>
warmup_epochs           5
cooldown_epochs         10
patience_epochs         10
decay_rate              0.1
no_aug                  False
scale                   (0.08, 1.0)
ratio                   (0.75, 1.3333333333333333)
hflip                   0.5
vflip                   0.0
color_jitter            0.4
aa                      rand-m9-mstd0.5-inc1
reprob                  0.25
remode                  pixel
recount                 1
resplit                 False
mixup                   0.1
cutmix                  0.1
cutmix_minmax           <class 'NoneType'>
mixup_prob              0.5
mixup_switch_prob       0.5
mixup_mode              batch
mixup_off_epoch         0
smoothing               0.1
train_interpolation     bicubic
drop                    0.0
drop_connect            <class 'NoneType'>
drop_path               0.15
drop_block              <class 'NoneType'>
bn_tf                   False
bn_momentum             <class 'NoneType'>
bn_eps                  <class 'NoneType'>
sync_bn                 False
dist_bn                 reduce
model_ema               True
model_ema_force_cpu     False
model_ema_decay         0.9998
num_workers             10
weights_prefix
layer_decay             1.0
warmup_lr               1e-06
min_lr                  5e-07
attn_drop_rate          0.0
pretrain_exp_name       HiFuse_Small_1e-5-0.05
save_folder_prefix      ft_progressive_v4_1
use_enhanced_model      True
enhancement_reduction   0.0625
backbone_lr_scale       0.05
mhf_lr_scale            0.2
enhancement_lr_scale    3.0
head_lr_scale           2.0
freeze_backbone_epochs  3
push_start_epoch        999
push_interval           999
push_end_epoch          0
push_momentum           0.0
stage1_ckpt_path        <class 'NoneType'>
loss_weights            {'clst_scale': 0.8, 'sep_scale': 0.25, 'orth_scale': 0.02, 'local_consistency_scale': 0.1, 'margin': 0.5}
======================  =========================================================================================================
/home/backup/lh/KD/mae_lite/tools/train.py:235: DeprecationWarning: The 'ansi' parameter is deprecated, please use 'colors' instead
  logger.opt(ansi=True).info("<yellow>Environment info:</yellow>\n<blue>{}</blue>".format(collect_env_info()))
/home/backup/lh/KD/mae_lite/utils/env.py:48: UserWarning: Current path is possibly not a valid git repository.
  warnings.warn("Current path is possibly not a valid git repository.")
2026-01-29 14:34:56.695 | INFO     | __main__:main_worker:235 - Environment info:
----------------------  --------------------------------------------------------------------------
sys.platform            linux
Python                  3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
numpy                   1.24.3
Pillow                  9.4.0
PyTorch                 2.1.0 @/home/backup/lh/anaconda3/lib/python3.11/site-packages/torch
PyTorch debug build     False
CUDA available          True
GPU 0                   NVIDIA GeForce RTX 3090
CUDA_HOME               /usr
NVCC                    Build cuda_12.0.r12.0/compiler.32267302_0
torchvision             0.16.0 @/home/backup/lh/anaconda3/lib/python3.11/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75, sm_80, sm_86
cv2                     4.8.1
----------------------  --------------------------------------------------------------------------
Git status: unknown
----------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

2026-01-29 14:34:57.294164: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-01-29 14:34:58.209447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
220 images were found in the dataset.
1753 images for training.
468 images for validation.
2026-01-29 14:35:00.911 | INFO     | projects.eval_tools.finetuning_mae_exp:get_model:120 - Using enhanced model: HiFuse_Small_Enhanced (reduction=0.0625)
[main_model_enhanced] MHF Enhancement: Enabled (reduction=0.0625)
2026-01-29 14:35:01.066 | INFO     | finetuning_progressive_v4_exp:get_model:108 - [Exp v4] Loss weights adjusted:
2026-01-29 14:35:01.067 | INFO     | finetuning_progressive_v4_exp:get_model:109 -   sep_scale: 0.12 -> 0.25
2026-01-29 14:35:01.067 | INFO     | finetuning_progressive_v4_exp:get_model:110 -   orth_scale: 0.08 -> 0.02
2026-01-29 14:35:01.067 | INFO     | finetuning_progressive_v4_exp:get_model:111 -   local_consistency_scale: 0.05 -> 0.1
2026-01-29 14:35:01.067 | INFO     | finetuning_progressive_v4_exp:get_model:112 -   margin: 0.3 -> 0.5
2026-01-29 14:35:01.070 | INFO     | finetuning_progressive_v4_exp:get_model:108 - [Exp v4] Loss weights adjusted:
2026-01-29 14:35:01.070 | INFO     | finetuning_progressive_v4_exp:get_model:109 -   sep_scale: 0.12 -> 0.25
2026-01-29 14:35:01.070 | INFO     | finetuning_progressive_v4_exp:get_model:110 -   orth_scale: 0.08 -> 0.02
2026-01-29 14:35:01.071 | INFO     | finetuning_progressive_v4_exp:get_model:111 -   local_consistency_scale: 0.05 -> 0.1
2026-01-29 14:35:01.071 | INFO     | finetuning_progressive_v4_exp:get_model:112 -   margin: 0.3 -> 0.5
2026-01-29 14:35:01.078 | INFO     | __main__:main_worker:262 - Illustration of model strcutures:
Model(
  (model): main_model_enhanced(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (conv_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0, inplace=False)
    (meta_tokenlize): PatchEmbed(
      (proj): Conv2d(96, 768, kernel_size=(16, 16), stride=(16, 16))
      (norm): Identity()
    )
    (layers1): BasicLayer(
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0, inplace=False)
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop2): Dropout(p=0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0, inplace=False)
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop2): Dropout(p=0, inplace=False)
          )
        )
      )
    )
    (layers2): BasicLayer(
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0, inplace=False)
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop2): Dropout(p=0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (reduction): Linear(in_features=384, out_features=192, bias=False)
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layers3): BasicLayer(
      (blocks): ModuleList(
        (0-5): 6 x SwinTransformerBlock(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0, inplace=False)
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop2): Dropout(p=0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (reduction): Linear(in_features=768, out_features=384, bias=False)
        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layers4): BasicLayer(
      (blocks): ModuleList(
        (0-1): 2 x SwinTransformerBlock(
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0, inplace=False)
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop2): Dropout(p=0, inplace=False)
          )
        )
      )
      (downsample): PatchMerging(
        (reduction): Linear(in_features=1536, out_features=768, bias=False)
        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
      )
    )
    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (avgpool): AdaptiveAvgPool1d(output_size=1)
    (head): HeadOptimal(
      (proj): Sequential(
        (0): Linear(in_features=768, out_features=768, bias=True)
        (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (2): Dropout(p=0.1, inplace=False)
      )
      (proto_manager): DynamicPrototypeManagerOptimal()
      (mixed_attn): MixedAttentionBlockOptimal(
        (cross_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (light_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
        )
        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (gate): Sequential(
          (0): Linear(in_features=2304, out_features=768, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=768, out_features=3, bias=True)
        )
      )
      (ffn): Sequential(
        (0): Linear(in_features=768, out_features=3072, bias=True)
        (1): GELU(approximate='none')
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=3072, out_features=768, bias=True)
        (4): Dropout(p=0.1, inplace=False)
      )
      (ffn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (proto_loss_fn): OptimalPrototypeLoss()
    )
    (fu1): MHF_block_v2(
      (att_conv): Sequential(
        (0): Conv2d(192, 2, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
      (maxpool): AdaptiveMaxPool2d(output_size=1)
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (se): Sequential(
        (0): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): ReLU()
        (2): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (sigmoid): Sigmoid()
      (spatial): Conv(
        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_x): Conv(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_g): Conv(
        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (chan): Conv(
        (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W): Conv(
        (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (gelu): GELU(approximate='none')
      (residual): Residual(
        (relu): ReLU(inplace=True)
        (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1): Conv(
          (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv(
          (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv(
          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip_layer): Conv(
          (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (dropout): Dropout2d(p=0.0, inplace=False)
      (enhancement): EnhancementModuleLite(
        (channel_att): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): ReLU(inplace=True)
          (3): Conv2d(8, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): Sigmoid()
        )
        (spatial_att): Sequential(
          (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): Sigmoid()
        )
      )
    )
    (fu2): MHF_block_v2(
      (att_conv): Sequential(
        (0): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
      (maxpool): AdaptiveMaxPool2d(output_size=1)
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (se): Sequential(
        (0): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): ReLU()
        (2): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (sigmoid): Sigmoid()
      (spatial): Conv(
        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_x): Conv(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_g): Conv(
        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (chan): Conv(
        (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W): Conv(
        (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (gelu): GELU(approximate='none')
      (residual): Residual(
        (relu): ReLU(inplace=True)
        (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1): Conv(
          (conv): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv(
          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv(
          (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip_layer): Conv(
          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (dropout): Dropout2d(p=0.1, inplace=False)
      (enhancement): EnhancementModuleLite(
        (channel_att): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): ReLU(inplace=True)
          (3): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): Sigmoid()
        )
        (spatial_att): Sequential(
          (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): Sigmoid()
        )
      )
    )
    (fu3): MHF_block_v2(
      (att_conv): Sequential(
        (0): Conv2d(768, 2, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
      (maxpool): AdaptiveMaxPool2d(output_size=1)
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (se): Sequential(
        (0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): ReLU()
        (2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (sigmoid): Sigmoid()
      (spatial): Conv(
        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_x): Conv(
        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_g): Conv(
        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (chan): Conv(
        (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W): Conv(
        (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (gelu): GELU(approximate='none')
      (residual): Residual(
        (relu): ReLU(inplace=True)
        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1): Conv(
          (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv(
          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv(
          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip_layer): Conv(
          (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (dropout): Dropout2d(p=0.2, inplace=False)
      (enhancement): EnhancementModuleLite(
        (channel_att): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): ReLU(inplace=True)
          (3): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): Sigmoid()
        )
        (spatial_att): Sequential(
          (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): Sigmoid()
        )
      )
    )
    (fu4): MHF_block_v2(
      (att_conv): Sequential(
        (0): Conv2d(1536, 2, kernel_size=(1, 1), stride=(1, 1))
        (1): Sigmoid()
      )
      (maxpool): AdaptiveMaxPool2d(output_size=1)
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (se): Sequential(
        (0): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): ReLU()
        (2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (sigmoid): Sigmoid()
      (spatial): Conv(
        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_x): Conv(
        (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W_g): Conv(
        (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (norm1): LayerNorm()
      (norm2): LayerNorm()
      (chan): Conv(
        (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (W): Conv(
        (conv): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (relu): ReLU(inplace=True)
        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (gelu): GELU(approximate='none')
      (residual): Residual(
        (relu): ReLU(inplace=True)
        (bn1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv1): Conv(
          (conv): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1))
        )
        (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv(
          (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv(
          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
        )
        (skip_layer): Conv(
          (conv): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (dropout): Dropout2d(p=0.2, inplace=False)
      (enhancement): EnhancementModuleLite(
        (channel_att): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (2): ReLU(inplace=True)
          (3): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (4): Sigmoid()
        )
        (spatial_att): Sequential(
          (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): Sigmoid()
        )
      )
    )
  )
  (train_loss_fn): SoftTargetCrossEntropy()
  (ema_model): ModelEmaV2(
    (module): main_model_enhanced(
      (downsample_layers): ModuleList(
        (0): Sequential(
          (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (1): LayerNorm()
        )
        (1): Sequential(
          (0): LayerNorm()
          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
        )
        (2): Sequential(
          (0): LayerNorm()
          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
        )
        (3): Sequential(
          (0): LayerNorm()
          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
        )
      )
      (stages): ModuleList(
        (0): Sequential(
          (0): Block(
            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=384, out_features=96, bias=True)
            (drop_path): Identity()
          )
          (1): Block(
            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=384, out_features=96, bias=True)
            (drop_path): Identity()
          )
          (2): Block(
            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=384, out_features=96, bias=True)
            (drop_path): Identity()
          )
        )
        (1): Sequential(
          (0): Block(
            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=768, out_features=192, bias=True)
            (drop_path): Identity()
          )
          (1): Block(
            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=768, out_features=192, bias=True)
            (drop_path): Identity()
          )
          (2): Block(
            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=768, out_features=192, bias=True)
            (drop_path): Identity()
          )
        )
        (2): Sequential(
          (0): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (1): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (2): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (3): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (4): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (5): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (6): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (7): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
          (8): Block(
            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
            (drop_path): Identity()
          )
        )
        (3): Sequential(
          (0): Block(
            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
            (drop_path): Identity()
          )
          (1): Block(
            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
            (drop_path): Identity()
          )
          (2): Block(
            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
            (norm): LayerNorm()
            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
            (drop_path): Identity()
          )
        )
      )
      (conv_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0, inplace=False)
      (meta_tokenlize): PatchEmbed(
        (proj): Conv2d(96, 768, kernel_size=(16, 16), stride=(16, 16))
        (norm): Identity()
      )
      (layers1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0, inplace=False)
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop2): Dropout(p=0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0, inplace=False)
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop2): Dropout(p=0, inplace=False)
            )
          )
        )
      )
      (layers2): BasicLayer(
        (blocks): ModuleList(
          (0-1): 2 x SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0, inplace=False)
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop2): Dropout(p=0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layers3): BasicLayer(
        (blocks): ModuleList(
          (0-5): 6 x SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0, inplace=False)
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop2): Dropout(p=0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (layers4): BasicLayer(
        (blocks): ModuleList(
          (0-1): 2 x SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (drop1): Dropout(p=0, inplace=False)
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop2): Dropout(p=0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (avgpool): AdaptiveAvgPool1d(output_size=1)
      (head): HeadOptimal(
        (proj): Sequential(
          (0): Linear(in_features=768, out_features=768, bias=True)
          (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (proto_manager): DynamicPrototypeManagerOptimal()
        (mixed_attn): MixedAttentionBlockOptimal(
          (cross_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (light_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (gate): Sequential(
            (0): Linear(in_features=2304, out_features=768, bias=True)
            (1): GELU(approximate='none')
            (2): Linear(in_features=768, out_features=3, bias=True)
          )
        )
        (ffn): Sequential(
          (0): Linear(in_features=768, out_features=3072, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=3072, out_features=768, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
        (ffn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (proto_loss_fn): OptimalPrototypeLoss()
      )
      (fu1): MHF_block_v2(
        (att_conv): Sequential(
          (0): Conv2d(192, 2, kernel_size=(1, 1), stride=(1, 1))
          (1): Sigmoid()
        )
        (maxpool): AdaptiveMaxPool2d(output_size=1)
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (se): Sequential(
          (0): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
        (spatial): Conv(
          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_x): Conv(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_g): Conv(
          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (norm1): LayerNorm()
        (norm2): LayerNorm()
        (chan): Conv(
          (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W): Conv(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (gelu): GELU(approximate='none')
        (residual): Residual(
          (relu): ReLU(inplace=True)
          (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv1): Conv(
            (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1))
          )
          (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv(
            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv(
            (conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))
          )
          (skip_layer): Conv(
            (conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (dropout): Dropout2d(p=0.0, inplace=False)
        (enhancement): EnhancementModuleLite(
          (channel_att): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(8, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): Sigmoid()
          )
          (spatial_att): Sequential(
            (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): Sigmoid()
          )
        )
      )
      (fu2): MHF_block_v2(
        (att_conv): Sequential(
          (0): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
          (1): Sigmoid()
        )
        (maxpool): AdaptiveMaxPool2d(output_size=1)
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (se): Sequential(
          (0): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
        (spatial): Conv(
          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_x): Conv(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_g): Conv(
          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (norm1): LayerNorm()
        (norm2): LayerNorm()
        (chan): Conv(
          (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W): Conv(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (gelu): GELU(approximate='none')
        (residual): Residual(
          (relu): ReLU(inplace=True)
          (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv1): Conv(
            (conv): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))
          )
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv(
            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv(
            (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))
          )
          (skip_layer): Conv(
            (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (dropout): Dropout2d(p=0.1, inplace=False)
        (enhancement): EnhancementModuleLite(
          (channel_att): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): Sigmoid()
          )
          (spatial_att): Sequential(
            (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): Sigmoid()
          )
        )
      )
      (fu3): MHF_block_v2(
        (att_conv): Sequential(
          (0): Conv2d(768, 2, kernel_size=(1, 1), stride=(1, 1))
          (1): Sigmoid()
        )
        (maxpool): AdaptiveMaxPool2d(output_size=1)
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (se): Sequential(
          (0): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
        (spatial): Conv(
          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_x): Conv(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_g): Conv(
          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (norm1): LayerNorm()
        (norm2): LayerNorm()
        (chan): Conv(
          (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W): Conv(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (gelu): GELU(approximate='none')
        (residual): Residual(
          (relu): ReLU(inplace=True)
          (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv1): Conv(
            (conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1))
          )
          (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv(
            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv(
            (conv): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))
          )
          (skip_layer): Conv(
            (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (dropout): Dropout2d(p=0.2, inplace=False)
        (enhancement): EnhancementModuleLite(
          (channel_att): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): Sigmoid()
          )
          (spatial_att): Sequential(
            (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): Sigmoid()
          )
        )
      )
      (fu4): MHF_block_v2(
        (att_conv): Sequential(
          (0): Conv2d(1536, 2, kernel_size=(1, 1), stride=(1, 1))
          (1): Sigmoid()
        )
        (maxpool): AdaptiveMaxPool2d(output_size=1)
        (avgpool): AdaptiveAvgPool2d(output_size=1)
        (se): Sequential(
          (0): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): ReLU()
          (2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
        (spatial): Conv(
          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_x): Conv(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W_g): Conv(
          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))
          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (Avg): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (norm1): LayerNorm()
        (norm2): LayerNorm()
        (chan): Conv(
          (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (W): Conv(
          (conv): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (relu): ReLU(inplace=True)
          (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (gelu): GELU(approximate='none')
        (residual): Residual(
          (relu): ReLU(inplace=True)
          (bn1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv1): Conv(
            (conv): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1))
          )
          (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv(
            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv(
            (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))
          )
          (skip_layer): Conv(
            (conv): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (dropout): Dropout2d(p=0.2, inplace=False)
        (enhancement): EnhancementModuleLite(
          (channel_att): Sequential(
            (0): AdaptiveAvgPool2d(output_size=1)
            (1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (2): ReLU(inplace=True)
            (3): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (4): Sigmoid()
          )
          (spatial_att): Sequential(
            (0): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): Sigmoid()
          )
        )
      )
    )
  )
)
2026-01-29 14:35:01.080 | INFO     | projects.eval_tools.finetuning_mae_exp:get_optimizer:150 - Using differential learning rates:
2026-01-29 14:35:01.080 | INFO     | projects.eval_tools.finetuning_mae_exp:get_optimizer:151 -   backbone: 0.05x, mhf: 0.2x, enhancement: 3.0x, head: 2.0x
2026-01-29 14:35:01.080 | INFO     | finetuning_progressive_v4_exp:get_model:108 - [Exp v4] Loss weights adjusted:
2026-01-29 14:35:01.080 | INFO     | finetuning_progressive_v4_exp:get_model:109 -   sep_scale: 0.12 -> 0.25
2026-01-29 14:35:01.081 | INFO     | finetuning_progressive_v4_exp:get_model:110 -   orth_scale: 0.08 -> 0.02
2026-01-29 14:35:01.081 | INFO     | finetuning_progressive_v4_exp:get_model:111 -   local_consistency_scale: 0.05 -> 0.1
2026-01-29 14:35:01.081 | INFO     | finetuning_progressive_v4_exp:get_model:112 -   margin: 0.3 -> 0.5
Parameter groups for differential learning rate:
  - backbone: 305 tensors, 56,940,186 params (51.6%), lr=5.00e-06
  - mhf_original: 164 tensors, 21,889,848 params (19.8%), lr=2.00e-05
  - enhancement: 16 tensors, 98,380 params (0.1%), lr=3.00e-04
  - head: 84 tensors, 31,477,830 params (28.5%), lr=2.00e-04
2026-01-29 14:35:01.510 | INFO     | projects.eval_tools.finetuning_stage2_exp:set_current_state:111 - Loading stage1 weights from: /home/backup/lh/KD/outputs/HiFuse_Small_1e-5-0.05/ft_progressive_v3_eval/88.4last_epoch_best_ckpt.checkpoints.tar
2026-01-29 14:35:02.917 | INFO     | finetuning_progressive_v4_exp:get_model:108 - [Exp v4] Loss weights adjusted:
2026-01-29 14:35:02.917 | INFO     | finetuning_progressive_v4_exp:get_model:109 -   sep_scale: 0.12 -> 0.25
2026-01-29 14:35:02.917 | INFO     | finetuning_progressive_v4_exp:get_model:110 -   orth_scale: 0.08 -> 0.02
2026-01-29 14:35:02.918 | INFO     | finetuning_progressive_v4_exp:get_model:111 -   local_consistency_scale: 0.05 -> 0.1
2026-01-29 14:35:02.918 | INFO     | finetuning_progressive_v4_exp:get_model:112 -   margin: 0.3 -> 0.5
2026-01-29 14:35:03.047 | INFO     | projects.eval_tools.finetuning_stage2_exp:set_model_weights_stage2:172 - Successfully loaded 679 parameters
2026-01-29 14:35:03.048 | INFO     | projects.eval_tools.finetuning_stage2_exp:set_model_weights_stage2:173 - Skipped 679 parameters (shape mismatch or not in target)
2026-01-29 14:35:03.152 | INFO     | projects.eval_tools.finetuning_stage2_exp:set_current_state:113 - Loaded keys: 647
2026-01-29 14:35:03.153 | INFO     | projects.eval_tools.finetuning_stage2_exp:set_current_state:114 - Missing keys (new modules): ['ema_model.module.downsample_layers.0.0.weight', 'ema_model.module.downsample_layers.0.0.bias', 'ema_model.module.downsample_layers.0.1.weight', 'ema_model.module.downsample_layers.0.1.bias', 'ema_model.module.downsample_layers.1.0.weight', 'ema_model.module.downsample_layers.1.0.bias', 'ema_model.module.downsample_layers.1.1.weight', 'ema_model.module.downsample_layers.1.1.bias', 'ema_model.module.downsample_layers.2.0.weight', 'ema_model.module.downsample_layers.2.0.bias']...
2026-01-29 14:35:03.153 | INFO     | projects.eval_tools.finetuning_stage2_exp:set_current_state:115 - Unexpected keys: []...
2026-01-29 14:35:03.153 | INFO     | __main__:main_worker:321 - Training start...
2026-01-29 14:35:03.155 | INFO     | __main__:main_worker:346 - Backbone frozen for first 3 epochs (Head warmup)
[main_model_enhanced] Backbone frozen: 353 parameter tensors
2026-01-29 14:35:08.271 | INFO     | __main__:main_worker:355 - ---> start train epoch1
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:35:13.972 | INFO     | __main__:main_worker:429 - [1/100], remain:0d.00h.50m, It:[10/54], Max-Mem:8349M, Data-Time:0.023, LR:0.0000, Train_Loss:0.3971, total_loss:tensor([0.3971], device='cuda:0'), ce_loss:0.7062709331512451, cluster_loss:0.10092436522245407, sep_loss:0.06044965609908104, soft_orth_loss:0.004965758416801691, local_consistency_loss:0.0008892686455510557, proto_loss:0.1672290414571762
2026-01-29 14:35:17.461 | INFO     | __main__:main_worker:429 - [1/100], remain:0d.00h.40m, It:[20/54], Max-Mem:8349M, Data-Time:1.013, LR:0.0000, Train_Loss:0.9137, total_loss:tensor([0.9137], device='cuda:0'), ce_loss:0.993634045124054, cluster_loss:0.15088777244091034, sep_loss:0.05876951664686203, soft_orth_loss:0.004964776337146759, local_consistency_loss:0.007028072606772184, proto_loss:0.2216501235961914
2026-01-29 14:35:22.081 | INFO     | __main__:main_worker:429 - [1/100], remain:0d.00h.40m, It:[30/54], Max-Mem:8349M, Data-Time:2.097, LR:0.0000, Train_Loss:-0.0869, total_loss:tensor([-0.0869], device='cuda:0'), ce_loss:0.41754817962646484, cluster_loss:0.07339322566986084, sep_loss:0.05389633774757385, soft_orth_loss:0.004963788669556379, local_consistency_loss:0.0006439079879783094, proto_loss:0.1328972578048706
2026-01-29 14:35:27.099 | INFO     | __main__:main_worker:429 - [1/100], remain:0d.00h.41m, It:[40/54], Max-Mem:8349M, Data-Time:2.494, LR:0.0000, Train_Loss:0.0350, total_loss:tensor([0.0350], device='cuda:0'), ce_loss:0.47357693314552307, cluster_loss:0.0943605825304985, sep_loss:0.053358398377895355, soft_orth_loss:0.004962049424648285, local_consistency_loss:0.003154011210426688, proto_loss:0.15583503246307373
2026-01-29 14:35:32.456 | INFO     | __main__:main_worker:429 - [1/100], remain:0d.00h.42m, It:[50/54], Max-Mem:8349M, Data-Time:2.797, LR:0.0000, Train_Loss:-0.0276, total_loss:tensor([-0.0276], device='cuda:0'), ce_loss:0.44996756315231323, cluster_loss:0.07674723118543625, sep_loss:0.05676950514316559, soft_orth_loss:0.004960572812706232, local_consistency_loss:0.0012515386333689094, proto_loss:0.1397288292646408
Evaluating: 100%|| 15/15 [00:09<00:00,  1.55it/s]
2026-01-29 14:35:43.087 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [1/100], Top1:87.393, Top3:100.000, Test_precision:0.7827,Test_recall:0.8804,Test_f1:0.8153,,Test_specificity:0.9431 Test_loss:0.350413
2026-01-29 14:35:43.090 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
acc1: 87.3932, acc3: 100.0000, Precision: 0.7827, Recall: 0.8804, F1-Score: 0.8153, Specificity: 0.9431
2026-01-29 14:35:56.928 | INFO     | __main__:main_worker:355 - ---> start train epoch2
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:36:05.745 | INFO     | __main__:main_worker:429 - [2/100], remain:0d.00h.41m, It:[10/54], Max-Mem:8349M, Data-Time:1.717, LR:0.0000, Train_Loss:0.3751, total_loss:tensor([0.3751], device='cuda:0'), ce_loss:0.6660233736038208, cluster_loss:0.11714553087949753, sep_loss:0.06640751659870148, soft_orth_loss:0.004960197955369949, local_consistency_loss:0.0005357788759283721, proto_loss:0.18904902040958405
2026-01-29 14:36:10.637 | INFO     | __main__:main_worker:429 - [2/100], remain:0d.00h.42m, It:[20/54], Max-Mem:8349M, Data-Time:1.603, LR:0.0000, Train_Loss:0.3382, total_loss:tensor([0.3382], device='cuda:0'), ce_loss:0.6485483646392822, cluster_loss:0.11090745031833649, sep_loss:0.06555211544036865, soft_orth_loss:0.00495894392952323, local_consistency_loss:0.0012526772916316986, proto_loss:0.1826711893081665
2026-01-29 14:36:14.744 | INFO     | __main__:main_worker:429 - [2/100], remain:0d.00h.40m, It:[30/54], Max-Mem:8349M, Data-Time:1.106, LR:0.0000, Train_Loss:4.9593, total_loss:tensor([4.9593], device='cuda:0'), ce_loss:3.300673246383667, cluster_loss:0.47326144576072693, sep_loss:0.0886571854352951, soft_orth_loss:0.004957576282322407, local_consistency_loss:0.032454248517751694, proto_loss:0.5993304252624512
2026-01-29 14:36:19.533 | INFO     | __main__:main_worker:429 - [2/100], remain:0d.00h.40m, It:[40/54], Max-Mem:8349M, Data-Time:1.134, LR:0.0000, Train_Loss:0.8893, total_loss:tensor([0.8893], device='cuda:0'), ce_loss:1.013662338256836, cluster_loss:0.11109817028045654, sep_loss:0.07177530974149704, soft_orth_loss:0.00495876045897603, local_consistency_loss:0.0030875904485583305, proto_loss:0.19091984629631042
2026-01-29 14:36:23.789 | INFO     | __main__:main_worker:429 - [2/100], remain:0d.00h.39m, It:[50/54], Max-Mem:8349M, Data-Time:1.361, LR:0.0000, Train_Loss:0.5316, total_loss:tensor([0.5316], device='cuda:0'), ce_loss:0.7661508917808533, cluster_loss:0.11256259679794312, sep_loss:0.07583330571651459, soft_orth_loss:0.004960709251463413, local_consistency_loss:0.001469485810957849, proto_loss:0.19482611119747162
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 14:36:33.970 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [2/100], Top1:86.111, Top3:100.000, Test_precision:0.7655,Test_recall:0.8486,Test_f1:0.7945,,Test_specificity:0.9334 Test_loss:0.405838
2026-01-29 14:36:33.971 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:36:33.971 | INFO     | __main__:main_worker:355 - ---> start train epoch3
acc1: 86.1111, acc3: 100.0000, Precision: 0.7655, Recall: 0.8486, F1-Score: 0.7945, Specificity: 0.9334
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:36:43.726 | INFO     | __main__:main_worker:429 - [3/100], remain:0d.00h.39m, It:[10/54], Max-Mem:8349M, Data-Time:1.995, LR:0.0000, Train_Loss:0.2515, total_loss:tensor([0.2515], device='cuda:0'), ce_loss:0.6162176728248596, cluster_loss:0.08185901492834091, sep_loss:0.07192809879779816, soft_orth_loss:0.0049615842290222645, local_consistency_loss:0.0017768308753147721, proto_loss:0.16052551567554474
2026-01-29 14:36:47.706 | INFO     | __main__:main_worker:429 - [3/100], remain:0d.00h.36m, It:[20/54], Max-Mem:8349M, Data-Time:1.445, LR:0.0000, Train_Loss:0.3813, total_loss:tensor([0.3813], device='cuda:0'), ce_loss:0.6815170049667358, cluster_loss:0.09661173075437546, sep_loss:0.0769551545381546, soft_orth_loss:0.004964042454957962, local_consistency_loss:0.0016906524542719126, proto_loss:0.1802215725183487
2026-01-29 14:36:52.384 | INFO     | __main__:main_worker:429 - [3/100], remain:0d.00h.37m, It:[30/54], Max-Mem:8349M, Data-Time:2.149, LR:0.0001, Train_Loss:2.2945, total_loss:tensor([2.2945], device='cuda:0'), ce_loss:1.6974289417266846, cluster_loss:0.30013877153396606, sep_loss:0.07663477957248688, soft_orth_loss:0.004965116735547781, local_consistency_loss:0.0408816784620285, proto_loss:0.42262035608291626
2026-01-29 14:36:57.499 | INFO     | __main__:main_worker:429 - [3/100], remain:0d.00h.39m, It:[40/54], Max-Mem:8349M, Data-Time:2.519, LR:0.0001, Train_Loss:0.2279, total_loss:tensor([0.2279], device='cuda:0'), ce_loss:0.5912446975708008, cluster_loss:0.1006116271018982, sep_loss:0.06074315309524536, soft_orth_loss:0.004962998908013105, local_consistency_loss:0.0023848339915275574, proto_loss:0.1687026023864746
2026-01-29 14:37:00.694 | INFO     | __main__:main_worker:429 - [3/100], remain:0d.00h.36m, It:[50/54], Max-Mem:8349M, Data-Time:0.629, LR:0.0001, Train_Loss:0.2999, total_loss:tensor([0.2999], device='cuda:0'), ce_loss:0.6411704421043396, cluster_loss:0.08773107826709747, sep_loss:0.07417179644107819, soft_orth_loss:0.0049630990251898766, local_consistency_loss:0.0011935158399865031, proto_loss:0.16805948317050934
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
acc1: 85.2564, acc3: 100.0000, Precision: 0.7544, Recall: 0.8395, F1-Score: 0.7834, Specificity: 0.9298
[main_model_enhanced] Backbone unfrozen: 353 parameter tensors
2026-01-29 14:37:10.537 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [3/100], Top1:85.256, Top3:100.000, Test_precision:0.7544,Test_recall:0.8395,Test_f1:0.7834,,Test_specificity:0.9298 Test_loss:0.378648
2026-01-29 14:37:10.538 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:37:10.538 | INFO     | __main__:main_worker:355 - ---> start train epoch4
2026-01-29 14:37:10.541 | INFO     | __main__:main_worker:364 - Backbone unfrozen at epoch 4 (Head warmup completed)
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:37:20.878 | INFO     | __main__:main_worker:429 - [4/100], remain:0d.00h.52m, It:[10/54], Max-Mem:11246M, Data-Time:2.308, LR:0.0001, Train_Loss:0.2141, total_loss:tensor([0.2141], device='cuda:0'), ce_loss:0.5954227447509766, cluster_loss:0.08767616003751755, sep_loss:0.0638945922255516, soft_orth_loss:0.004963192623108625, local_consistency_loss:0.001104683498851955, proto_loss:0.15763862431049347
2026-01-29 14:37:25.291 | INFO     | __main__:main_worker:429 - [4/100], remain:0d.00h.45m, It:[20/54], Max-Mem:11246M, Data-Time:0.988, LR:0.0001, Train_Loss:0.2580, total_loss:tensor([0.2580], device='cuda:0'), ce_loss:0.6198233962059021, cluster_loss:0.0890786349773407, sep_loss:0.06653536856174469, soft_orth_loss:0.00496320053935051, local_consistency_loss:0.0017647140193730593, proto_loss:0.1623419225215912
2026-01-29 14:37:29.117 | INFO     | __main__:main_worker:429 - [4/100], remain:0d.00h.40m, It:[30/54], Max-Mem:11246M, Data-Time:0.401, LR:0.0001, Train_Loss:0.1104, total_loss:tensor([0.1104], device='cuda:0'), ce_loss:0.5405857563018799, cluster_loss:0.07841687649488449, sep_loss:0.06003239005804062, soft_orth_loss:0.004961771424859762, local_consistency_loss:0.0011263660853728652, proto_loss:0.14453740417957306
2026-01-29 14:37:32.795 | INFO     | __main__:main_worker:429 - [4/100], remain:0d.00h.38m, It:[40/54], Max-Mem:11246M, Data-Time:0.267, LR:0.0001, Train_Loss:-0.0125, total_loss:tensor([-0.0125], device='cuda:0'), ce_loss:0.45578068494796753, cluster_loss:0.08051007241010666, sep_loss:0.05919496715068817, soft_orth_loss:0.004959368146955967, local_consistency_loss:0.0010144757106900215, proto_loss:0.14567887783050537
2026-01-29 14:37:37.782 | INFO     | __main__:main_worker:429 - [4/100], remain:0d.00h.38m, It:[50/54], Max-Mem:11246M, Data-Time:1.594, LR:0.0001, Train_Loss:-0.0209, total_loss:tensor([-0.0209], device='cuda:0'), ce_loss:0.48061156272888184, cluster_loss:0.057298507541418076, sep_loss:0.055948518216609955, soft_orth_loss:0.004957449156790972, local_consistency_loss:0.0016412902623414993, proto_loss:0.11984576284885406
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
2026-01-29 14:37:47.419 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [4/100], Top1:85.684, Top3:100.000, Test_precision:0.7482,Test_recall:0.7958,Test_f1:0.7672,,Test_specificity:0.9253 Test_loss:0.366004
acc1: 85.6838, acc3: 100.0000, Precision: 0.7482, Recall: 0.7958, F1-Score: 0.7672, Specificity: 0.9253
2026-01-29 14:37:47.420 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:37:47.421 | INFO     | __main__:main_worker:355 - ---> start train epoch5
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:37:55.143 | INFO     | __main__:main_worker:429 - [5/100], remain:0d.00h.32m, It:[10/54], Max-Mem:11246M, Data-Time:0.431, LR:0.0001, Train_Loss:0.3158, total_loss:tensor([0.3158], device='cuda:0'), ce_loss:0.6477938890457153, cluster_loss:0.09759841114282608, sep_loss:0.06818213313817978, soft_orth_loss:0.00495556415989995, local_consistency_loss:0.0016254725633189082, proto_loss:0.1723615825176239
2026-01-29 14:37:59.959 | INFO     | __main__:main_worker:429 - [5/100], remain:0d.00h.36m, It:[20/54], Max-Mem:11246M, Data-Time:0.010, LR:0.0001, Train_Loss:2.4211, total_loss:tensor([2.4211], device='cuda:0'), ce_loss:1.875279426574707, cluster_loss:0.22890153527259827, sep_loss:0.09172531217336655, soft_orth_loss:0.00495429802685976, local_consistency_loss:0.019733725115656853, proto_loss:0.3453148901462555
2026-01-29 14:38:03.636 | INFO     | __main__:main_worker:429 - [5/100], remain:0d.00h.34m, It:[30/54], Max-Mem:11246M, Data-Time:0.253, LR:0.0001, Train_Loss:0.4250, total_loss:tensor([0.4250], device='cuda:0'), ce_loss:0.7089434266090393, cluster_loss:0.10017389059066772, sep_loss:0.0767165943980217, soft_orth_loss:0.0049538337625563145, local_consistency_loss:0.0018474636599421501, proto_loss:0.18369178473949432
2026-01-29 14:38:09.480 | INFO     | __main__:main_worker:429 - [5/100], remain:0d.00h.38m, It:[40/54], Max-Mem:11246M, Data-Time:0.012, LR:0.0001, Train_Loss:0.4647, total_loss:tensor([0.4647], device='cuda:0'), ce_loss:0.7287691831588745, cluster_loss:0.11563892662525177, sep_loss:0.06810781359672546, soft_orth_loss:0.0049552940763533115, local_consistency_loss:0.001185477594844997, proto_loss:0.18988750874996185
2026-01-29 14:38:14.167 | INFO     | __main__:main_worker:429 - [5/100], remain:0d.00h.38m, It:[50/54], Max-Mem:11246M, Data-Time:0.017, LR:0.0001, Train_Loss:0.5321, total_loss:tensor([0.5321], device='cuda:0'), ce_loss:0.7712075710296631, cluster_loss:0.10249032825231552, sep_loss:0.07998092472553253, soft_orth_loss:0.004955269396305084, local_consistency_loss:0.005458657164126635, proto_loss:0.192885160446167
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 86.1111, acc3: 100.0000, Precision: 0.7624, Recall: 0.8170, F1-Score: 0.7846, Specificity: 0.9276
2026-01-29 14:38:23.601 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [5/100], Top1:86.111, Top3:100.000, Test_precision:0.7624,Test_recall:0.8170,Test_f1:0.7846,,Test_specificity:0.9276 Test_loss:0.434291
2026-01-29 14:38:23.604 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:38:33.490 | INFO     | __main__:main_worker:355 - ---> start train epoch6
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:38:41.693 | INFO     | __main__:main_worker:429 - [6/100], remain:0d.00h.36m, It:[10/54], Max-Mem:11246M, Data-Time:0.010, LR:0.0001, Train_Loss:1.4736, total_loss:tensor([1.4736], device='cuda:0'), ce_loss:1.320419430732727, cluster_loss:0.16456234455108643, sep_loss:0.08326812833547592, soft_orth_loss:0.004954598378390074, local_consistency_loss:0.017477385699748993, proto_loss:0.2702624797821045
2026-01-29 14:38:46.430 | INFO     | __main__:main_worker:429 - [6/100], remain:0d.00h.38m, It:[20/54], Max-Mem:11246M, Data-Time:0.561, LR:0.0001, Train_Loss:1.9514, total_loss:tensor([1.9514], device='cuda:0'), ce_loss:1.63399076461792, cluster_loss:0.16929687559604645, sep_loss:0.09812226891517639, soft_orth_loss:0.00495231244713068, local_consistency_loss:0.007788735907524824, proto_loss:0.28016021847724915
2026-01-29 14:38:51.225 | INFO     | __main__:main_worker:429 - [6/100], remain:0d.00h.38m, It:[30/54], Max-Mem:11246M, Data-Time:0.017, LR:0.0001, Train_Loss:0.3479, total_loss:tensor([0.3479], device='cuda:0'), ce_loss:0.6704887747764587, cluster_loss:0.08700966089963913, sep_loss:0.07910922914743423, soft_orth_loss:0.004952079150825739, local_consistency_loss:0.0015167577657848597, proto_loss:0.17258772253990173
2026-01-29 14:38:56.317 | INFO     | __main__:main_worker:429 - [6/100], remain:0d.00h.39m, It:[40/54], Max-Mem:11246M, Data-Time:0.016, LR:0.0001, Train_Loss:1.7412, total_loss:tensor([1.7412], device='cuda:0'), ce_loss:1.4994651079177856, cluster_loss:0.1757621169090271, sep_loss:0.09126760065555573, soft_orth_loss:0.004951917566359043, local_consistency_loss:0.0014831156004220247, proto_loss:0.27346473932266235
2026-01-29 14:38:59.997 | INFO     | __main__:main_worker:429 - [6/100], remain:0d.00h.37m, It:[50/54], Max-Mem:11246M, Data-Time:0.012, LR:0.0001, Train_Loss:0.4336, total_loss:tensor([0.4336], device='cuda:0'), ce_loss:0.7214013934135437, cluster_loss:0.09338857978582382, sep_loss:0.0798744261264801, soft_orth_loss:0.004950660280883312, local_consistency_loss:0.0009160186164081097, proto_loss:0.1791296899318695
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
acc1: 85.4701, acc3: 100.0000, Precision: 0.7761, Recall: 0.7862, F1-Score: 0.7761, Specificity: 0.9229
2026-01-29 14:39:11.060 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [6/100], Top1:85.470, Top3:100.000, Test_precision:0.7761,Test_recall:0.7862,Test_f1:0.7761,,Test_specificity:0.9229 Test_loss:0.481048
2026-01-29 14:39:11.061 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:39:11.062 | INFO     | __main__:main_worker:355 - ---> start train epoch7
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:39:20.018 | INFO     | __main__:main_worker:429 - [7/100], remain:0d.00h.43m, It:[10/54], Max-Mem:11246M, Data-Time:0.068, LR:0.0001, Train_Loss:0.5178, total_loss:tensor([0.5178], device='cuda:0'), ce_loss:0.7797498106956482, cluster_loss:0.08878560364246368, sep_loss:0.0835585743188858, soft_orth_loss:0.004947995766997337, local_consistency_loss:0.0012183196377009153, proto_loss:0.17851048707962036
2026-01-29 14:39:24.635 | INFO     | __main__:main_worker:429 - [7/100], remain:0d.00h.40m, It:[20/54], Max-Mem:11246M, Data-Time:0.018, LR:0.0001, Train_Loss:0.5278, total_loss:tensor([0.5278], device='cuda:0'), ce_loss:0.786207914352417, cluster_loss:0.0919879898428917, sep_loss:0.08086885511875153, soft_orth_loss:0.0049481443129479885, local_consistency_loss:0.0012212548172101378, proto_loss:0.17902623116970062
2026-01-29 14:39:29.104 | INFO     | __main__:main_worker:429 - [7/100], remain:0d.00h.39m, It:[30/54], Max-Mem:11246M, Data-Time:0.464, LR:0.0001, Train_Loss:0.4860, total_loss:tensor([0.4860], device='cuda:0'), ce_loss:0.7508304119110107, cluster_loss:0.09841641038656235, sep_loss:0.08051711320877075, soft_orth_loss:0.0049490309320390224, local_consistency_loss:0.0011511138873174787, proto_loss:0.1850336790084839
2026-01-29 14:39:33.590 | INFO     | __main__:main_worker:429 - [7/100], remain:0d.00h.38m, It:[40/54], Max-Mem:11246M, Data-Time:0.562, LR:0.0001, Train_Loss:0.3037, total_loss:tensor([0.3037], device='cuda:0'), ce_loss:0.6473869681358337, cluster_loss:0.0886925607919693, sep_loss:0.07191304862499237, soft_orth_loss:0.004950045607984066, local_consistency_loss:0.0020970983896404505, proto_loss:0.16765275597572327
2026-01-29 14:39:38.408 | INFO     | __main__:main_worker:429 - [7/100], remain:0d.00h.38m, It:[50/54], Max-Mem:11246M, Data-Time:0.012, LR:0.0001, Train_Loss:0.0010, total_loss:tensor([0.0010], device='cuda:0'), ce_loss:0.4858899414539337, cluster_loss:0.05338640138506889, sep_loss:0.06972600519657135, soft_orth_loss:0.004948846995830536, local_consistency_loss:0.0020223078317940235, proto_loss:0.1300835758447647
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
2026-01-29 14:39:48.582 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [7/100], Top1:84.829, Top3:100.000, Test_precision:0.7375,Test_recall:0.7728,Test_f1:0.7509,,Test_specificity:0.9168 Test_loss:0.456660
2026-01-29 14:39:48.583 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:39:48.584 | INFO     | __main__:main_worker:355 - ---> start train epoch8
acc1: 84.8291, acc3: 100.0000, Precision: 0.7375, Recall: 0.7728, F1-Score: 0.7509, Specificity: 0.9168
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:39:59.135 | INFO     | __main__:main_worker:429 - [8/100], remain:0d.00h.42m, It:[10/54], Max-Mem:11246M, Data-Time:1.629, LR:0.0001, Train_Loss:-0.0273, total_loss:tensor([-0.0273], device='cuda:0'), ce_loss:0.4523351192474365, cluster_loss:0.07116541266441345, sep_loss:0.06407865136861801, soft_orth_loss:0.004950868897140026, local_consistency_loss:0.0021206801757216454, proto_loss:0.14231561124324799
2026-01-29 14:40:03.177 | INFO     | __main__:main_worker:429 - [8/100], remain:0d.00h.37m, It:[20/54], Max-Mem:11246M, Data-Time:0.659, LR:0.0001, Train_Loss:0.2596, total_loss:tensor([0.2596], device='cuda:0'), ce_loss:0.6440128087997437, cluster_loss:0.07273950427770615, sep_loss:0.06664110720157623, soft_orth_loss:0.004952021408826113, local_consistency_loss:0.0014722875785082579, proto_loss:0.14580492675304413
2026-01-29 14:40:06.683 | INFO     | __main__:main_worker:429 - [8/100], remain:0d.00h.34m, It:[30/54], Max-Mem:11246M, Data-Time:0.126, LR:0.0001, Train_Loss:2.3178, total_loss:tensor([2.3178], device='cuda:0'), ce_loss:1.829635739326477, cluster_loss:0.22945895791053772, sep_loss:0.09159131348133087, soft_orth_loss:0.004951329901814461, local_consistency_loss:0.0028505336958914995, proto_loss:0.3288521468639374
2026-01-29 14:40:10.263 | INFO     | __main__:main_worker:429 - [8/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11246M, Data-Time:0.051, LR:0.0001, Train_Loss:1.3189, total_loss:tensor([1.3189], device='cuda:0'), ce_loss:1.2409114837646484, cluster_loss:0.1576816588640213, sep_loss:0.0869826078414917, soft_orth_loss:0.004949497990310192, local_consistency_loss:0.0018609442049637437, proto_loss:0.2514747083187103
2026-01-29 14:40:15.041 | INFO     | __main__:main_worker:429 - [8/100], remain:0d.00h.34m, It:[50/54], Max-Mem:11246M, Data-Time:0.011, LR:0.0001, Train_Loss:0.2563, total_loss:tensor([0.2563], device='cuda:0'), ce_loss:0.7165490984916687, cluster_loss:0.00019083524239249527, sep_loss:0.0773792415857315, soft_orth_loss:0.00495200976729393, local_consistency_loss:0.0009757058578543365, proto_loss:0.0834977850317955
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 14:40:25.359 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [8/100], Top1:85.043, Top3:100.000, Test_precision:0.7537,Test_recall:0.8332,Test_f1:0.7826,,Test_specificity:0.9263 Test_loss:0.448209
acc1: 85.0427, acc3: 100.0000, Precision: 0.7537, Recall: 0.8332, F1-Score: 0.7826, Specificity: 0.9263
2026-01-29 14:40:25.360 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:40:25.360 | INFO     | __main__:main_worker:355 - ---> start train epoch9
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:40:34.611 | INFO     | __main__:main_worker:429 - [9/100], remain:0d.00h.29m, It:[10/54], Max-Mem:11246M, Data-Time:0.278, LR:0.0001, Train_Loss:0.5693, total_loss:tensor([0.5693], device='cuda:0'), ce_loss:0.7756372690200806, cluster_loss:0.14884641766548157, sep_loss:0.05828550457954407, soft_orth_loss:0.004955003038048744, local_consistency_loss:0.0013594873016700149, proto_loss:0.21344642341136932
2026-01-29 14:40:39.065 | INFO     | __main__:main_worker:429 - [9/100], remain:0d.00h.32m, It:[20/54], Max-Mem:11246M, Data-Time:1.036, LR:0.0001, Train_Loss:0.7263, total_loss:tensor([0.7263], device='cuda:0'), ce_loss:0.8901891112327576, cluster_loss:0.12394874542951584, sep_loss:0.0771569311618805, soft_orth_loss:0.004954996984452009, local_consistency_loss:0.0012697629863396287, proto_loss:0.20733043551445007
2026-01-29 14:40:43.784 | INFO     | __main__:main_worker:429 - [9/100], remain:0d.00h.34m, It:[30/54], Max-Mem:11246M, Data-Time:0.019, LR:0.0001, Train_Loss:0.3446, total_loss:tensor([0.3446], device='cuda:0'), ce_loss:0.6679509282112122, cluster_loss:0.1052086353302002, sep_loss:0.06454576551914215, soft_orth_loss:0.004954023286700249, local_consistency_loss:0.0008657213184051216, proto_loss:0.1755741536617279
2026-01-29 14:40:48.260 | INFO     | __main__:main_worker:429 - [9/100], remain:0d.00h.34m, It:[40/54], Max-Mem:11246M, Data-Time:0.016, LR:0.0001, Train_Loss:0.1485, total_loss:tensor([0.1485], device='cuda:0'), ce_loss:0.6674790978431702, cluster_loss:0.00022614859335590154, sep_loss:0.05765809863805771, soft_orth_loss:0.004953255411237478, local_consistency_loss:0.0012494297698140144, proto_loss:0.06408693641424179
2026-01-29 14:40:52.393 | INFO     | __main__:main_worker:429 - [9/100], remain:0d.00h.34m, It:[50/54], Max-Mem:11246M, Data-Time:0.013, LR:0.0001, Train_Loss:0.0341, total_loss:tensor([0.0341], device='cuda:0'), ce_loss:0.5905987620353699, cluster_loss:0.00023223071184474975, sep_loss:0.05707688257098198, soft_orth_loss:0.004952553194016218, local_consistency_loss:0.0011628641514107585, proto_loss:0.06342452764511108
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 86.7521, acc3: 100.0000, Precision: 0.8064, Recall: 0.7559, F1-Score: 0.7678, Specificity: 0.9210
2026-01-29 14:41:03.246 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [9/100], Top1:86.752, Top3:100.000, Test_precision:0.8064,Test_recall:0.7559,Test_f1:0.7678,,Test_specificity:0.9210 Test_loss:0.366338
2026-01-29 14:41:03.247 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:41:03.247 | INFO     | __main__:main_worker:355 - ---> start train epoch10
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:41:12.701 | INFO     | __main__:main_worker:429 - [10/100], remain:0d.00h.35m, It:[10/54], Max-Mem:11246M, Data-Time:1.016, LR:0.0001, Train_Loss:1.2892, total_loss:tensor([1.2892], device='cuda:0'), ce_loss:1.2120383977890015, cluster_loss:0.17173774540424347, sep_loss:0.0817602202296257, soft_orth_loss:0.004951060749590397, local_consistency_loss:0.0014659868320450187, proto_loss:0.25991499423980713
2026-01-29 14:41:16.843 | INFO     | __main__:main_worker:429 - [10/100], remain:0d.00h.34m, It:[20/54], Max-Mem:11246M, Data-Time:0.680, LR:0.0001, Train_Loss:0.2142, total_loss:tensor([0.2142], device='cuda:0'), ce_loss:0.6010680198669434, cluster_loss:0.08910804241895676, sep_loss:0.06272976845502853, soft_orth_loss:0.004948941990733147, local_consistency_loss:0.001176726771518588, proto_loss:0.15796348452568054
2026-01-29 14:41:21.172 | INFO     | __main__:main_worker:429 - [10/100], remain:0d.00h.34m, It:[30/54], Max-Mem:11246M, Data-Time:0.637, LR:0.0001, Train_Loss:0.2181, total_loss:tensor([0.2181], device='cuda:0'), ce_loss:0.6152329444885254, cluster_loss:0.07995125651359558, sep_loss:0.06320326030254364, soft_orth_loss:0.0049481806345283985, local_consistency_loss:0.00043925028876401484, proto_loss:0.14854195713996887
2026-01-29 14:41:25.423 | INFO     | __main__:main_worker:429 - [10/100], remain:0d.00h.34m, It:[40/54], Max-Mem:11246M, Data-Time:0.818, LR:0.0001, Train_Loss:-0.0057, total_loss:tensor([-0.0057], device='cuda:0'), ce_loss:0.470522940158844, cluster_loss:0.0780177041888237, sep_loss:0.05837342143058777, soft_orth_loss:0.004946248605847359, local_consistency_loss:0.0007757990970276296, proto_loss:0.14211317896842957
2026-01-29 14:41:30.129 | INFO     | __main__:main_worker:429 - [10/100], remain:0d.00h.34m, It:[50/54], Max-Mem:11246M, Data-Time:1.320, LR:0.0001, Train_Loss:0.3325, total_loss:tensor([0.3325], device='cuda:0'), ce_loss:0.7759591937065125, cluster_loss:0.000498334295116365, sep_loss:0.072685107588768, soft_orth_loss:0.004943118896335363, local_consistency_loss:0.001645540469326079, proto_loss:0.07977209985256195
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 14:41:39.635 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [10/100], Top1:83.761, Top3:100.000, Test_precision:0.7464,Test_recall:0.8343,Test_f1:0.7770,,Test_specificity:0.9170 Test_loss:0.436316
2026-01-29 14:41:39.637 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
acc1: 83.7607, acc3: 100.0000, Precision: 0.7464, Recall: 0.8343, F1-Score: 0.7770, Specificity: 0.9170
2026-01-29 14:41:49.853 | INFO     | __main__:main_worker:355 - ---> start train epoch11
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:41:58.369 | INFO     | __main__:main_worker:429 - [11/100], remain:0d.00h.37m, It:[10/54], Max-Mem:11246M, Data-Time:0.196, LR:0.0001, Train_Loss:0.0512, total_loss:tensor([0.0512], device='cuda:0'), ce_loss:0.47779783606529236, cluster_loss:0.0968407616019249, sep_loss:0.06531590968370438, soft_orth_loss:0.004940595477819443, local_consistency_loss:0.0018173720454797149, proto_loss:0.16891464591026306
2026-01-29 14:42:03.534 | INFO     | __main__:main_worker:429 - [11/100], remain:0d.00h.38m, It:[20/54], Max-Mem:11246M, Data-Time:0.017, LR:0.0001, Train_Loss:0.0060, total_loss:tensor([0.0060], device='cuda:0'), ce_loss:0.4806440770626068, cluster_loss:0.07783149927854538, sep_loss:0.057374440133571625, soft_orth_loss:0.004940114449709654, local_consistency_loss:0.0009073684923350811, proto_loss:0.14105340838432312
2026-01-29 14:42:07.952 | INFO     | __main__:main_worker:429 - [11/100], remain:0d.00h.37m, It:[30/54], Max-Mem:11246M, Data-Time:0.896, LR:0.0001, Train_Loss:-0.1398, total_loss:tensor([-0.1398], device='cuda:0'), ce_loss:0.4075493812561035, cluster_loss:0.06881865113973618, sep_loss:0.0440269373357296, soft_orth_loss:0.004937668796628714, local_consistency_loss:0.0015788078308105469, proto_loss:0.11936206370592117
2026-01-29 14:42:11.461 | INFO     | __main__:main_worker:429 - [11/100], remain:0d.00h.34m, It:[40/54], Max-Mem:11246M, Data-Time:0.011, LR:0.0001, Train_Loss:-0.2003, total_loss:tensor([-0.2003], device='cuda:0'), ce_loss:0.36451226472854614, cluster_loss:0.06804533302783966, sep_loss:0.04716312885284424, soft_orth_loss:0.004936251323670149, local_consistency_loss:0.0009410089114680886, proto_loss:0.12108571827411652
2026-01-29 14:42:15.714 | INFO     | __main__:main_worker:429 - [11/100], remain:0d.00h.34m, It:[50/54], Max-Mem:11246M, Data-Time:0.144, LR:0.0001, Train_Loss:0.3260, total_loss:tensor([0.3260], device='cuda:0'), ce_loss:0.6616730690002441, cluster_loss:0.09402089565992355, sep_loss:0.07234654575586319, soft_orth_loss:0.004934650380164385, local_consistency_loss:0.0012606403324753046, proto_loss:0.17256273329257965
Evaluating: 100%|| 15/15 [00:07<00:00,  1.90it/s]
acc1: 82.6923, acc3: 100.0000, Precision: 0.7363, Recall: 0.8625, F1-Score: 0.7639, Specificity: 0.9294
2026-01-29 14:42:26.197 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [11/100], Top1:82.692, Top3:100.000, Test_precision:0.7363,Test_recall:0.8625,Test_f1:0.7639,,Test_specificity:0.9294 Test_loss:0.500323
2026-01-29 14:42:26.198 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:42:26.199 | INFO     | __main__:main_worker:355 - ---> start train epoch12
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:42:34.682 | INFO     | __main__:main_worker:429 - [12/100], remain:0d.00h.29m, It:[10/54], Max-Mem:11246M, Data-Time:0.376, LR:0.0001, Train_Loss:0.2454, total_loss:tensor([0.2454], device='cuda:0'), ce_loss:0.606028139591217, cluster_loss:0.10225701332092285, sep_loss:0.06533439457416534, soft_orth_loss:0.0049313390627503395, local_consistency_loss:0.0008804401732049882, proto_loss:0.17340318858623505
2026-01-29 14:42:39.329 | INFO     | __main__:main_worker:429 - [12/100], remain:0d.00h.32m, It:[20/54], Max-Mem:11246M, Data-Time:0.674, LR:0.0001, Train_Loss:0.3655, total_loss:tensor([0.3655], device='cuda:0'), ce_loss:0.6853511333465576, cluster_loss:0.09709355980157852, sep_loss:0.07217727601528168, soft_orth_loss:0.0049301800318062305, local_consistency_loss:0.0015023043379187584, proto_loss:0.17570333182811737
2026-01-29 14:42:43.861 | INFO     | __main__:main_worker:429 - [12/100], remain:0d.00h.33m, It:[30/54], Max-Mem:11246M, Data-Time:0.868, LR:0.0001, Train_Loss:0.4229, total_loss:tensor([0.4229], device='cuda:0'), ce_loss:0.693095326423645, cluster_loss:0.1302143782377243, sep_loss:0.0664062649011612, soft_orth_loss:0.004928349517285824, local_consistency_loss:0.00043507353984750807, proto_loss:0.20198406279087067
2026-01-29 14:42:48.603 | INFO     | __main__:main_worker:429 - [12/100], remain:0d.00h.34m, It:[40/54], Max-Mem:11246M, Data-Time:0.944, LR:0.0001, Train_Loss:0.1255, total_loss:tensor([0.1255], device='cuda:0'), ce_loss:0.5479209423065186, cluster_loss:0.07772599905729294, sep_loss:0.07078555226325989, soft_orth_loss:0.004923158325254917, local_consistency_loss:0.0008589983335696161, proto_loss:0.1542937159538269
2026-01-29 14:42:52.556 | INFO     | __main__:main_worker:429 - [12/100], remain:0d.00h.33m, It:[50/54], Max-Mem:11246M, Data-Time:0.311, LR:0.0001, Train_Loss:0.9764, total_loss:tensor([0.9764], device='cuda:0'), ce_loss:1.2048389911651611, cluster_loss:0.0003507898363750428, sep_loss:0.08442538976669312, soft_orth_loss:0.004918800201267004, local_consistency_loss:0.0007192627526819706, proto_loss:0.09041424095630646
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 85.6838, acc3: 100.0000, Precision: 0.7719, Recall: 0.8027, F1-Score: 0.7850, Specificity: 0.9220
2026-01-29 14:43:02.380 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [12/100], Top1:85.684, Top3:100.000, Test_precision:0.7719,Test_recall:0.8027,Test_f1:0.7850,,Test_specificity:0.9220 Test_loss:0.384580
2026-01-29 14:43:02.381 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:43:02.382 | INFO     | __main__:main_worker:355 - ---> start train epoch13
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:43:11.373 | INFO     | __main__:main_worker:429 - [13/100], remain:0d.00h.34m, It:[10/54], Max-Mem:11247M, Data-Time:1.100, LR:0.0001, Train_Loss:0.7057, total_loss:tensor([0.7057], device='cuda:0'), ce_loss:0.858421266078949, cluster_loss:0.14969556033611298, sep_loss:0.06997472047805786, soft_orth_loss:0.004911583382636309, local_consistency_loss:0.0008406316046603024, proto_loss:0.22542250156402588
2026-01-29 14:43:14.894 | INFO     | __main__:main_worker:429 - [13/100], remain:0d.00h.30m, It:[20/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:0.5495, total_loss:tensor([0.5495], device='cuda:0'), ce_loss:0.7880532145500183, cluster_loss:0.10877873003482819, sep_loss:0.07985976338386536, soft_orth_loss:0.00490542221814394, local_consistency_loss:0.0020359940826892853, proto_loss:0.1955799013376236
2026-01-29 14:43:18.983 | INFO     | __main__:main_worker:429 - [13/100], remain:0d.00h.31m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.1484, total_loss:tensor([0.1484], device='cuda:0'), ce_loss:0.574784517288208, cluster_loss:0.07630521804094315, sep_loss:0.06381998211145401, soft_orth_loss:0.004901401698589325, local_consistency_loss:0.0007846836815588176, proto_loss:0.1458112746477127
2026-01-29 14:43:23.376 | INFO     | __main__:main_worker:429 - [13/100], remain:0d.00h.31m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.5945, total_loss:tensor([0.5945], device='cuda:0'), ce_loss:0.8010156750679016, cluster_loss:0.13211408257484436, sep_loss:0.07232287526130676, soft_orth_loss:0.004897011909633875, local_consistency_loss:0.0013505590613931417, proto_loss:0.21068452298641205
2026-01-29 14:43:27.774 | INFO     | __main__:main_worker:429 - [13/100], remain:0d.00h.31m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:2.2296, total_loss:tensor([2.2296], device='cuda:0'), ce_loss:1.7621523141860962, cluster_loss:0.24468262493610382, sep_loss:0.08810864388942719, soft_orth_loss:0.0048952060751616955, local_consistency_loss:0.0007571927271783352, proto_loss:0.33844366669654846
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 83.9744, acc3: 100.0000, Precision: 0.7433, Recall: 0.8298, F1-Score: 0.7700, Specificity: 0.9317
2026-01-29 14:43:37.824 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [13/100], Top1:83.974, Top3:100.000, Test_precision:0.7433,Test_recall:0.8298,Test_f1:0.7700,,Test_specificity:0.9317 Test_loss:0.483412
2026-01-29 14:43:37.825 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:43:37.826 | INFO     | __main__:main_worker:355 - ---> start train epoch14
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:43:46.124 | INFO     | __main__:main_worker:429 - [14/100], remain:0d.00h.26m, It:[10/54], Max-Mem:11247M, Data-Time:0.179, LR:0.0001, Train_Loss:1.7186, total_loss:tensor([1.7186], device='cuda:0'), ce_loss:1.5042237043380737, cluster_loss:0.16047170758247375, sep_loss:0.09490494430065155, soft_orth_loss:0.004894046112895012, local_consistency_loss:0.0037268120795488358, proto_loss:0.26399749517440796
2026-01-29 14:43:50.496 | INFO     | __main__:main_worker:429 - [14/100], remain:0d.00h.30m, It:[20/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:1.5273, total_loss:tensor([1.5273], device='cuda:0'), ce_loss:1.3858054876327515, cluster_loss:0.15279121696949005, sep_loss:0.09469809383153915, soft_orth_loss:0.004893024452030659, local_consistency_loss:0.0020438400097191334, proto_loss:0.25442618131637573
2026-01-29 14:43:54.997 | INFO     | __main__:main_worker:429 - [14/100], remain:0d.00h.31m, It:[30/54], Max-Mem:11247M, Data-Time:0.414, LR:0.0001, Train_Loss:0.0853, total_loss:tensor([0.0853], device='cuda:0'), ce_loss:0.5333102345466614, cluster_loss:0.07433165609836578, sep_loss:0.06554502248764038, soft_orth_loss:0.004890642128884792, local_consistency_loss:0.0008802637457847595, proto_loss:0.1456475853919983
2026-01-29 14:43:59.917 | INFO     | __main__:main_worker:429 - [14/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.1466, total_loss:tensor([0.1466], device='cuda:0'), ce_loss:0.5529562830924988, cluster_loss:0.09801456332206726, sep_loss:0.06038527935743332, soft_orth_loss:0.0048866127617657185, local_consistency_loss:0.0009107555379159749, proto_loss:0.16419722139835358
2026-01-29 14:44:04.834 | INFO     | __main__:main_worker:429 - [14/100], remain:0d.00h.33m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:1.0662, total_loss:tensor([1.0662], device='cuda:0'), ce_loss:1.0749377012252808, cluster_loss:0.17423096299171448, sep_loss:0.07099700719118118, soft_orth_loss:0.004882102832198143, local_consistency_loss:0.001721254433505237, proto_loss:0.2518313229084015
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 14:44:14.957 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [14/100], Top1:86.752, Top3:100.000, Test_precision:0.8029,Test_recall:0.7597,Test_f1:0.7757,,Test_specificity:0.9139 Test_loss:0.369514
2026-01-29 14:44:14.958 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:44:14.958 | INFO     | __main__:main_worker:355 - ---> start train epoch15
acc1: 86.7521, acc3: 100.0000, Precision: 0.8029, Recall: 0.7597, F1-Score: 0.7757, Specificity: 0.9139
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:44:24.341 | INFO     | __main__:main_worker:429 - [15/100], remain:0d.00h.36m, It:[10/54], Max-Mem:11247M, Data-Time:0.996, LR:0.0001, Train_Loss:0.7960, total_loss:tensor([0.7960], device='cuda:0'), ce_loss:0.9048998355865479, cluster_loss:0.15764984488487244, sep_loss:0.0768624022603035, soft_orth_loss:0.004877828061580658, local_consistency_loss:0.0007455589366145432, proto_loss:0.24013563990592957
2026-01-29 14:44:29.256 | INFO     | __main__:main_worker:429 - [15/100], remain:0d.00h.36m, It:[20/54], Max-Mem:11247M, Data-Time:1.506, LR:0.0001, Train_Loss:0.8127, total_loss:tensor([0.8127], device='cuda:0'), ce_loss:0.9487103223800659, cluster_loss:0.12360026687383652, sep_loss:0.08452209830284119, soft_orth_loss:0.004874608013778925, local_consistency_loss:0.000607613124884665, proto_loss:0.21360458433628082
2026-01-29 14:44:33.527 | INFO     | __main__:main_worker:429 - [15/100], remain:0d.00h.35m, It:[30/54], Max-Mem:11247M, Data-Time:0.875, LR:0.0001, Train_Loss:0.1775, total_loss:tensor([0.1775], device='cuda:0'), ce_loss:0.6726306676864624, cluster_loss:0.0001824234495870769, sep_loss:0.07822982966899872, soft_orth_loss:0.0048711164854466915, local_consistency_loss:0.0006368284812197089, proto_loss:0.0839201956987381
2026-01-29 14:44:37.795 | INFO     | __main__:main_worker:429 - [15/100], remain:0d.00h.34m, It:[40/54], Max-Mem:11247M, Data-Time:0.594, LR:0.0001, Train_Loss:0.0639, total_loss:tensor([0.0639], device='cuda:0'), ce_loss:0.5094114542007446, cluster_loss:0.07912725955247879, sep_loss:0.07002244889736176, soft_orth_loss:0.004868745803833008, local_consistency_loss:0.000598809274379164, proto_loss:0.15461726486682892
2026-01-29 14:44:41.281 | INFO     | __main__:main_worker:429 - [15/100], remain:0d.00h.32m, It:[50/54], Max-Mem:11247M, Data-Time:0.154, LR:0.0001, Train_Loss:0.3382, total_loss:tensor([0.3382], device='cuda:0'), ce_loss:0.6886040568351746, cluster_loss:0.08575128763914108, sep_loss:0.07055196166038513, soft_orth_loss:0.004865589085966349, local_consistency_loss:0.00040984340012073517, proto_loss:0.1615786850452423
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
acc1: 84.1880, acc3: 100.0000, Precision: 0.7320, Recall: 0.7783, F1-Score: 0.7468, Specificity: 0.9151
2026-01-29 14:44:51.598 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [15/100], Top1:84.188, Top3:100.000, Test_precision:0.7320,Test_recall:0.7783,Test_f1:0.7468,,Test_specificity:0.9151 Test_loss:0.434967
2026-01-29 14:44:51.599 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [1/100], Top1:87.393, Top-3:100.000
2026-01-29 14:45:01.641 | INFO     | __main__:main_worker:355 - ---> start train epoch16
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:45:11.041 | INFO     | __main__:main_worker:429 - [16/100], remain:0d.00h.40m, It:[10/54], Max-Mem:11247M, Data-Time:1.307, LR:0.0001, Train_Loss:0.2529, total_loss:tensor([0.2529], device='cuda:0'), ce_loss:0.6172837018966675, cluster_loss:0.10772969573736191, sep_loss:0.059368036687374115, soft_orth_loss:0.004859394393861294, local_consistency_loss:0.0006678298232145607, proto_loss:0.17262494564056396
2026-01-29 14:45:14.556 | INFO     | __main__:main_worker:429 - [16/100], remain:0d.00h.33m, It:[20/54], Max-Mem:11247M, Data-Time:0.167, LR:0.0001, Train_Loss:0.0958, total_loss:tensor([0.0958], device='cuda:0'), ce_loss:0.5226390361785889, cluster_loss:0.0888243317604065, sep_loss:0.06766360998153687, soft_orth_loss:0.0048502786085009575, local_consistency_loss:0.0010706953471526504, proto_loss:0.16240891814231873
2026-01-29 14:45:19.395 | INFO     | __main__:main_worker:429 - [16/100], remain:0d.00h.34m, It:[30/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:0.4417, total_loss:tensor([0.4417], device='cuda:0'), ce_loss:0.7209292650222778, cluster_loss:0.11886878311634064, sep_loss:0.0692809522151947, soft_orth_loss:0.004842729307711124, local_consistency_loss:0.0008678011945448816, proto_loss:0.19386026263237
2026-01-29 14:45:24.038 | INFO     | __main__:main_worker:429 - [16/100], remain:0d.00h.34m, It:[40/54], Max-Mem:11247M, Data-Time:0.597, LR:0.0001, Train_Loss:-0.1398, total_loss:tensor([-0.1398], device='cuda:0'), ce_loss:0.40337416529655457, cluster_loss:0.06452460587024689, sep_loss:0.058181032538414, soft_orth_loss:0.004837621934711933, local_consistency_loss:0.0010829163948073983, proto_loss:0.12862616777420044
2026-01-29 14:45:28.371 | INFO     | __main__:main_worker:429 - [16/100], remain:0d.00h.33m, It:[50/54], Max-Mem:11247M, Data-Time:0.635, LR:0.0001, Train_Loss:0.3972, total_loss:tensor([0.3972], device='cuda:0'), ce_loss:0.7068676948547363, cluster_loss:0.11155495792627335, sep_loss:0.06368838995695114, soft_orth_loss:0.004832767881453037, local_consistency_loss:0.000733723456505686, proto_loss:0.1808098405599594
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 87.6068, acc3: 100.0000, Precision: 0.7864, Recall: 0.8467, F1-Score: 0.8110, Specificity: 0.9393
2026-01-29 14:45:37.750 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [16/100], Top1:87.607, Top3:100.000, Test_precision:0.7864,Test_recall:0.8467,Test_f1:0.8110,,Test_specificity:0.9393 Test_loss:0.356411
2026-01-29 14:45:37.751 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:45:56.896 | INFO     | __main__:main_worker:355 - ---> start train epoch17
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:46:07.226 | INFO     | __main__:main_worker:429 - [17/100], remain:0d.00h.33m, It:[10/54], Max-Mem:11247M, Data-Time:1.093, LR:0.0001, Train_Loss:0.0173, total_loss:tensor([0.0173], device='cuda:0'), ce_loss:0.48014596104621887, cluster_loss:0.09198050945997238, sep_loss:0.05658096820116043, soft_orth_loss:0.004828556440770626, local_consistency_loss:0.0008228621445596218, proto_loss:0.15421289205551147
2026-01-29 14:46:11.758 | INFO     | __main__:main_worker:429 - [17/100], remain:0d.00h.33m, It:[20/54], Max-Mem:11247M, Data-Time:1.050, LR:0.0001, Train_Loss:0.6011, total_loss:tensor([0.6011], device='cuda:0'), ce_loss:0.8257442712783813, cluster_loss:0.12267611175775528, sep_loss:0.06906377524137497, soft_orth_loss:0.004825790878385305, local_consistency_loss:0.0014447803841903806, proto_loss:0.19801045954227448
2026-01-29 14:46:16.628 | INFO     | __main__:main_worker:429 - [17/100], remain:0d.00h.34m, It:[30/54], Max-Mem:11247M, Data-Time:1.078, LR:0.0001, Train_Loss:0.2240, total_loss:tensor([0.2240], device='cuda:0'), ce_loss:0.6043069958686829, cluster_loss:0.08715559542179108, sep_loss:0.07348432391881943, soft_orth_loss:0.0048182313330471516, local_consistency_loss:0.003077251836657524, proto_loss:0.16853539645671844
2026-01-29 14:46:20.232 | INFO     | __main__:main_worker:429 - [17/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11247M, Data-Time:0.183, LR:0.0001, Train_Loss:0.1976, total_loss:tensor([0.1976], device='cuda:0'), ce_loss:0.6136585474014282, cluster_loss:0.07242417335510254, sep_loss:0.06849147379398346, soft_orth_loss:0.00481192534789443, local_consistency_loss:0.0006380471750162542, proto_loss:0.14636562764644623
2026-01-29 14:46:24.690 | INFO     | __main__:main_worker:429 - [17/100], remain:0d.00h.32m, It:[50/54], Max-Mem:11247M, Data-Time:1.088, LR:0.0001, Train_Loss:0.1303, total_loss:tensor([0.1303], device='cuda:0'), ce_loss:0.5558596253395081, cluster_loss:0.08042197674512863, sep_loss:0.07039360702037811, soft_orth_loss:0.004805111326277256, local_consistency_loss:0.0006122097256593406, proto_loss:0.15623290836811066
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
2026-01-29 14:46:34.000 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [17/100], Top1:86.111, Top3:100.000, Test_precision:0.7695,Test_recall:0.8212,Test_f1:0.7909,,Test_specificity:0.9286 Test_loss:0.430956
2026-01-29 14:46:34.001 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:46:34.002 | INFO     | __main__:main_worker:355 - ---> start train epoch18
acc1: 86.1111, acc3: 100.0000, Precision: 0.7695, Recall: 0.8212, F1-Score: 0.7909, Specificity: 0.9286
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:46:43.162 | INFO     | __main__:main_worker:429 - [18/100], remain:0d.00h.36m, It:[10/54], Max-Mem:11247M, Data-Time:0.480, LR:0.0001, Train_Loss:0.0414, total_loss:tensor([0.0414], device='cuda:0'), ce_loss:0.5134085416793823, cluster_loss:0.0734984427690506, sep_loss:0.062050607055425644, soft_orth_loss:0.004800396505743265, local_consistency_loss:0.0011979475384578109, proto_loss:0.14154739677906036
2026-01-29 14:46:47.523 | INFO     | __main__:main_worker:429 - [18/100], remain:0d.00h.34m, It:[20/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:-0.1028, total_loss:tensor([-0.1028], device='cuda:0'), ce_loss:0.4147724211215973, cluster_loss:0.07846371829509735, sep_loss:0.05785953253507614, soft_orth_loss:0.004797326400876045, local_consistency_loss:0.0006045759655535221, proto_loss:0.14172513782978058
2026-01-29 14:46:51.910 | INFO     | __main__:main_worker:429 - [18/100], remain:0d.00h.33m, It:[30/54], Max-Mem:11247M, Data-Time:0.816, LR:0.0001, Train_Loss:0.2079, total_loss:tensor([0.2079], device='cuda:0'), ce_loss:0.5985225439071655, cluster_loss:0.0855882540345192, sep_loss:0.07433523237705231, soft_orth_loss:0.004789885599166155, local_consistency_loss:0.0007319066789932549, proto_loss:0.16544528305530548
2026-01-29 14:46:56.305 | INFO     | __main__:main_worker:429 - [18/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11247M, Data-Time:0.018, LR:0.0001, Train_Loss:0.7443, total_loss:tensor([0.7443], device='cuda:0'), ce_loss:0.9194450378417969, cluster_loss:0.1126081570982933, sep_loss:0.08501094579696655, soft_orth_loss:0.004782076459378004, local_consistency_loss:0.0009104663622565567, proto_loss:0.20331165194511414
2026-01-29 14:47:01.122 | INFO     | __main__:main_worker:429 - [18/100], remain:0d.00h.33m, It:[50/54], Max-Mem:11247M, Data-Time:0.467, LR:0.0001, Train_Loss:0.1952, total_loss:tensor([0.1952], device='cuda:0'), ce_loss:0.6096628308296204, cluster_loss:0.078868068754673, sep_loss:0.06537109613418579, soft_orth_loss:0.0047782836481928825, local_consistency_loss:0.0007742907619103789, proto_loss:0.14979173243045807
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
acc1: 83.1197, acc3: 100.0000, Precision: 0.7291, Recall: 0.8301, F1-Score: 0.7535, Specificity: 0.9288
2026-01-29 14:47:10.567 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [18/100], Top1:83.120, Top3:100.000, Test_precision:0.7291,Test_recall:0.8301,Test_f1:0.7535,,Test_specificity:0.9288 Test_loss:0.494992
2026-01-29 14:47:10.568 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:47:10.569 | INFO     | __main__:main_worker:355 - ---> start train epoch19
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:47:20.286 | INFO     | __main__:main_worker:429 - [19/100], remain:0d.00h.33m, It:[10/54], Max-Mem:11247M, Data-Time:1.275, LR:0.0001, Train_Loss:-0.1022, total_loss:tensor([-0.1022], device='cuda:0'), ce_loss:0.4299340844154358, cluster_loss:0.0712769404053688, sep_loss:0.05431855842471123, soft_orth_loss:0.004771007690578699, local_consistency_loss:0.00036030792398378253, proto_loss:0.13072681427001953
2026-01-29 14:47:24.187 | INFO     | __main__:main_worker:429 - [19/100], remain:0d.00h.30m, It:[20/54], Max-Mem:11247M, Data-Time:0.512, LR:0.0001, Train_Loss:1.1191, total_loss:tensor([1.1191], device='cuda:0'), ce_loss:1.1365125179290771, cluster_loss:0.14535731077194214, sep_loss:0.08505237102508545, soft_orth_loss:0.004765672143548727, local_consistency_loss:0.0010395905701443553, proto_loss:0.23621495068073273
2026-01-29 14:47:28.949 | INFO     | __main__:main_worker:429 - [19/100], remain:0d.00h.31m, It:[30/54], Max-Mem:11247M, Data-Time:0.330, LR:0.0001, Train_Loss:0.0507, total_loss:tensor([0.0507], device='cuda:0'), ce_loss:0.5108446478843689, cluster_loss:0.07678591459989548, sep_loss:0.06808135658502579, soft_orth_loss:0.004758218303322792, local_consistency_loss:0.0008616526611149311, proto_loss:0.15048715472221375
2026-01-29 14:47:33.872 | INFO     | __main__:main_worker:429 - [19/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11247M, Data-Time:0.018, LR:0.0001, Train_Loss:1.6384, total_loss:tensor([1.6384], device='cuda:0'), ce_loss:1.4195448160171509, cluster_loss:0.20051860809326172, sep_loss:0.08912254869937897, soft_orth_loss:0.004755498841404915, local_consistency_loss:0.0012038147542625666, proto_loss:0.29560044407844543
2026-01-29 14:47:38.423 | INFO     | __main__:main_worker:429 - [19/100], remain:0d.00h.32m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.3381, total_loss:tensor([0.3381], device='cuda:0'), ce_loss:0.6722822189331055, cluster_loss:0.11026930809020996, sep_loss:0.06402852386236191, soft_orth_loss:0.004752007313072681, local_consistency_loss:0.0005918100359849632, proto_loss:0.17964166402816772
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 83.5470, acc3: 100.0000, Precision: 0.7285, Recall: 0.8041, F1-Score: 0.7495, Specificity: 0.9214
2026-01-29 14:47:48.294 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [19/100], Top1:83.547, Top3:100.000, Test_precision:0.7285,Test_recall:0.8041,Test_f1:0.7495,,Test_specificity:0.9214 Test_loss:0.468229
2026-01-29 14:47:48.295 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:47:48.295 | INFO     | __main__:main_worker:355 - ---> start train epoch20
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:47:56.522 | INFO     | __main__:main_worker:429 - [20/100], remain:0d.00h.30m, It:[10/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:0.3810, total_loss:tensor([0.3810], device='cuda:0'), ce_loss:0.7220362424850464, cluster_loss:0.08352788537740707, sep_loss:0.07435508817434311, soft_orth_loss:0.004747931379824877, local_consistency_loss:0.0008004979463294148, proto_loss:0.16343140602111816
2026-01-29 14:48:01.552 | INFO     | __main__:main_worker:429 - [20/100], remain:0d.00h.33m, It:[20/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:0.0831, total_loss:tensor([0.0831], device='cuda:0'), ce_loss:0.5177027583122253, cluster_loss:0.0915842056274414, sep_loss:0.06625586748123169, soft_orth_loss:0.004742647521197796, local_consistency_loss:0.0012802159180864692, proto_loss:0.163862943649292
2026-01-29 14:48:06.315 | INFO     | __main__:main_worker:429 - [20/100], remain:0d.00h.33m, It:[30/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:0.4292, total_loss:tensor([0.4292], device='cuda:0'), ce_loss:0.8745458722114563, cluster_loss:0.0002603681932669133, sep_loss:0.060383252799510956, soft_orth_loss:0.004738773684948683, local_consistency_loss:0.0018491771770641208, proto_loss:0.06723156571388245
2026-01-29 14:48:10.789 | INFO     | __main__:main_worker:429 - [20/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11247M, Data-Time:0.018, LR:0.0001, Train_Loss:0.4248, total_loss:tensor([0.4248], device='cuda:0'), ce_loss:0.7405409216880798, cluster_loss:0.10194563865661621, sep_loss:0.06546948850154877, soft_orth_loss:0.004735600668936968, local_consistency_loss:0.0011987853795289993, proto_loss:0.1733495146036148
2026-01-29 14:48:15.012 | INFO     | __main__:main_worker:429 - [20/100], remain:0d.00h.32m, It:[50/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:0.2398, total_loss:tensor([0.2398], device='cuda:0'), ce_loss:0.6245912313461304, cluster_loss:0.08794555813074112, sep_loss:0.07118131965398788, soft_orth_loss:0.004731288645416498, local_consistency_loss:0.0009357676026411355, proto_loss:0.1647939234972
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 14:48:25.814 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [20/100], Top1:82.479, Top3:100.000, Test_precision:0.7127,Test_recall:0.7850,Test_f1:0.7356,,Test_specificity:0.9165 Test_loss:0.503200
2026-01-29 14:48:25.817 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
acc1: 82.4786, acc3: 100.0000, Precision: 0.7127, Recall: 0.7850, F1-Score: 0.7356, Specificity: 0.9165
2026-01-29 14:48:35.237 | INFO     | __main__:main_worker:355 - ---> start train epoch21
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:48:44.529 | INFO     | __main__:main_worker:429 - [21/100], remain:0d.00h.33m, It:[10/54], Max-Mem:11247M, Data-Time:0.878, LR:0.0001, Train_Loss:1.0418, total_loss:tensor([1.0418], device='cuda:0'), ce_loss:1.1576935052871704, cluster_loss:0.08195044845342636, sep_loss:0.09042423218488693, soft_orth_loss:0.004721956327557564, local_consistency_loss:0.0015908647328615189, proto_loss:0.17868749797344208
2026-01-29 14:48:49.402 | INFO     | __main__:main_worker:429 - [21/100], remain:0d.00h.33m, It:[20/54], Max-Mem:11247M, Data-Time:1.311, LR:0.0001, Train_Loss:0.2477, total_loss:tensor([0.2477], device='cuda:0'), ce_loss:0.6277535557746887, cluster_loss:0.08285775035619736, sep_loss:0.07836584001779556, soft_orth_loss:0.004715731833130121, local_consistency_loss:0.001246201922185719, proto_loss:0.16718551516532898
2026-01-29 14:48:53.657 | INFO     | __main__:main_worker:429 - [21/100], remain:0d.00h.32m, It:[30/54], Max-Mem:11247M, Data-Time:0.808, LR:0.0001, Train_Loss:1.8229, total_loss:tensor([1.8229], device='cuda:0'), ce_loss:1.5389968156814575, cluster_loss:0.20651283860206604, sep_loss:0.09159572422504425, soft_orth_loss:0.004710059612989426, local_consistency_loss:0.0012373672798275948, proto_loss:0.30405598878860474
2026-01-29 14:48:57.428 | INFO     | __main__:main_worker:429 - [21/100], remain:0d.00h.30m, It:[40/54], Max-Mem:11247M, Data-Time:0.343, LR:0.0001, Train_Loss:0.6515, total_loss:tensor([0.6515], device='cuda:0'), ce_loss:0.8547481894493103, cluster_loss:0.12634888291358948, sep_loss:0.07612908631563187, soft_orth_loss:0.004712264519184828, local_consistency_loss:0.00084324722411111, proto_loss:0.2080334722995758
2026-01-29 14:49:01.173 | INFO     | __main__:main_worker:429 - [21/100], remain:0d.00h.29m, It:[50/54], Max-Mem:11247M, Data-Time:0.202, LR:0.0001, Train_Loss:0.3395, total_loss:tensor([0.3395], device='cuda:0'), ce_loss:0.8036606311798096, cluster_loss:0.00023201340809464455, sep_loss:0.07046191394329071, soft_orth_loss:0.004711245186626911, local_consistency_loss:0.0017859969520941377, proto_loss:0.07719116657972336
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
2026-01-29 14:49:11.053 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [21/100], Top1:86.325, Top3:100.000, Test_precision:0.7705,Test_recall:0.8251,Test_f1:0.7930,,Test_specificity:0.9289 Test_loss:0.365743
2026-01-29 14:49:11.056 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:49:11.057 | INFO     | __main__:main_worker:355 - ---> start train epoch22
acc1: 86.3248, acc3: 100.0000, Precision: 0.7705, Recall: 0.8251, F1-Score: 0.7930, Specificity: 0.9289
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:49:21.172 | INFO     | __main__:main_worker:429 - [22/100], remain:0d.00h.37m, It:[10/54], Max-Mem:11247M, Data-Time:1.995, LR:0.0001, Train_Loss:-0.2234, total_loss:tensor([-0.2234], device='cuda:0'), ce_loss:0.3529984951019287, cluster_loss:0.07782699912786484, sep_loss:0.04555417224764824, soft_orth_loss:0.004705497529357672, local_consistency_loss:0.0011704489588737488, proto_loss:0.12925711274147034
2026-01-29 14:49:25.202 | INFO     | __main__:main_worker:429 - [22/100], remain:0d.00h.32m, It:[20/54], Max-Mem:11247M, Data-Time:0.643, LR:0.0001, Train_Loss:2.5386, total_loss:tensor([2.5386], device='cuda:0'), ce_loss:1.9710208177566528, cluster_loss:0.2569887042045593, sep_loss:0.08918271958827972, soft_orth_loss:0.004702453035861254, local_consistency_loss:0.001266335602849722, proto_loss:0.3521402180194855
2026-01-29 14:49:29.862 | INFO     | __main__:main_worker:429 - [22/100], remain:0d.00h.32m, It:[30/54], Max-Mem:11247M, Data-Time:1.289, LR:0.0001, Train_Loss:0.0915, total_loss:tensor([0.0915], device='cuda:0'), ce_loss:0.5426897406578064, cluster_loss:0.07591716945171356, sep_loss:0.0694143995642662, soft_orth_loss:0.0046978602185845375, local_consistency_loss:0.0009143330389633775, proto_loss:0.15094375610351562
2026-01-29 14:49:35.433 | INFO     | __main__:main_worker:429 - [22/100], remain:0d.00h.33m, It:[40/54], Max-Mem:11247M, Data-Time:2.149, LR:0.0001, Train_Loss:-0.1370, total_loss:tensor([-0.1370], device='cuda:0'), ce_loss:0.40964359045028687, cluster_loss:0.06746382266283035, sep_loss:0.05956452712416649, soft_orth_loss:0.004693958442658186, local_consistency_loss:0.00040273703052662313, proto_loss:0.13212503492832184
2026-01-29 14:49:40.008 | INFO     | __main__:main_worker:429 - [22/100], remain:0d.00h.33m, It:[50/54], Max-Mem:11247M, Data-Time:1.211, LR:0.0001, Train_Loss:-0.2996, total_loss:tensor([-0.2996], device='cuda:0'), ce_loss:0.3008001446723938, cluster_loss:0.07459348440170288, sep_loss:0.05019098520278931, soft_orth_loss:0.004687964916229248, local_consistency_loss:0.0007048489642329514, proto_loss:0.13017728924751282
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 14:49:49.401 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [22/100], Top1:86.111, Top3:100.000, Test_precision:0.7631,Test_recall:0.8319,Test_f1:0.7890,,Test_specificity:0.9301 Test_loss:0.408876
2026-01-29 14:49:49.402 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:49:49.403 | INFO     | __main__:main_worker:355 - ---> start train epoch23
acc1: 86.1111, acc3: 100.0000, Precision: 0.7631, Recall: 0.8319, F1-Score: 0.7890, Specificity: 0.9301
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:49:57.769 | INFO     | __main__:main_worker:429 - [23/100], remain:0d.00h.26m, It:[10/54], Max-Mem:11247M, Data-Time:0.438, LR:0.0001, Train_Loss:-0.0039, total_loss:tensor([-0.0039], device='cuda:0'), ce_loss:0.470901221036911, cluster_loss:0.08532857149839401, sep_loss:0.0656801164150238, soft_orth_loss:0.004678134806454182, local_consistency_loss:0.0011825489345937967, proto_loss:0.15686938166618347
2026-01-29 14:50:02.338 | INFO     | __main__:main_worker:429 - [23/100], remain:0d.00h.28m, It:[20/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:1.8334, total_loss:tensor([1.8334], device='cuda:0'), ce_loss:1.5681570768356323, cluster_loss:0.188274547457695, sep_loss:0.093598872423172, soft_orth_loss:0.004671233706176281, local_consistency_loss:0.0012843214208260179, proto_loss:0.2878289818763733
2026-01-29 14:50:06.872 | INFO     | __main__:main_worker:429 - [23/100], remain:0d.00h.29m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.2109, total_loss:tensor([0.2109], device='cuda:0'), ce_loss:0.6170185208320618, cluster_loss:0.07948171347379684, sep_loss:0.07320048660039902, soft_orth_loss:0.004666707944124937, local_consistency_loss:0.0008955220691859722, proto_loss:0.15824441611766815
2026-01-29 14:50:11.512 | INFO     | __main__:main_worker:429 - [23/100], remain:0d.00h.29m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.6880, total_loss:tensor([0.6880], device='cuda:0'), ce_loss:0.9039367437362671, cluster_loss:0.09677916020154953, sep_loss:0.08909459412097931, soft_orth_loss:0.004661143757402897, local_consistency_loss:0.0004752757085952908, proto_loss:0.19101016223430634
2026-01-29 14:50:15.876 | INFO     | __main__:main_worker:429 - [23/100], remain:0d.00h.29m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:0.2163, total_loss:tensor([0.2163], device='cuda:0'), ce_loss:0.6225288510322571, cluster_loss:0.07362522929906845, sep_loss:0.07864706963300705, soft_orth_loss:0.004651885479688644, local_consistency_loss:0.0003615673631429672, proto_loss:0.15728574991226196
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 83.5470, acc3: 100.0000, Precision: 0.7330, Recall: 0.8299, F1-Score: 0.7616, Specificity: 0.9281
2026-01-29 14:50:27.332 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [23/100], Top1:83.547, Top3:100.000, Test_precision:0.7330,Test_recall:0.8299,Test_f1:0.7616,,Test_specificity:0.9281 Test_loss:0.572550
2026-01-29 14:50:27.333 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:50:27.333 | INFO     | __main__:main_worker:355 - ---> start train epoch24
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:50:36.984 | INFO     | __main__:main_worker:429 - [24/100], remain:0d.00h.33m, It:[10/54], Max-Mem:11247M, Data-Time:1.503, LR:0.0001, Train_Loss:0.2051, total_loss:tensor([0.2051], device='cuda:0'), ce_loss:0.6053978204727173, cluster_loss:0.09131669253110886, sep_loss:0.06886164844036102, soft_orth_loss:0.004640302620828152, local_consistency_loss:0.00042368247522972524, proto_loss:0.16524231433868408
2026-01-29 14:50:41.171 | INFO     | __main__:main_worker:429 - [24/100], remain:0d.00h.30m, It:[20/54], Max-Mem:11247M, Data-Time:0.806, LR:0.0001, Train_Loss:0.4069, total_loss:tensor([0.4069], device='cuda:0'), ce_loss:0.7292720675468445, cluster_loss:0.09224612265825272, sep_loss:0.07991454005241394, soft_orth_loss:0.004627652000635862, local_consistency_loss:0.000638440775219351, proto_loss:0.17742674052715302
2026-01-29 14:50:46.263 | INFO     | __main__:main_worker:429 - [24/100], remain:0d.00h.31m, It:[30/54], Max-Mem:11247M, Data-Time:1.566, LR:0.0001, Train_Loss:0.1576, total_loss:tensor([0.1576], device='cuda:0'), ce_loss:0.5890407562255859, cluster_loss:0.07250246405601501, sep_loss:0.07486510276794434, soft_orth_loss:0.004614048637449741, local_consistency_loss:0.0008280290639959276, proto_loss:0.15280964970588684
2026-01-29 14:50:50.754 | INFO     | __main__:main_worker:429 - [24/100], remain:0d.00h.31m, It:[40/54], Max-Mem:11247M, Data-Time:1.114, LR:0.0001, Train_Loss:0.2421, total_loss:tensor([0.2421], device='cuda:0'), ce_loss:0.7507378458976746, cluster_loss:0.00022398307919502258, sep_loss:0.0656338781118393, soft_orth_loss:0.004603845998644829, local_consistency_loss:0.00063997384859249, proto_loss:0.07110168039798737
2026-01-29 14:50:54.602 | INFO     | __main__:main_worker:429 - [24/100], remain:0d.00h.30m, It:[50/54], Max-Mem:11247M, Data-Time:0.497, LR:0.0001, Train_Loss:0.1823, total_loss:tensor([0.1823], device='cuda:0'), ce_loss:0.5836185216903687, cluster_loss:0.1078537106513977, sep_loss:0.05811191722750664, soft_orth_loss:0.004593988414853811, local_consistency_loss:0.0006025200127623975, proto_loss:0.17116212844848633
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 84.6154, acc3: 100.0000, Precision: 0.7477, Recall: 0.8435, F1-Score: 0.7781, Specificity: 0.9303
2026-01-29 14:51:04.109 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [24/100], Top1:84.615, Top3:100.000, Test_precision:0.7477,Test_recall:0.8435,Test_f1:0.7781,,Test_specificity:0.9303 Test_loss:0.432840
2026-01-29 14:51:04.110 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:51:04.110 | INFO     | __main__:main_worker:355 - ---> start train epoch25
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:51:13.960 | INFO     | __main__:main_worker:429 - [25/100], remain:0d.00h.40m, It:[10/54], Max-Mem:11247M, Data-Time:0.020, LR:0.0001, Train_Loss:0.3726, total_loss:tensor([0.3726], device='cuda:0'), ce_loss:0.6945739388465881, cluster_loss:0.11875291168689728, sep_loss:0.0628240704536438, soft_orth_loss:0.004580910783261061, local_consistency_loss:0.0012034701649099588, proto_loss:0.18736137449741364
2026-01-29 14:51:17.776 | INFO     | __main__:main_worker:429 - [25/100], remain:0d.00h.32m, It:[20/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0001, Train_Loss:0.1550, total_loss:tensor([0.1550], device='cuda:0'), ce_loss:0.5796946883201599, cluster_loss:0.09533822536468506, sep_loss:0.059308361262083054, soft_orth_loss:0.004572328645735979, local_consistency_loss:0.0006439820863306522, proto_loss:0.15986290574073792
2026-01-29 14:51:22.624 | INFO     | __main__:main_worker:429 - [25/100], remain:0d.00h.32m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:1.4334, total_loss:tensor([1.4334], device='cuda:0'), ce_loss:1.3141071796417236, cluster_loss:0.17939317226409912, sep_loss:0.09009677171707153, soft_orth_loss:0.004560894798487425, local_consistency_loss:0.0017597947735339403, proto_loss:0.2758106291294098
2026-01-29 14:51:26.610 | INFO     | __main__:main_worker:429 - [25/100], remain:0d.00h.30m, It:[40/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:0.9450, total_loss:tensor([0.9450], device='cuda:0'), ce_loss:1.0585346221923828, cluster_loss:0.1231377050280571, sep_loss:0.08335500955581665, soft_orth_loss:0.004558374173939228, local_consistency_loss:0.001035868190228939, proto_loss:0.21208696067333221
2026-01-29 14:51:31.532 | INFO     | __main__:main_worker:429 - [25/100], remain:0d.00h.31m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:2.3076, total_loss:tensor([2.3076], device='cuda:0'), ce_loss:1.8752236366271973, cluster_loss:0.20511721074581146, sep_loss:0.0981329008936882, soft_orth_loss:0.00455230800434947, local_consistency_loss:0.001381964422762394, proto_loss:0.30918437242507935
Evaluating: 100%|| 15/15 [00:08<00:00,  1.82it/s]
2026-01-29 14:51:42.872 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [25/100], Top1:80.556, Top3:100.000, Test_precision:0.7072,Test_recall:0.7912,Test_f1:0.7195,,Test_specificity:0.9103 Test_loss:0.579269
acc1: 80.5556, acc3: 100.0000, Precision: 0.7072, Recall: 0.7912, F1-Score: 0.7195, Specificity: 0.9103
2026-01-29 14:51:42.873 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:51:54.042 | INFO     | __main__:main_worker:355 - ---> start train epoch26
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:52:02.842 | INFO     | __main__:main_worker:429 - [26/100], remain:0d.00h.28m, It:[10/54], Max-Mem:11247M, Data-Time:0.832, LR:0.0001, Train_Loss:0.6012, total_loss:tensor([0.6012], device='cuda:0'), ce_loss:0.8581810593605042, cluster_loss:0.08829476684331894, sep_loss:0.09010856598615646, soft_orth_loss:0.004538404755294323, local_consistency_loss:0.0008574860403314233, proto_loss:0.18379922211170197
2026-01-29 14:52:08.532 | INFO     | __main__:main_worker:429 - [26/100], remain:0d.00h.32m, It:[20/54], Max-Mem:11247M, Data-Time:2.345, LR:0.0001, Train_Loss:1.2747, total_loss:tensor([1.2747], device='cuda:0'), ce_loss:1.220947504043579, cluster_loss:0.17454609274864197, sep_loss:0.08482164144515991, soft_orth_loss:0.004534178413450718, local_consistency_loss:0.0006156452000141144, proto_loss:0.26451757550239563
2026-01-29 14:52:12.250 | INFO     | __main__:main_worker:429 - [26/100], remain:0d.00h.29m, It:[30/54], Max-Mem:11247M, Data-Time:0.323, LR:0.0001, Train_Loss:1.9503, total_loss:tensor([1.9503], device='cuda:0'), ce_loss:1.6089518070220947, cluster_loss:0.2452448457479477, sep_loss:0.0736829936504364, soft_orth_loss:0.004528832156211138, local_consistency_loss:0.0027351451572030783, proto_loss:0.326191782951355
2026-01-29 14:52:16.533 | INFO     | __main__:main_worker:429 - [26/100], remain:0d.00h.29m, It:[40/54], Max-Mem:11247M, Data-Time:0.399, LR:0.0001, Train_Loss:1.5814, total_loss:tensor([1.5814], device='cuda:0'), ce_loss:1.4316942691802979, cluster_loss:0.17158864438533783, sep_loss:0.08637602627277374, soft_orth_loss:0.004519864451140165, local_consistency_loss:0.0030718494672328234, proto_loss:0.26555636525154114
2026-01-29 14:52:21.877 | INFO     | __main__:main_worker:429 - [26/100], remain:0d.00h.30m, It:[50/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0001, Train_Loss:0.5587, total_loss:tensor([0.5587], device='cuda:0'), ce_loss:0.8156812787055969, cluster_loss:0.11703477054834366, sep_loss:0.07260935008525848, soft_orth_loss:0.004506844095885754, local_consistency_loss:0.001089894794858992, proto_loss:0.19524087011814117
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 14:52:31.212 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [26/100], Top1:81.624, Top3:100.000, Test_precision:0.7175,Test_recall:0.8234,Test_f1:0.7447,,Test_specificity:0.9193 Test_loss:0.569493
2026-01-29 14:52:31.213 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:52:31.214 | INFO     | __main__:main_worker:355 - ---> start train epoch27
acc1: 81.6239, acc3: 100.0000, Precision: 0.7175, Recall: 0.8234, F1-Score: 0.7447, Specificity: 0.9193
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:52:41.875 | INFO     | __main__:main_worker:429 - [27/100], remain:0d.00h.33m, It:[10/54], Max-Mem:11247M, Data-Time:1.751, LR:0.0001, Train_Loss:0.6138, total_loss:tensor([0.6138], device='cuda:0'), ce_loss:0.8154683113098145, cluster_loss:0.13359807431697845, sep_loss:0.07757745683193207, soft_orth_loss:0.004494264721870422, local_consistency_loss:0.009865998290479183, proto_loss:0.2255357950925827
2026-01-29 14:52:46.136 | INFO     | __main__:main_worker:429 - [27/100], remain:0d.00h.30m, It:[20/54], Max-Mem:11247M, Data-Time:0.927, LR:0.0001, Train_Loss:0.3223, total_loss:tensor([0.3223], device='cuda:0'), ce_loss:0.6669216752052307, cluster_loss:0.09853707998991013, sep_loss:0.08108021318912506, soft_orth_loss:0.004488211590796709, local_consistency_loss:0.0003522579208947718, proto_loss:0.18445776402950287
2026-01-29 14:52:50.604 | INFO     | __main__:main_worker:429 - [27/100], remain:0d.00h.29m, It:[30/54], Max-Mem:11247M, Data-Time:1.105, LR:0.0001, Train_Loss:-0.1957, total_loss:tensor([-0.1957], device='cuda:0'), ce_loss:0.37169361114501953, cluster_loss:0.08042239397764206, sep_loss:0.04825441539287567, soft_orth_loss:0.00447952002286911, local_consistency_loss:0.0026621827855706215, proto_loss:0.1358185112476349
2026-01-29 14:52:54.388 | INFO     | __main__:main_worker:429 - [27/100], remain:0d.00h.28m, It:[40/54], Max-Mem:11247M, Data-Time:0.440, LR:0.0001, Train_Loss:0.1907, total_loss:tensor([0.1907], device='cuda:0'), ce_loss:0.5934010744094849, cluster_loss:0.1060873419046402, sep_loss:0.060569655150175095, soft_orth_loss:0.004469549283385277, local_consistency_loss:0.00027599907480180264, proto_loss:0.17140254378318787
2026-01-29 14:52:58.549 | INFO     | __main__:main_worker:429 - [27/100], remain:0d.00h.28m, It:[50/54], Max-Mem:11247M, Data-Time:0.819, LR:0.0001, Train_Loss:0.1740, total_loss:tensor([0.1740], device='cuda:0'), ce_loss:0.603004515171051, cluster_loss:0.08923646062612534, sep_loss:0.0608949176967144, soft_orth_loss:0.004462436307221651, local_consistency_loss:0.0004881984496023506, proto_loss:0.15508200228214264
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
acc1: 85.0427, acc3: 100.0000, Precision: 0.7499, Recall: 0.8356, F1-Score: 0.7775, Specificity: 0.9295
2026-01-29 14:53:07.888 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [27/100], Top1:85.043, Top3:100.000, Test_precision:0.7499,Test_recall:0.8356,Test_f1:0.7775,,Test_specificity:0.9295 Test_loss:0.421273
2026-01-29 14:53:07.889 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:53:07.890 | INFO     | __main__:main_worker:355 - ---> start train epoch28
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:53:16.770 | INFO     | __main__:main_worker:429 - [28/100], remain:0d.00h.33m, It:[10/54], Max-Mem:11247M, Data-Time:0.970, LR:0.0001, Train_Loss:0.1045, total_loss:tensor([0.1045], device='cuda:0'), ce_loss:0.5508854985237122, cluster_loss:0.08995325118303299, sep_loss:0.06375309824943542, soft_orth_loss:0.004452813416719437, local_consistency_loss:0.0003744052373804152, proto_loss:0.15853355824947357
2026-01-29 14:53:21.593 | INFO     | __main__:main_worker:429 - [28/100], remain:0d.00h.32m, It:[20/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:-0.0112, total_loss:tensor([-0.0112], device='cuda:0'), ce_loss:0.4779285788536072, cluster_loss:0.08793170005083084, sep_loss:0.06029147654771805, soft_orth_loss:0.004444146528840065, local_consistency_loss:0.0006857385160401464, proto_loss:0.15335306525230408
2026-01-29 14:53:26.568 | INFO     | __main__:main_worker:429 - [28/100], remain:0d.00h.31m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:-0.2116, total_loss:tensor([-0.2116], device='cuda:0'), ce_loss:0.3706945776939392, cluster_loss:0.0726916491985321, sep_loss:0.05163947865366936, soft_orth_loss:0.004437791649252176, local_consistency_loss:0.0004363790212664753, proto_loss:0.12920530140399933
2026-01-29 14:53:32.153 | INFO     | __main__:main_worker:429 - [28/100], remain:0d.00h.32m, It:[40/54], Max-Mem:11247M, Data-Time:0.017, LR:0.0001, Train_Loss:0.4669, total_loss:tensor([0.4669], device='cuda:0'), ce_loss:0.7632693648338318, cluster_loss:0.10908885300159454, sep_loss:0.07441577315330505, soft_orth_loss:0.004428819287568331, local_consistency_loss:0.0006415837560780346, proto_loss:0.18857502937316895
2026-01-29 14:53:36.492 | INFO     | __main__:main_worker:429 - [28/100], remain:0d.00h.31m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:0.9963, total_loss:tensor([0.9963], device='cuda:0'), ce_loss:1.0928542613983154, cluster_loss:0.12460483610630035, sep_loss:0.08727709949016571, soft_orth_loss:0.0044166999869048595, local_consistency_loss:0.0005604433827102184, proto_loss:0.21685908734798431
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
acc1: 85.0427, acc3: 100.0000, Precision: 0.7473, Recall: 0.8119, F1-Score: 0.7706, Specificity: 0.9239
2026-01-29 14:53:46.945 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [28/100], Top1:85.043, Top3:100.000, Test_precision:0.7473,Test_recall:0.8119,Test_f1:0.7706,,Test_specificity:0.9239 Test_loss:0.479186
2026-01-29 14:53:46.946 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:53:46.947 | INFO     | __main__:main_worker:355 - ---> start train epoch29
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:53:58.320 | INFO     | __main__:main_worker:429 - [29/100], remain:0d.00h.35m, It:[10/54], Max-Mem:11247M, Data-Time:2.150, LR:0.0001, Train_Loss:-0.0314, total_loss:tensor([-0.0314], device='cuda:0'), ce_loss:0.47053825855255127, cluster_loss:0.07935640960931778, sep_loss:0.06478956341743469, soft_orth_loss:0.004402552265673876, local_consistency_loss:0.0005862962570972741, proto_loss:0.1491348147392273
2026-01-29 14:54:02.071 | INFO     | __main__:main_worker:429 - [29/100], remain:0d.00h.29m, It:[20/54], Max-Mem:11247M, Data-Time:0.376, LR:0.0001, Train_Loss:0.2329, total_loss:tensor([0.2329], device='cuda:0'), ce_loss:0.6438215970993042, cluster_loss:0.08404392004013062, sep_loss:0.0669441819190979, soft_orth_loss:0.004392688628286123, local_consistency_loss:0.0011523569701239467, proto_loss:0.1565331369638443
2026-01-29 14:54:06.496 | INFO     | __main__:main_worker:429 - [29/100], remain:0d.00h.28m, It:[30/54], Max-Mem:11247M, Data-Time:0.804, LR:0.0001, Train_Loss:2.4197, total_loss:tensor([2.4197], device='cuda:0'), ce_loss:1.8970550298690796, cluster_loss:0.2599465548992157, sep_loss:0.09136281907558441, soft_orth_loss:0.0043822056613862514, local_consistency_loss:0.0010036695748567581, proto_loss:0.3566952347755432
2026-01-29 14:54:11.159 | INFO     | __main__:main_worker:429 - [29/100], remain:0d.00h.28m, It:[40/54], Max-Mem:11247M, Data-Time:1.334, LR:0.0001, Train_Loss:0.1368, total_loss:tensor([0.1368], device='cuda:0'), ce_loss:0.5686399340629578, cluster_loss:0.08387632668018341, sep_loss:0.07493414729833603, soft_orth_loss:0.004373404663056135, local_consistency_loss:0.0006027573253959417, proto_loss:0.1637866199016571
2026-01-29 14:54:16.261 | INFO     | __main__:main_worker:429 - [29/100], remain:0d.00h.29m, It:[50/54], Max-Mem:11247M, Data-Time:1.738, LR:0.0001, Train_Loss:0.6804, total_loss:tensor([0.6804], device='cuda:0'), ce_loss:0.8881153464317322, cluster_loss:0.12565578520298004, sep_loss:0.07682781666517258, soft_orth_loss:0.004362847656011581, local_consistency_loss:0.0007821204490028322, proto_loss:0.20762856304645538
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 86.3248, acc3: 100.0000, Precision: 0.7814, Recall: 0.8275, F1-Score: 0.8012, Specificity: 0.9228
2026-01-29 14:54:25.611 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [29/100], Top1:86.325, Top3:100.000, Test_precision:0.7814,Test_recall:0.8275,Test_f1:0.8012,,Test_specificity:0.9228 Test_loss:0.439085
2026-01-29 14:54:25.613 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:54:25.614 | INFO     | __main__:main_worker:355 - ---> start train epoch30
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:54:34.293 | INFO     | __main__:main_worker:429 - [30/100], remain:0d.00h.27m, It:[10/54], Max-Mem:11247M, Data-Time:0.099, LR:0.0001, Train_Loss:0.9700, total_loss:tensor([0.9700], device='cuda:0'), ce_loss:1.0438108444213867, cluster_loss:0.15244455635547638, sep_loss:0.08387373387813568, soft_orth_loss:0.004346259403973818, local_consistency_loss:0.0017119098920375109, proto_loss:0.24237646162509918
2026-01-29 14:54:38.379 | INFO     | __main__:main_worker:429 - [30/100], remain:0d.00h.26m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:1.8226, total_loss:tensor([1.8226], device='cuda:0'), ce_loss:1.5611075162887573, cluster_loss:0.2054724544286728, sep_loss:0.08705422282218933, soft_orth_loss:0.004335072357207537, local_consistency_loss:0.0014517281670123339, proto_loss:0.2983134686946869
2026-01-29 14:54:42.704 | INFO     | __main__:main_worker:429 - [30/100], remain:0d.00h.26m, It:[30/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:1.0608, total_loss:tensor([1.0608], device='cuda:0'), ce_loss:1.0580343008041382, cluster_loss:0.15657711029052734, sep_loss:0.080522820353508, soft_orth_loss:0.004325553774833679, local_consistency_loss:0.03900247439742088, proto_loss:0.2804279625415802
2026-01-29 14:54:47.246 | INFO     | __main__:main_worker:429 - [30/100], remain:0d.00h.26m, It:[40/54], Max-Mem:11247M, Data-Time:0.762, LR:0.0001, Train_Loss:-0.1971, total_loss:tensor([-0.1971], device='cuda:0'), ce_loss:0.3744615614414215, cluster_loss:0.07298579066991806, sep_loss:0.05894836038351059, soft_orth_loss:0.004312468692660332, local_consistency_loss:0.00046000126167200506, proto_loss:0.1367066204547882
2026-01-29 14:54:51.801 | INFO     | __main__:main_worker:429 - [30/100], remain:0d.00h.27m, It:[50/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0001, Train_Loss:-0.0158, total_loss:tensor([-0.0158], device='cuda:0'), ce_loss:0.47320079803466797, cluster_loss:0.08759186416864395, sep_loss:0.0651492029428482, soft_orth_loss:0.004300709348171949, local_consistency_loss:0.00041544140549376607, proto_loss:0.15745723247528076
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 14:55:01.263 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [30/100], Top1:86.325, Top3:100.000, Test_precision:0.7677,Test_recall:0.8284,Test_f1:0.7919,,Test_specificity:0.9338 Test_loss:0.429491
2026-01-29 14:55:01.264 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
acc1: 86.3248, acc3: 100.0000, Precision: 0.7677, Recall: 0.8284, F1-Score: 0.7919, Specificity: 0.9338
2026-01-29 14:55:10.624 | INFO     | __main__:main_worker:355 - ---> start train epoch31
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:55:20.033 | INFO     | __main__:main_worker:429 - [31/100], remain:0d.00h.28m, It:[10/54], Max-Mem:11247M, Data-Time:0.688, LR:0.0001, Train_Loss:0.3060, total_loss:tensor([0.3060], device='cuda:0'), ce_loss:0.6694292426109314, cluster_loss:0.10538902133703232, sep_loss:0.06780239194631577, soft_orth_loss:0.004286803770810366, local_consistency_loss:0.0005416263011284173, proto_loss:0.17801985144615173
2026-01-29 14:55:24.671 | INFO     | __main__:main_worker:429 - [31/100], remain:0d.00h.28m, It:[20/54], Max-Mem:11247M, Data-Time:0.904, LR:0.0001, Train_Loss:0.0663, total_loss:tensor([0.0663], device='cuda:0'), ce_loss:0.5530827045440674, cluster_loss:0.07995522022247314, sep_loss:0.05528026446700096, soft_orth_loss:0.004277402069419622, local_consistency_loss:0.0005497261881828308, proto_loss:0.1400626301765442
2026-01-29 14:55:29.001 | INFO     | __main__:main_worker:429 - [31/100], remain:0d.00h.27m, It:[30/54], Max-Mem:11247M, Data-Time:0.926, LR:0.0001, Train_Loss:0.0237, total_loss:tensor([0.0237], device='cuda:0'), ce_loss:0.5115310549736023, cluster_loss:0.08181833475828171, sep_loss:0.0629705861210823, soft_orth_loss:0.004266474861651659, local_consistency_loss:0.0006196729955263436, proto_loss:0.14967507123947144
2026-01-29 14:55:33.347 | INFO     | __main__:main_worker:429 - [31/100], remain:0d.00h.27m, It:[40/54], Max-Mem:11247M, Data-Time:0.017, LR:0.0001, Train_Loss:0.2689, total_loss:tensor([0.2689], device='cuda:0'), ce_loss:0.6437448859214783, cluster_loss:0.10496445000171661, sep_loss:0.06905597448348999, soft_orth_loss:0.004257372580468655, local_consistency_loss:0.00040643601096235216, proto_loss:0.17868421971797943
2026-01-29 14:55:37.881 | INFO     | __main__:main_worker:429 - [31/100], remain:0d.00h.27m, It:[50/54], Max-Mem:11247M, Data-Time:0.446, LR:0.0001, Train_Loss:2.0571, total_loss:tensor([2.0571], device='cuda:0'), ce_loss:1.7102643251419067, cluster_loss:0.21680741012096405, sep_loss:0.08769723773002625, soft_orth_loss:0.004248307552188635, local_consistency_loss:0.0011850281152874231, proto_loss:0.309937983751297
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 14:55:47.781 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [31/100], Top1:86.966, Top3:100.000, Test_precision:0.7808,Test_recall:0.8526,Test_f1:0.8090,,Test_specificity:0.9368 Test_loss:0.391463
2026-01-29 14:55:47.781 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:55:47.782 | INFO     | __main__:main_worker:355 - ---> start train epoch32
acc1: 86.9658, acc3: 100.0000, Precision: 0.7808, Recall: 0.8526, F1-Score: 0.8090, Specificity: 0.9368
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:55:57.541 | INFO     | __main__:main_worker:429 - [32/100], remain:0d.00h.29m, It:[10/54], Max-Mem:11247M, Data-Time:1.315, LR:0.0001, Train_Loss:2.2481, total_loss:tensor([2.2481], device='cuda:0'), ce_loss:1.8245044946670532, cluster_loss:0.22468212246894836, sep_loss:0.09376468509435654, soft_orth_loss:0.004235655535012484, local_consistency_loss:0.0013036394957453012, proto_loss:0.32398611307144165
2026-01-29 14:56:01.977 | INFO     | __main__:main_worker:429 - [32/100], remain:0d.00h.28m, It:[20/54], Max-Mem:11247M, Data-Time:0.678, LR:0.0001, Train_Loss:0.0395, total_loss:tensor([0.0395], device='cuda:0'), ce_loss:0.5308671593666077, cluster_loss:0.07070305198431015, sep_loss:0.06847894936800003, soft_orth_loss:0.004225720651447773, local_consistency_loss:0.0005479800747707486, proto_loss:0.14395569264888763
2026-01-29 14:56:06.480 | INFO     | __main__:main_worker:429 - [32/100], remain:0d.00h.27m, It:[30/54], Max-Mem:11247M, Data-Time:1.066, LR:0.0001, Train_Loss:0.0889, total_loss:tensor([0.0889], device='cuda:0'), ce_loss:0.5836483836174011, cluster_loss:0.05435490235686302, sep_loss:0.07039179652929306, soft_orth_loss:0.004214102402329445, local_consistency_loss:0.0008849928271956742, proto_loss:0.12984579801559448
2026-01-29 14:56:10.841 | INFO     | __main__:main_worker:429 - [32/100], remain:0d.00h.27m, It:[40/54], Max-Mem:11247M, Data-Time:0.503, LR:0.0001, Train_Loss:1.6455, total_loss:tensor([1.6455], device='cuda:0'), ce_loss:1.4601491689682007, cluster_loss:0.19047947227954865, sep_loss:0.08816796541213989, soft_orth_loss:0.004202117677778006, local_consistency_loss:0.0015526972711086273, proto_loss:0.2844022512435913
2026-01-29 14:56:15.739 | INFO     | __main__:main_worker:429 - [32/100], remain:0d.00h.27m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.9952, total_loss:tensor([0.9952], device='cuda:0'), ce_loss:1.0457016229629517, cluster_loss:0.1649027317762375, sep_loss:0.08782794326543808, soft_orth_loss:0.004191022831946611, local_consistency_loss:0.00034632632741704583, proto_loss:0.2572680115699768
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
2026-01-29 14:56:25.535 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [32/100], Top1:85.897, Top3:100.000, Test_precision:0.7639,Test_recall:0.8294,Test_f1:0.7896,,Test_specificity:0.9294 Test_loss:0.409491
2026-01-29 14:56:25.536 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:56:25.537 | INFO     | __main__:main_worker:355 - ---> start train epoch33
acc1: 85.8974, acc3: 100.0000, Precision: 0.7639, Recall: 0.8294, F1-Score: 0.7896, Specificity: 0.9294
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:56:34.282 | INFO     | __main__:main_worker:429 - [33/100], remain:0d.00h.31m, It:[10/54], Max-Mem:11247M, Data-Time:0.797, LR:0.0001, Train_Loss:0.0755, total_loss:tensor([0.0755], device='cuda:0'), ce_loss:0.5523058772087097, cluster_loss:0.07373335212469101, sep_loss:0.06926998496055603, soft_orth_loss:0.00417400524020195, local_consistency_loss:0.0003779130056500435, proto_loss:0.14755526185035706
2026-01-29 14:56:38.817 | INFO     | __main__:main_worker:429 - [33/100], remain:0d.00h.29m, It:[20/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0001, Train_Loss:2.1401, total_loss:tensor([2.1401], device='cuda:0'), ce_loss:1.754339575767517, cluster_loss:0.22603051364421844, sep_loss:0.08994929492473602, soft_orth_loss:0.004161398392170668, local_consistency_loss:0.0018177395686507225, proto_loss:0.3219589293003082
2026-01-29 14:56:44.031 | INFO     | __main__:main_worker:429 - [33/100], remain:0d.00h.29m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.9882, total_loss:tensor([0.9882], device='cuda:0'), ce_loss:1.080127477645874, cluster_loss:0.14106400310993195, sep_loss:0.0818835198879242, soft_orth_loss:0.00414972472935915, local_consistency_loss:0.0006236475892364979, proto_loss:0.22772088646888733
2026-01-29 14:56:48.025 | INFO     | __main__:main_worker:429 - [33/100], remain:0d.00h.28m, It:[40/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0001, Train_Loss:0.1644, total_loss:tensor([0.1644], device='cuda:0'), ce_loss:0.5950153470039368, cluster_loss:0.09118608385324478, sep_loss:0.06677763164043427, soft_orth_loss:0.004137774463742971, local_consistency_loss:0.0004310412332415581, proto_loss:0.16253253817558289
2026-01-29 14:56:52.331 | INFO     | __main__:main_worker:429 - [33/100], remain:0d.00h.27m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:-0.1769, total_loss:tensor([-0.1769], device='cuda:0'), ce_loss:0.392762690782547, cluster_loss:0.07485555857419968, sep_loss:0.05741816759109497, soft_orth_loss:0.0041233450174331665, local_consistency_loss:0.0003318584931548685, proto_loss:0.1367289423942566
Evaluating: 100%|| 15/15 [00:07<00:00,  1.90it/s]
acc1: 85.4701, acc3: 100.0000, Precision: 0.7750, Recall: 0.7562, F1-Score: 0.7641, Specificity: 0.9069
2026-01-29 14:57:02.405 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [33/100], Top1:85.470, Top3:100.000, Test_precision:0.7750,Test_recall:0.7562,Test_f1:0.7641,,Test_specificity:0.9069 Test_loss:0.396425
2026-01-29 14:57:02.406 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:57:02.407 | INFO     | __main__:main_worker:355 - ---> start train epoch34
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:57:10.520 | INFO     | __main__:main_worker:429 - [34/100], remain:0d.00h.23m, It:[10/54], Max-Mem:11247M, Data-Time:0.061, LR:0.0001, Train_Loss:0.5254, total_loss:tensor([0.5254], device='cuda:0'), ce_loss:0.812955379486084, cluster_loss:0.11144757270812988, sep_loss:0.0710621029138565, soft_orth_loss:0.004108875524252653, local_consistency_loss:0.000971761648543179, proto_loss:0.1875903159379959
2026-01-29 14:57:15.237 | INFO     | __main__:main_worker:429 - [34/100], remain:0d.00h.25m, It:[20/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:0.2234, total_loss:tensor([0.2234], device='cuda:0'), ce_loss:0.6342822313308716, cluster_loss:0.08997174352407455, sep_loss:0.06990429759025574, soft_orth_loss:0.004097940865904093, local_consistency_loss:0.0005101689603179693, proto_loss:0.1644841581583023
2026-01-29 14:57:19.955 | INFO     | __main__:main_worker:429 - [34/100], remain:0d.00h.26m, It:[30/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:0.4169, total_loss:tensor([0.4169], device='cuda:0'), ce_loss:0.7388948202133179, cluster_loss:0.10736503452062607, sep_loss:0.07525723427534103, soft_orth_loss:0.004084229469299316, local_consistency_loss:0.0004158043011557311, proto_loss:0.18712230026721954
2026-01-29 14:57:24.544 | INFO     | __main__:main_worker:429 - [34/100], remain:0d.00h.26m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:0.1557, total_loss:tensor([0.1557], device='cuda:0'), ce_loss:0.5942050814628601, cluster_loss:0.08723020553588867, sep_loss:0.06784425675868988, soft_orth_loss:0.004069933667778969, local_consistency_loss:0.0005379085778258741, proto_loss:0.15968230366706848
2026-01-29 14:57:29.106 | INFO     | __main__:main_worker:429 - [34/100], remain:0d.00h.26m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.2900, total_loss:tensor([0.2900], device='cuda:0'), ce_loss:0.6717576384544373, cluster_loss:0.0974249392747879, sep_loss:0.06955264508724213, soft_orth_loss:0.004056854173541069, local_consistency_loss:0.0007053699227981269, proto_loss:0.17173981666564941
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 85.6838, acc3: 100.0000, Precision: 0.7581, Recall: 0.7782, F1-Score: 0.7675, Specificity: 0.9179
2026-01-29 14:57:38.780 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [34/100], Top1:85.684, Top3:100.000, Test_precision:0.7581,Test_recall:0.7782,Test_f1:0.7675,,Test_specificity:0.9179 Test_loss:0.388892
2026-01-29 14:57:38.781 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:57:38.782 | INFO     | __main__:main_worker:355 - ---> start train epoch35
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:57:48.826 | INFO     | __main__:main_worker:429 - [35/100], remain:0d.00h.30m, It:[10/54], Max-Mem:11247M, Data-Time:1.765, LR:0.0001, Train_Loss:-0.0453, total_loss:tensor([-0.0453], device='cuda:0'), ce_loss:0.48251208662986755, cluster_loss:0.08287479728460312, sep_loss:0.051477059721946716, soft_orth_loss:0.004041552077978849, local_consistency_loss:0.0007165367132984102, proto_loss:0.13910993933677673
2026-01-29 14:57:52.369 | INFO     | __main__:main_worker:429 - [35/100], remain:0d.00h.25m, It:[20/54], Max-Mem:11247M, Data-Time:0.120, LR:0.0001, Train_Loss:0.2718, total_loss:tensor([0.2718], device='cuda:0'), ce_loss:0.6671680212020874, cluster_loss:0.089054174721241, sep_loss:0.07122382521629333, soft_orth_loss:0.004028813913464546, local_consistency_loss:0.0017557822866365314, proto_loss:0.166062593460083
2026-01-29 14:57:56.969 | INFO     | __main__:main_worker:429 - [35/100], remain:0d.00h.25m, It:[30/54], Max-Mem:11247M, Data-Time:1.114, LR:0.0001, Train_Loss:1.8513, total_loss:tensor([1.8513], device='cuda:0'), ce_loss:1.5860947370529175, cluster_loss:0.20525775849819183, sep_loss:0.0884956642985344, soft_orth_loss:0.004016264341771603, local_consistency_loss:0.00196936191059649, proto_loss:0.2997390329837799
2026-01-29 14:58:01.673 | INFO     | __main__:main_worker:429 - [35/100], remain:0d.00h.26m, It:[40/54], Max-Mem:11247M, Data-Time:1.261, LR:0.0001, Train_Loss:-0.0465, total_loss:tensor([-0.0465], device='cuda:0'), ce_loss:0.47224900126457214, cluster_loss:0.08121942728757858, sep_loss:0.06122088432312012, soft_orth_loss:0.004002891480922699, local_consistency_loss:0.000507100485265255, proto_loss:0.14695031940937042
2026-01-29 14:58:05.666 | INFO     | __main__:main_worker:429 - [35/100], remain:0d.00h.25m, It:[50/54], Max-Mem:11247M, Data-Time:0.544, LR:0.0001, Train_Loss:0.4517, total_loss:tensor([0.4517], device='cuda:0'), ce_loss:0.7486560344696045, cluster_loss:0.12142660468816757, sep_loss:0.07358658313751221, soft_orth_loss:0.003988602664321661, local_consistency_loss:0.0004827857483178377, proto_loss:0.19948458671569824
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 84.8291, acc3: 100.0000, Precision: 0.7469, Recall: 0.8131, F1-Score: 0.7721, Specificity: 0.9258
2026-01-29 14:58:15.082 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [35/100], Top1:84.829, Top3:100.000, Test_precision:0.7469,Test_recall:0.8131,Test_f1:0.7721,,Test_specificity:0.9258 Test_loss:0.450725
2026-01-29 14:58:15.084 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:58:25.208 | INFO     | __main__:main_worker:355 - ---> start train epoch36
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:58:35.243 | INFO     | __main__:main_worker:429 - [36/100], remain:0d.00h.29m, It:[10/54], Max-Mem:11247M, Data-Time:1.751, LR:0.0001, Train_Loss:0.1501, total_loss:tensor([0.1501], device='cuda:0'), ce_loss:0.570862352848053, cluster_loss:0.10449448972940445, sep_loss:0.06731873005628586, soft_orth_loss:0.0039734188467264175, local_consistency_loss:0.0002211196842836216, proto_loss:0.17600776255130768
2026-01-29 14:58:39.780 | INFO     | __main__:main_worker:429 - [36/100], remain:0d.00h.27m, It:[20/54], Max-Mem:11247M, Data-Time:1.125, LR:0.0001, Train_Loss:0.2739, total_loss:tensor([0.2739], device='cuda:0'), ce_loss:0.6652854681015015, cluster_loss:0.09067554771900177, sep_loss:0.0745016485452652, soft_orth_loss:0.003957397770136595, local_consistency_loss:0.0005810837610624731, proto_loss:0.16971567273139954
2026-01-29 14:58:43.370 | INFO     | __main__:main_worker:429 - [36/100], remain:0d.00h.25m, It:[30/54], Max-Mem:11247M, Data-Time:0.018, LR:0.0001, Train_Loss:0.6191, total_loss:tensor([0.6191], device='cuda:0'), ce_loss:0.8616138100624084, cluster_loss:0.12440075725317001, sep_loss:0.07371079921722412, soft_orth_loss:0.003940182738006115, local_consistency_loss:0.0004550850426312536, proto_loss:0.20250682532787323
2026-01-29 14:58:47.523 | INFO     | __main__:main_worker:429 - [36/100], remain:0d.00h.24m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:0.1262, total_loss:tensor([0.1262], device='cuda:0'), ce_loss:0.6075842380523682, cluster_loss:0.061275970190763474, sep_loss:0.0704943835735321, soft_orth_loss:0.00392546784132719, local_consistency_loss:0.0005287416279315948, proto_loss:0.13622456789016724
2026-01-29 14:58:52.480 | INFO     | __main__:main_worker:429 - [36/100], remain:0d.00h.25m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.0643, total_loss:tensor([0.0643], device='cuda:0'), ce_loss:0.5385772585868835, cluster_loss:0.08394384384155273, sep_loss:0.06780798733234406, soft_orth_loss:0.003912078682333231, local_consistency_loss:0.0005473162163980305, proto_loss:0.1562112271785736
Evaluating: 100%|| 15/15 [00:07<00:00,  1.89it/s]
2026-01-29 14:59:02.359 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [36/100], Top1:84.615, Top3:100.000, Test_precision:0.7478,Test_recall:0.8523,Test_f1:0.7785,,Test_specificity:0.9338 Test_loss:0.468410
2026-01-29 14:59:02.360 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:59:02.361 | INFO     | __main__:main_worker:355 - ---> start train epoch37
acc1: 84.6154, acc3: 100.0000, Precision: 0.7478, Recall: 0.8523, F1-Score: 0.7785, Specificity: 0.9338
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:59:11.417 | INFO     | __main__:main_worker:429 - [37/100], remain:0d.00h.25m, It:[10/54], Max-Mem:11247M, Data-Time:0.660, LR:0.0001, Train_Loss:0.2433, total_loss:tensor([0.2433], device='cuda:0'), ce_loss:0.6602047681808472, cluster_loss:0.088544562458992, sep_loss:0.0650390237569809, soft_orth_loss:0.0038937341887503862, local_consistency_loss:0.0008640101295895875, proto_loss:0.15834133327007294
2026-01-29 14:59:15.447 | INFO     | __main__:main_worker:429 - [37/100], remain:0d.00h.23m, It:[20/54], Max-Mem:11247M, Data-Time:0.651, LR:0.0001, Train_Loss:0.1192, total_loss:tensor([0.1192], device='cuda:0'), ce_loss:0.555469274520874, cluster_loss:0.10253097116947174, sep_loss:0.0657963976264, soft_orth_loss:0.0038778085727244616, local_consistency_loss:0.00046264362754300237, proto_loss:0.17266780138015747
2026-01-29 14:59:19.543 | INFO     | __main__:main_worker:429 - [37/100], remain:0d.00h.23m, It:[30/54], Max-Mem:11247M, Data-Time:0.492, LR:0.0001, Train_Loss:1.4701, total_loss:tensor([1.4701], device='cuda:0'), ce_loss:1.3669235706329346, cluster_loss:0.17997311055660248, sep_loss:0.07952161878347397, soft_orth_loss:0.0038644548039883375, local_consistency_loss:0.004085329361259937, proto_loss:0.26744452118873596
2026-01-29 14:59:24.422 | INFO     | __main__:main_worker:429 - [37/100], remain:0d.00h.24m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:2.0976, total_loss:tensor([2.0976], device='cuda:0'), ce_loss:1.6687819957733154, cluster_loss:0.2753593325614929, sep_loss:0.08752274513244629, soft_orth_loss:0.003852951107546687, local_consistency_loss:0.0016374202677980065, proto_loss:0.36837247014045715
2026-01-29 14:59:29.503 | INFO     | __main__:main_worker:429 - [37/100], remain:0d.00h.25m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.4630, total_loss:tensor([0.4630], device='cuda:0'), ce_loss:0.7756854295730591, cluster_loss:0.10176955908536911, sep_loss:0.08074110746383667, soft_orth_loss:0.0038402306381613016, local_consistency_loss:0.000516447820700705, proto_loss:0.186867356300354
Evaluating: 100%|| 15/15 [00:07<00:00,  1.89it/s]
2026-01-29 14:59:38.795 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [37/100], Top1:84.829, Top3:100.000, Test_precision:0.7704,Test_recall:0.7426,Test_f1:0.7540,,Test_specificity:0.9018 Test_loss:0.415203
2026-01-29 14:59:38.796 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 14:59:38.797 | INFO     | __main__:main_worker:355 - ---> start train epoch38
acc1: 84.8291, acc3: 100.0000, Precision: 0.7704, Recall: 0.7426, F1-Score: 0.7540, Specificity: 0.9018
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 14:59:47.612 | INFO     | __main__:main_worker:429 - [38/100], remain:0d.00h.27m, It:[10/54], Max-Mem:11247M, Data-Time:0.840, LR:0.0001, Train_Loss:0.0964, total_loss:tensor([0.0964], device='cuda:0'), ce_loss:0.5713800191879272, cluster_loss:0.08046602457761765, sep_loss:0.06451403349637985, soft_orth_loss:0.0038261699955910444, local_consistency_loss:0.0006260016816668212, proto_loss:0.1494322270154953
2026-01-29 14:59:51.867 | INFO     | __main__:main_worker:429 - [38/100], remain:0d.00h.25m, It:[20/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.0383, total_loss:tensor([0.0383], device='cuda:0'), ce_loss:0.5349416136741638, cluster_loss:0.07883906364440918, sep_loss:0.06350159645080566, soft_orth_loss:0.0038118225056678057, local_consistency_loss:0.0005772947333753109, proto_loss:0.14672978222370148
2026-01-29 14:59:56.522 | INFO     | __main__:main_worker:429 - [38/100], remain:0d.00h.25m, It:[30/54], Max-Mem:11247M, Data-Time:1.048, LR:0.0001, Train_Loss:-0.1722, total_loss:tensor([-0.1722], device='cuda:0'), ce_loss:0.419694721698761, cluster_loss:0.059245843440294266, sep_loss:0.06014300510287285, soft_orth_loss:0.003798637306317687, local_consistency_loss:0.0004977419157512486, proto_loss:0.12368522584438324
2026-01-29 15:00:00.593 | INFO     | __main__:main_worker:429 - [38/100], remain:0d.00h.24m, It:[40/54], Max-Mem:11247M, Data-Time:0.459, LR:0.0001, Train_Loss:0.0826, total_loss:tensor([0.0826], device='cuda:0'), ce_loss:0.6614391803741455, cluster_loss:0.00020912836771458387, sep_loss:0.06987346708774567, soft_orth_loss:0.0037825487088412046, local_consistency_loss:0.001112911500968039, proto_loss:0.0749780535697937
2026-01-29 15:00:05.888 | INFO     | __main__:main_worker:429 - [38/100], remain:0d.00h.25m, It:[50/54], Max-Mem:11247M, Data-Time:1.315, LR:0.0001, Train_Loss:-0.0730, total_loss:tensor([-0.0730], device='cuda:0'), ce_loss:0.4655686318874359, cluster_loss:0.07302810996770859, sep_loss:0.06421918421983719, soft_orth_loss:0.00376923312433064, local_consistency_loss:0.00036105027538724244, proto_loss:0.14137758314609528
Evaluating: 100%|| 15/15 [00:08<00:00,  1.76it/s]
2026-01-29 15:00:15.697 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [38/100], Top1:83.547, Top3:100.000, Test_precision:0.7213,Test_recall:0.7851,Test_f1:0.7401,,Test_specificity:0.9210 Test_loss:0.465582
2026-01-29 15:00:15.698 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [16/100], Top1:87.607, Top-3:100.000
2026-01-29 15:00:15.699 | INFO     | __main__:main_worker:355 - ---> start train epoch39
acc1: 83.5470, acc3: 100.0000, Precision: 0.7213, Recall: 0.7851, F1-Score: 0.7401, Specificity: 0.9210
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:00:25.851 | INFO     | __main__:main_worker:429 - [39/100], remain:0d.00h.30m, It:[10/54], Max-Mem:11247M, Data-Time:1.701, LR:0.0001, Train_Loss:0.2792, total_loss:tensor([0.2792], device='cuda:0'), ce_loss:0.6722588539123535, cluster_loss:0.09524040669202805, sep_loss:0.07056987285614014, soft_orth_loss:0.0037475561257451773, local_consistency_loss:0.000471152103273198, proto_loss:0.17002898454666138
2026-01-29 15:00:30.045 | INFO     | __main__:main_worker:429 - [39/100], remain:0d.00h.26m, It:[20/54], Max-Mem:11247M, Data-Time:0.832, LR:0.0001, Train_Loss:0.2851, total_loss:tensor([0.2851], device='cuda:0'), ce_loss:0.6781922578811646, cluster_loss:0.08461122959852219, sep_loss:0.07993274927139282, soft_orth_loss:0.0037314766086637974, local_consistency_loss:0.0005522757419385016, proto_loss:0.16882774233818054
2026-01-29 15:00:34.307 | INFO     | __main__:main_worker:429 - [39/100], remain:0d.00h.25m, It:[30/54], Max-Mem:11247M, Data-Time:0.655, LR:0.0001, Train_Loss:-0.0414, total_loss:tensor([-0.0414], device='cuda:0'), ce_loss:0.4835682213306427, cluster_loss:0.07280808687210083, sep_loss:0.06815141439437866, soft_orth_loss:0.0037132406141608953, local_consistency_loss:0.00022760352294426411, proto_loss:0.1449003368616104
2026-01-29 15:00:38.762 | INFO     | __main__:main_worker:429 - [39/100], remain:0d.00h.24m, It:[40/54], Max-Mem:11247M, Data-Time:1.047, LR:0.0001, Train_Loss:0.5087, total_loss:tensor([0.5087], device='cuda:0'), ce_loss:0.8215703964233398, cluster_loss:0.09747599810361862, sep_loss:0.07673273980617523, soft_orth_loss:0.0036999089643359184, local_consistency_loss:0.0002728993713390082, proto_loss:0.17818154394626617
2026-01-29 15:00:42.499 | INFO     | __main__:main_worker:429 - [39/100], remain:0d.00h.23m, It:[50/54], Max-Mem:11247M, Data-Time:0.267, LR:0.0001, Train_Loss:0.5119, total_loss:tensor([0.5119], device='cuda:0'), ce_loss:0.7687338590621948, cluster_loss:0.15950743854045868, sep_loss:0.05555712804198265, soft_orth_loss:0.003683316521346569, local_consistency_loss:0.0008946478483267128, proto_loss:0.2196425348520279
Evaluating: 100%|| 15/15 [00:07<00:00,  1.89it/s]
acc1: 88.4615, acc3: 100.0000, Precision: 0.8016, Recall: 0.8229, F1-Score: 0.8109, Specificity: 0.9373
2026-01-29 15:00:52.125 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [39/100], Top1:88.462, Top3:100.000, Test_precision:0.8016,Test_recall:0.8229,Test_f1:0.8109,,Test_specificity:0.9373 Test_loss:0.356564
2026-01-29 15:00:52.126 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:01:11.156 | INFO     | __main__:main_worker:355 - ---> start train epoch40
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:01:19.549 | INFO     | __main__:main_worker:429 - [40/100], remain:0d.00h.22m, It:[10/54], Max-Mem:11247M, Data-Time:0.200, LR:0.0001, Train_Loss:2.6632, total_loss:tensor([2.6632], device='cuda:0'), ce_loss:2.060804843902588, cluster_loss:0.27520254254341125, sep_loss:0.08979418873786926, soft_orth_loss:0.0036621172912418842, local_consistency_loss:0.0022238148376345634, proto_loss:0.37088266015052795
2026-01-29 15:01:23.710 | INFO     | __main__:main_worker:429 - [40/100], remain:0d.00h.22m, It:[20/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.1613, total_loss:tensor([0.1613], device='cuda:0'), ce_loss:0.6083365678787231, cluster_loss:0.07948083430528641, sep_loss:0.07423829287290573, soft_orth_loss:0.0036442335695028305, local_consistency_loss:0.0003756656078621745, proto_loss:0.15773901343345642
2026-01-29 15:01:28.928 | INFO     | __main__:main_worker:429 - [40/100], remain:0d.00h.23m, It:[30/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:0.2905, total_loss:tensor([0.2905], device='cuda:0'), ce_loss:0.7168070077896118, cluster_loss:0.06517374515533447, sep_loss:0.07475535571575165, soft_orth_loss:0.003634883789345622, local_consistency_loss:0.00033204039209522307, proto_loss:0.14389602839946747
2026-01-29 15:01:33.268 | INFO     | __main__:main_worker:429 - [40/100], remain:0d.00h.23m, It:[40/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0001, Train_Loss:0.5966, total_loss:tensor([0.5966], device='cuda:0'), ce_loss:0.8569684624671936, cluster_loss:0.10609197616577148, sep_loss:0.08833767473697662, soft_orth_loss:0.003619189839810133, local_consistency_loss:0.0003728459996636957, proto_loss:0.1984216868877411
2026-01-29 15:01:37.628 | INFO     | __main__:main_worker:429 - [40/100], remain:0d.00h.23m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:-0.1860, total_loss:tensor([-0.1860], device='cuda:0'), ce_loss:0.3965104818344116, cluster_loss:0.07074650377035141, sep_loss:0.061204396188259125, soft_orth_loss:0.003605671925470233, local_consistency_loss:0.0006381882703863084, proto_loss:0.13619476556777954
Evaluating: 100%|| 15/15 [00:08<00:00,  1.79it/s]
acc1: 86.9658, acc3: 100.0000, Precision: 0.7906, Recall: 0.7844, F1-Score: 0.7865, Specificity: 0.9214
2026-01-29 15:01:47.599 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [40/100], Top1:86.966, Top3:100.000, Test_precision:0.7906,Test_recall:0.7844,Test_f1:0.7865,,Test_specificity:0.9214 Test_loss:0.359410
2026-01-29 15:01:47.600 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:01:57.398 | INFO     | __main__:main_worker:355 - ---> start train epoch41
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:02:06.815 | INFO     | __main__:main_worker:429 - [41/100], remain:0d.00h.24m, It:[10/54], Max-Mem:11247M, Data-Time:1.085, LR:0.0001, Train_Loss:2.7140, total_loss:tensor([2.7140], device='cuda:0'), ce_loss:2.124751091003418, cluster_loss:0.25601860880851746, sep_loss:0.08985220640897751, soft_orth_loss:0.0035881942603737116, local_consistency_loss:0.0016220068791881204, proto_loss:0.3510810434818268
2026-01-29 15:02:11.594 | INFO     | __main__:main_worker:429 - [41/100], remain:0d.00h.24m, It:[20/54], Max-Mem:11247M, Data-Time:1.280, LR:0.0001, Train_Loss:-0.2223, total_loss:tensor([-0.2223], device='cuda:0'), ce_loss:0.38063839077949524, cluster_loss:0.0775594636797905, sep_loss:0.04831881821155548, soft_orth_loss:0.003577666822820902, local_consistency_loss:0.0002763039374258369, proto_loss:0.12973223626613617
2026-01-29 15:02:15.777 | INFO     | __main__:main_worker:429 - [41/100], remain:0d.00h.23m, It:[30/54], Max-Mem:11247M, Data-Time:0.017, LR:0.0001, Train_Loss:1.0487, total_loss:tensor([1.0487], device='cuda:0'), ce_loss:1.0839523077011108, cluster_loss:0.17659197747707367, sep_loss:0.08381720632314682, soft_orth_loss:0.0035645447205752134, local_consistency_loss:0.00038662320002913475, proto_loss:0.26436033844947815
2026-01-29 15:02:19.956 | INFO     | __main__:main_worker:429 - [41/100], remain:0d.00h.23m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:-0.0590, total_loss:tensor([-0.0590], device='cuda:0'), ce_loss:0.492399126291275, cluster_loss:0.06813397258520126, sep_loss:0.058957215398550034, soft_orth_loss:0.003550958586856723, local_consistency_loss:0.0007576544303447008, proto_loss:0.13139979541301727
2026-01-29 15:02:24.261 | INFO     | __main__:main_worker:429 - [41/100], remain:0d.00h.22m, It:[50/54], Max-Mem:11247M, Data-Time:0.197, LR:0.0001, Train_Loss:0.0825, total_loss:tensor([0.0825], device='cuda:0'), ce_loss:0.5519517660140991, cluster_loss:0.09492116421461105, sep_loss:0.060911040753126144, soft_orth_loss:0.0035313176922500134, local_consistency_loss:0.0012440234422683716, proto_loss:0.16060754656791687
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
2026-01-29 15:02:34.207 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [41/100], Top1:84.829, Top3:100.000, Test_precision:0.7961,Test_recall:0.7558,Test_f1:0.7735,,Test_specificity:0.8905 Test_loss:0.394343
2026-01-29 15:02:34.207 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:02:34.208 | INFO     | __main__:main_worker:355 - ---> start train epoch42
acc1: 84.8291, acc3: 100.0000, Precision: 0.7961, Recall: 0.7558, F1-Score: 0.7735, Specificity: 0.8905
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:02:44.046 | INFO     | __main__:main_worker:429 - [42/100], remain:0d.00h.25m, It:[10/54], Max-Mem:11247M, Data-Time:1.235, LR:0.0001, Train_Loss:-0.0796, total_loss:tensor([-0.0796], device='cuda:0'), ce_loss:0.47619837522506714, cluster_loss:0.06547709554433823, sep_loss:0.06406840682029724, soft_orth_loss:0.0035072581376880407, local_consistency_loss:0.0003337301022838801, proto_loss:0.133386492729187
2026-01-29 15:02:48.246 | INFO     | __main__:main_worker:429 - [42/100], remain:0d.00h.23m, It:[20/54], Max-Mem:11247M, Data-Time:0.782, LR:0.0001, Train_Loss:0.3322, total_loss:tensor([0.3322], device='cuda:0'), ce_loss:0.7282862067222595, cluster_loss:0.08143705874681473, sep_loss:0.07361668348312378, soft_orth_loss:0.003493907395750284, local_consistency_loss:0.0004048146365676075, proto_loss:0.15895245969295502
2026-01-29 15:02:52.508 | INFO     | __main__:main_worker:429 - [42/100], remain:0d.00h.23m, It:[30/54], Max-Mem:11247M, Data-Time:0.883, LR:0.0001, Train_Loss:0.6577, total_loss:tensor([0.6577], device='cuda:0'), ce_loss:0.8989956974983215, cluster_loss:0.1125529333949089, sep_loss:0.08382304757833481, soft_orth_loss:0.0034801289439201355, local_consistency_loss:0.0005896940710954368, proto_loss:0.20044580101966858
2026-01-29 15:02:56.972 | INFO     | __main__:main_worker:429 - [42/100], remain:0d.00h.22m, It:[40/54], Max-Mem:11247M, Data-Time:0.769, LR:0.0001, Train_Loss:-0.0033, total_loss:tensor([-0.0033], device='cuda:0'), ce_loss:0.506889283657074, cluster_loss:0.07884605973958969, sep_loss:0.06742769479751587, soft_orth_loss:0.003464676672592759, local_consistency_loss:0.0007709278725087643, proto_loss:0.15050937235355377
2026-01-29 15:03:01.118 | INFO     | __main__:main_worker:429 - [42/100], remain:0d.00h.22m, It:[50/54], Max-Mem:11247M, Data-Time:0.779, LR:0.0001, Train_Loss:0.0980, total_loss:tensor([0.0980], device='cuda:0'), ce_loss:0.5652544498443604, cluster_loss:0.08771248161792755, sep_loss:0.0681765079498291, soft_orth_loss:0.003448582487180829, local_consistency_loss:0.00036560322041623294, proto_loss:0.15970316529273987
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 88.2479, acc3: 100.0000, Precision: 0.8124, Recall: 0.8306, F1-Score: 0.8186, Specificity: 0.9394
2026-01-29 15:03:11.632 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [42/100], Top1:88.248, Top3:100.000, Test_precision:0.8124,Test_recall:0.8306,Test_f1:0.8186,,Test_specificity:0.9394 Test_loss:0.357040
2026-01-29 15:03:11.633 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:03:11.634 | INFO     | __main__:main_worker:355 - ---> start train epoch43
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:03:21.298 | INFO     | __main__:main_worker:429 - [43/100], remain:0d.00h.28m, It:[10/54], Max-Mem:11247M, Data-Time:2.153, LR:0.0001, Train_Loss:-0.0590, total_loss:tensor([-0.0590], device='cuda:0'), ce_loss:0.4715558588504791, cluster_loss:0.08024794608354568, sep_loss:0.06402784585952759, soft_orth_loss:0.0034292014315724373, local_consistency_loss:0.0007724273018538952, proto_loss:0.14847742021083832
2026-01-29 15:03:25.761 | INFO     | __main__:main_worker:429 - [43/100], remain:0d.00h.25m, It:[20/54], Max-Mem:11247M, Data-Time:1.142, LR:0.0001, Train_Loss:1.4549, total_loss:tensor([1.4549], device='cuda:0'), ce_loss:1.3867465257644653, cluster_loss:0.16058985888957977, sep_loss:0.08394213765859604, soft_orth_loss:0.003416636725887656, local_consistency_loss:0.002775023691356182, proto_loss:0.250723659992218
2026-01-29 15:03:30.651 | INFO     | __main__:main_worker:429 - [43/100], remain:0d.00h.25m, It:[30/54], Max-Mem:11247M, Data-Time:1.523, LR:0.0001, Train_Loss:-0.0423, total_loss:tensor([-0.0423], device='cuda:0'), ce_loss:0.4772264361381531, cluster_loss:0.08785571157932281, sep_loss:0.060607682913541794, soft_orth_loss:0.003405163995921612, local_consistency_loss:0.0012976957950741053, proto_loss:0.153166264295578
2026-01-29 15:03:34.672 | INFO     | __main__:main_worker:429 - [43/100], remain:0d.00h.23m, It:[40/54], Max-Mem:11247M, Data-Time:0.621, LR:0.0001, Train_Loss:1.4009, total_loss:tensor([1.4009], device='cuda:0'), ce_loss:1.5631614923477173, cluster_loss:0.00034342423896305263, sep_loss:0.08819067478179932, soft_orth_loss:0.003393157385289669, local_consistency_loss:0.0005352869047783315, proto_loss:0.09246254712343216
2026-01-29 15:03:38.469 | INFO     | __main__:main_worker:429 - [43/100], remain:0d.00h.22m, It:[50/54], Max-Mem:11247M, Data-Time:0.442, LR:0.0001, Train_Loss:0.1220, total_loss:tensor([0.1220], device='cuda:0'), ce_loss:0.5714094042778015, cluster_loss:0.10598549991846085, sep_loss:0.05832483619451523, soft_orth_loss:0.0033814795315265656, local_consistency_loss:0.0006948181544430554, proto_loss:0.16838662326335907
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 15:03:48.479 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [43/100], Top1:86.325, Top3:100.000, Test_precision:0.7775,Test_recall:0.8756,Test_f1:0.8121,,Test_specificity:0.9356 Test_loss:0.436884
2026-01-29 15:03:48.480 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:03:48.480 | INFO     | __main__:main_worker:355 - ---> start train epoch44
acc1: 86.3248, acc3: 100.0000, Precision: 0.7775, Recall: 0.8756, F1-Score: 0.8121, Specificity: 0.9356
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:03:57.167 | INFO     | __main__:main_worker:429 - [44/100], remain:0d.00h.22m, It:[10/54], Max-Mem:11247M, Data-Time:0.016, LR:0.0001, Train_Loss:0.2230, total_loss:tensor([0.2230], device='cuda:0'), ce_loss:0.6622123718261719, cluster_loss:0.08101098984479904, sep_loss:0.0685134157538414, soft_orth_loss:0.0033610749524086714, local_consistency_loss:0.0005034487694501877, proto_loss:0.15338893234729767
2026-01-29 15:04:00.973 | INFO     | __main__:main_worker:429 - [44/100], remain:0d.00h.20m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.5733, total_loss:tensor([0.5733], device='cuda:0'), ce_loss:0.8540405035018921, cluster_loss:0.11035292595624924, sep_loss:0.07769894599914551, soft_orth_loss:0.0033459861297160387, local_consistency_loss:0.0005999520071782172, proto_loss:0.19199781119823456
2026-01-29 15:04:05.569 | INFO     | __main__:main_worker:429 - [44/100], remain:0d.00h.21m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:1.0811, total_loss:tensor([1.0811], device='cuda:0'), ce_loss:1.1423554420471191, cluster_loss:0.15072405338287354, sep_loss:0.08508692681789398, soft_orth_loss:0.0033304672688245773, local_consistency_loss:0.0010463448707014322, proto_loss:0.24018779397010803
2026-01-29 15:04:10.580 | INFO     | __main__:main_worker:429 - [44/100], remain:0d.00h.22m, It:[40/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.8252, total_loss:tensor([0.8252], device='cuda:0'), ce_loss:0.9899887442588806, cluster_loss:0.13605134189128876, sep_loss:0.08131355047225952, soft_orth_loss:0.0033165665809065104, local_consistency_loss:0.0006579750333912671, proto_loss:0.22133943438529968
2026-01-29 15:04:15.473 | INFO     | __main__:main_worker:429 - [44/100], remain:0d.00h.22m, It:[50/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0001, Train_Loss:0.3297, total_loss:tensor([0.3297], device='cuda:0'), ce_loss:0.7097917795181274, cluster_loss:0.10149991512298584, sep_loss:0.06829076260328293, soft_orth_loss:0.003302929922938347, local_consistency_loss:0.0007667950703762472, proto_loss:0.17386041581630707
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
acc1: 86.7521, acc3: 100.0000, Precision: 0.7802, Recall: 0.8691, F1-Score: 0.8127, Specificity: 0.9364
2026-01-29 15:04:25.076 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [44/100], Top1:86.752, Top3:100.000, Test_precision:0.7802,Test_recall:0.8691,Test_f1:0.8127,,Test_specificity:0.9364 Test_loss:0.421081
2026-01-29 15:04:25.077 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:04:25.077 | INFO     | __main__:main_worker:355 - ---> start train epoch45
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:04:34.566 | INFO     | __main__:main_worker:429 - [45/100], remain:0d.00h.23m, It:[10/54], Max-Mem:11247M, Data-Time:0.746, LR:0.0001, Train_Loss:1.2181, total_loss:tensor([1.2181], device='cuda:0'), ce_loss:1.248138666152954, cluster_loss:0.14360368251800537, sep_loss:0.08478846400976181, soft_orth_loss:0.003284707898274064, local_consistency_loss:0.0012499764561653137, proto_loss:0.2329268455505371
2026-01-29 15:04:38.624 | INFO     | __main__:main_worker:429 - [45/100], remain:0d.00h.21m, It:[20/54], Max-Mem:11247M, Data-Time:0.668, LR:0.0001, Train_Loss:1.3666, total_loss:tensor([1.3666], device='cuda:0'), ce_loss:1.3583711385726929, cluster_loss:0.13001839816570282, sep_loss:0.09186296910047531, soft_orth_loss:0.0032739017624408007, local_consistency_loss:0.002904328750446439, proto_loss:0.2280595898628235
2026-01-29 15:04:42.408 | INFO     | __main__:main_worker:429 - [45/100], remain:0d.00h.20m, It:[30/54], Max-Mem:11247M, Data-Time:0.380, LR:0.0001, Train_Loss:-0.0731, total_loss:tensor([-0.0731], device='cuda:0'), ce_loss:0.46317967772483826, cluster_loss:0.07982411235570908, sep_loss:0.0655364990234375, soft_orth_loss:0.0032609840855002403, local_consistency_loss:0.0008701605838723481, proto_loss:0.14949175715446472
2026-01-29 15:04:47.045 | INFO     | __main__:main_worker:429 - [45/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:0.898, LR:0.0001, Train_Loss:0.1654, total_loss:tensor([0.1654], device='cuda:0'), ce_loss:0.6264194250106812, cluster_loss:0.08735444396734238, sep_loss:0.05939282104372978, soft_orth_loss:0.003245316445827484, local_consistency_loss:0.0017271576216444373, proto_loss:0.15171974897384644
2026-01-29 15:04:51.300 | INFO     | __main__:main_worker:429 - [45/100], remain:0d.00h.20m, It:[50/54], Max-Mem:11247M, Data-Time:0.114, LR:0.0001, Train_Loss:0.2860, total_loss:tensor([0.2860], device='cuda:0'), ce_loss:0.6696001887321472, cluster_loss:0.10903997719287872, sep_loss:0.06725219637155533, soft_orth_loss:0.003225726308301091, local_consistency_loss:0.0024553430266678333, proto_loss:0.18197324872016907
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 88.2479, acc3: 100.0000, Precision: 0.8128, Recall: 0.8330, F1-Score: 0.8224, Specificity: 0.9314
2026-01-29 15:05:00.682 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [45/100], Top1:88.248, Top3:100.000, Test_precision:0.8128,Test_recall:0.8330,Test_f1:0.8224,,Test_specificity:0.9314 Test_loss:0.347071
2026-01-29 15:05:00.683 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:05:10.130 | INFO     | __main__:main_worker:355 - ---> start train epoch46
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:05:18.539 | INFO     | __main__:main_worker:429 - [46/100], remain:0d.00h.22m, It:[10/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.4718, total_loss:tensor([0.4718], device='cuda:0'), ce_loss:0.7817311882972717, cluster_loss:0.10976498574018478, sep_loss:0.0803147479891777, soft_orth_loss:0.003203043946996331, local_consistency_loss:0.0016230170149356127, proto_loss:0.19490580260753632
2026-01-29 15:05:24.516 | INFO     | __main__:main_worker:429 - [46/100], remain:0d.00h.25m, It:[20/54], Max-Mem:11247M, Data-Time:1.640, LR:0.0001, Train_Loss:0.7973, total_loss:tensor([0.7973], device='cuda:0'), ce_loss:0.9582969546318054, cluster_loss:0.14539378881454468, sep_loss:0.08293464034795761, soft_orth_loss:0.0031938946340233088, local_consistency_loss:0.0002885163703467697, proto_loss:0.23181085288524628
2026-01-29 15:05:28.604 | INFO     | __main__:main_worker:429 - [46/100], remain:0d.00h.23m, It:[30/54], Max-Mem:11247M, Data-Time:0.700, LR:0.0001, Train_Loss:0.2961, total_loss:tensor([0.2961], device='cuda:0'), ce_loss:0.7112928628921509, cluster_loss:0.0874352976679802, sep_loss:0.06598161160945892, soft_orth_loss:0.0031878685113042593, local_consistency_loss:0.00042817063513211906, proto_loss:0.15703293681144714
2026-01-29 15:05:33.762 | INFO     | __main__:main_worker:429 - [46/100], remain:0d.00h.23m, It:[40/54], Max-Mem:11247M, Data-Time:1.741, LR:0.0001, Train_Loss:1.0056, total_loss:tensor([1.0056], device='cuda:0'), ce_loss:1.126843810081482, cluster_loss:0.12316343933343887, sep_loss:0.08793628215789795, soft_orth_loss:0.0031741049606353045, local_consistency_loss:0.0006406562752090394, proto_loss:0.2149144858121872
2026-01-29 15:05:37.672 | INFO     | __main__:main_worker:429 - [46/100], remain:0d.00h.22m, It:[50/54], Max-Mem:11247M, Data-Time:0.549, LR:0.0001, Train_Loss:0.2673, total_loss:tensor([0.2673], device='cuda:0'), ce_loss:0.6801307201385498, cluster_loss:0.08271964639425278, sep_loss:0.07920180261135101, soft_orth_loss:0.003160294843837619, local_consistency_loss:0.00043793595978058875, proto_loss:0.16551966965198517
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 86.1111, acc3: 100.0000, Precision: 0.7644, Recall: 0.7698, F1-Score: 0.7667, Specificity: 0.9183
2026-01-29 15:05:47.018 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [46/100], Top1:86.111, Top3:100.000, Test_precision:0.7644,Test_recall:0.7698,Test_f1:0.7667,,Test_specificity:0.9183 Test_loss:0.475537
2026-01-29 15:05:47.019 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:05:47.020 | INFO     | __main__:main_worker:355 - ---> start train epoch47
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:05:55.852 | INFO     | __main__:main_worker:429 - [47/100], remain:0d.00h.20m, It:[10/54], Max-Mem:11247M, Data-Time:1.020, LR:0.0001, Train_Loss:0.4665, total_loss:tensor([0.4665], device='cuda:0'), ce_loss:0.7960479855537415, cluster_loss:0.09608954191207886, sep_loss:0.08249332755804062, soft_orth_loss:0.0031377985142171383, local_consistency_loss:0.0007883179350756109, proto_loss:0.18250899016857147
2026-01-29 15:06:00.018 | INFO     | __main__:main_worker:429 - [47/100], remain:0d.00h.20m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.0983, total_loss:tensor([0.0983], device='cuda:0'), ce_loss:0.6052817702293396, cluster_loss:0.05428896099328995, sep_loss:0.07674334198236465, soft_orth_loss:0.0031205653212964535, local_consistency_loss:0.0003198270278517157, proto_loss:0.13447269797325134
2026-01-29 15:06:04.286 | INFO     | __main__:main_worker:429 - [47/100], remain:0d.00h.20m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.8563, total_loss:tensor([0.8563], device='cuda:0'), ce_loss:1.0229214429855347, cluster_loss:0.1216905489563942, sep_loss:0.09039481729269028, soft_orth_loss:0.003105293493717909, local_consistency_loss:0.0005919683608226478, proto_loss:0.21578262746334076
2026-01-29 15:06:09.126 | INFO     | __main__:main_worker:429 - [47/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0001, Train_Loss:0.0583, total_loss:tensor([0.0583], device='cuda:0'), ce_loss:0.6617560386657715, cluster_loss:0.00025163855752907693, sep_loss:0.06925879418849945, soft_orth_loss:0.0030920030549168587, local_consistency_loss:0.0005254877032712102, proto_loss:0.07312792539596558
2026-01-29 15:06:13.859 | INFO     | __main__:main_worker:429 - [47/100], remain:0d.00h.20m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.0209, total_loss:tensor([0.0209], device='cuda:0'), ce_loss:0.5308382511138916, cluster_loss:0.07764720916748047, sep_loss:0.06880059838294983, soft_orth_loss:0.003079617628827691, local_consistency_loss:0.00044080568477511406, proto_loss:0.1499682366847992
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 15:06:25.131 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [47/100], Top1:87.821, Top3:100.000, Test_precision:0.7983,Test_recall:0.8274,Test_f1:0.8116,,Test_specificity:0.9326 Test_loss:0.384238
acc1: 87.8205, acc3: 100.0000, Precision: 0.7983, Recall: 0.8274, F1-Score: 0.8116, Specificity: 0.9326
2026-01-29 15:06:25.132 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:06:25.132 | INFO     | __main__:main_worker:355 - ---> start train epoch48
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:06:33.722 | INFO     | __main__:main_worker:429 - [48/100], remain:0d.00h.23m, It:[10/54], Max-Mem:11247M, Data-Time:0.404, LR:0.0001, Train_Loss:0.6339, total_loss:tensor([0.6339], device='cuda:0'), ce_loss:0.8693109154701233, cluster_loss:0.1416277140378952, sep_loss:0.0700559988617897, soft_orth_loss:0.003062587697058916, local_consistency_loss:0.0004415098228491843, proto_loss:0.21518781781196594
2026-01-29 15:06:37.592 | INFO     | __main__:main_worker:429 - [48/100], remain:0d.00h.20m, It:[20/54], Max-Mem:11247M, Data-Time:0.180, LR:0.0001, Train_Loss:0.6052, total_loss:tensor([0.6052], device='cuda:0'), ce_loss:0.849618136882782, cluster_loss:0.1364540457725525, sep_loss:0.07529596984386444, soft_orth_loss:0.00305094919167459, local_consistency_loss:0.0002915680524893105, proto_loss:0.21509253978729248
2026-01-29 15:06:42.524 | INFO     | __main__:main_worker:429 - [48/100], remain:0d.00h.21m, It:[30/54], Max-Mem:11247M, Data-Time:0.499, LR:0.0001, Train_Loss:0.1602, total_loss:tensor([0.1602], device='cuda:0'), ce_loss:0.6311072111129761, cluster_loss:0.06992840766906738, sep_loss:0.07456403970718384, soft_orth_loss:0.0030399661045521498, local_consistency_loss:0.0006297508371062577, proto_loss:0.14816217124462128
2026-01-29 15:06:47.361 | INFO     | __main__:main_worker:429 - [48/100], remain:0d.00h.21m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0001, Train_Loss:1.8182, total_loss:tensor([1.8182], device='cuda:0'), ce_loss:1.6061294078826904, cluster_loss:0.18690571188926697, sep_loss:0.088851198554039, soft_orth_loss:0.0030287124682217836, local_consistency_loss:0.0019594372715801, proto_loss:0.2807450592517853
2026-01-29 15:06:53.470 | INFO     | __main__:main_worker:429 - [48/100], remain:0d.00h.22m, It:[50/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0001, Train_Loss:0.1576, total_loss:tensor([0.1576], device='cuda:0'), ce_loss:0.6037046909332275, cluster_loss:0.10246413201093674, sep_loss:0.061027757823467255, soft_orth_loss:0.003016528906300664, local_consistency_loss:0.0006623828085139394, proto_loss:0.16717080771923065
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
2026-01-29 15:07:02.932 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [48/100], Top1:85.256, Top3:100.000, Test_precision:0.7544,Test_recall:0.8282,Test_f1:0.7810,,Test_specificity:0.9332 Test_loss:0.415569
2026-01-29 15:07:02.943 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
acc1: 85.2564, acc3: 100.0000, Precision: 0.7544, Recall: 0.8282, F1-Score: 0.7810, Specificity: 0.9332
2026-01-29 15:07:02.944 | INFO     | __main__:main_worker:355 - ---> start train epoch49
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:07:11.322 | INFO     | __main__:main_worker:429 - [49/100], remain:0d.00h.17m, It:[10/54], Max-Mem:11247M, Data-Time:0.462, LR:0.0001, Train_Loss:2.2632, total_loss:tensor([2.2632], device='cuda:0'), ce_loss:1.7842075824737549, cluster_loss:0.28540536761283875, sep_loss:0.08789458125829697, soft_orth_loss:0.003002034267410636, local_consistency_loss:0.0010373808909207582, proto_loss:0.3773393929004669
2026-01-29 15:07:15.530 | INFO     | __main__:main_worker:429 - [49/100], remain:0d.00h.18m, It:[20/54], Max-Mem:11247M, Data-Time:0.050, LR:0.0001, Train_Loss:0.4862, total_loss:tensor([0.4862], device='cuda:0'), ce_loss:0.8059092164039612, cluster_loss:0.10727294534444809, sep_loss:0.07638632506132126, soft_orth_loss:0.002991747809574008, local_consistency_loss:0.0004665346350520849, proto_loss:0.1871175616979599
2026-01-29 15:07:19.899 | INFO     | __main__:main_worker:429 - [49/100], remain:0d.00h.18m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.0183, total_loss:tensor([0.0183], device='cuda:0'), ce_loss:0.5305992364883423, cluster_loss:0.08063628524541855, sep_loss:0.06596793234348297, soft_orth_loss:0.0029809020925313234, local_consistency_loss:0.00045831577153876424, proto_loss:0.15004342794418335
2026-01-29 15:07:25.371 | INFO     | __main__:main_worker:429 - [49/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.1343, total_loss:tensor([0.1343], device='cuda:0'), ce_loss:0.5927387475967407, cluster_loss:0.09718688577413559, sep_loss:0.06283940374851227, soft_orth_loss:0.0029682302847504616, local_consistency_loss:0.0008344272500835359, proto_loss:0.16382893919944763
2026-01-29 15:07:29.178 | INFO     | __main__:main_worker:429 - [49/100], remain:0d.00h.19m, It:[50/54], Max-Mem:11247M, Data-Time:0.020, LR:0.0001, Train_Loss:0.1473, total_loss:tensor([0.1473], device='cuda:0'), ce_loss:0.6437841057777405, cluster_loss:0.06535165756940842, sep_loss:0.06420673429965973, soft_orth_loss:0.002956395735964179, local_consistency_loss:0.0009723335388116539, proto_loss:0.13348710536956787
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 85.6838, acc3: 100.0000, Precision: 0.7654, Recall: 0.8491, F1-Score: 0.7952, Specificity: 0.9283
2026-01-29 15:07:38.864 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [49/100], Top1:85.684, Top3:100.000, Test_precision:0.7654,Test_recall:0.8491,Test_f1:0.7952,,Test_specificity:0.9283 Test_loss:0.416953
2026-01-29 15:07:38.865 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:07:38.865 | INFO     | __main__:main_worker:355 - ---> start train epoch50
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:07:47.508 | INFO     | __main__:main_worker:429 - [50/100], remain:0d.00h.16m, It:[10/54], Max-Mem:11247M, Data-Time:0.229, LR:0.0001, Train_Loss:2.0253, total_loss:tensor([2.0253], device='cuda:0'), ce_loss:1.6961305141448975, cluster_loss:0.22481591999530792, sep_loss:0.09257104992866516, soft_orth_loss:0.00293766800314188, local_consistency_loss:0.0006799357943236828, proto_loss:0.32100459933280945
2026-01-29 15:07:51.440 | INFO     | __main__:main_worker:429 - [50/100], remain:0d.00h.16m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.2537, total_loss:tensor([0.2537], device='cuda:0'), ce_loss:0.6599344611167908, cluster_loss:0.10045700520277023, sep_loss:0.07223768532276154, soft_orth_loss:0.0029234641697257757, local_consistency_loss:0.0005052813212387264, proto_loss:0.17612342536449432
2026-01-29 15:07:56.508 | INFO     | __main__:main_worker:429 - [50/100], remain:0d.00h.18m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:0.1806, total_loss:tensor([0.1806], device='cuda:0'), ce_loss:0.611038327217102, cluster_loss:0.09092863649129868, sep_loss:0.07912839949131012, soft_orth_loss:0.00291006569750607, local_consistency_loss:0.0017375432653352618, proto_loss:0.1747046411037445
2026-01-29 15:08:02.190 | INFO     | __main__:main_worker:429 - [50/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:0.5006, total_loss:tensor([0.5006], device='cuda:0'), ce_loss:0.813098669052124, cluster_loss:0.10605920851230621, sep_loss:0.08090464770793915, soft_orth_loss:0.002898636506870389, local_consistency_loss:0.0004086720000486821, proto_loss:0.19027116894721985
2026-01-29 15:08:08.533 | INFO     | __main__:main_worker:429 - [50/100], remain:0d.00h.21m, It:[50/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0001, Train_Loss:1.1980, total_loss:tensor([1.1980], device='cuda:0'), ce_loss:1.2520345449447632, cluster_loss:0.13296592235565186, sep_loss:0.08878477662801743, soft_orth_loss:0.002887182869017124, local_consistency_loss:0.00048066815361380577, proto_loss:0.22511856257915497
Evaluating: 100%|| 15/15 [00:08<00:00,  1.80it/s]
acc1: 85.4701, acc3: 100.0000, Precision: 0.7502, Recall: 0.8095, F1-Score: 0.7732, Specificity: 0.9271
2026-01-29 15:08:18.460 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [50/100], Top1:85.470, Top3:100.000, Test_precision:0.7502,Test_recall:0.8095,Test_f1:0.7732,,Test_specificity:0.9271 Test_loss:0.463114
2026-01-29 15:08:18.462 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:08:28.714 | INFO     | __main__:main_worker:355 - ---> start train epoch51
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:08:37.782 | INFO     | __main__:main_worker:429 - [51/100], remain:0d.00h.19m, It:[10/54], Max-Mem:11247M, Data-Time:0.886, LR:0.0001, Train_Loss:0.2313, total_loss:tensor([0.2313], device='cuda:0'), ce_loss:0.6499883532524109, cluster_loss:0.09581413120031357, sep_loss:0.07344293594360352, soft_orth_loss:0.0028707021847367287, local_consistency_loss:0.00044536750647239387, proto_loss:0.17257314920425415
2026-01-29 15:08:42.147 | INFO     | __main__:main_worker:429 - [51/100], remain:0d.00h.19m, It:[20/54], Max-Mem:11247M, Data-Time:0.920, LR:0.0001, Train_Loss:0.7603, total_loss:tensor([0.7603], device='cuda:0'), ce_loss:1.0112121105194092, cluster_loss:0.09588851034641266, sep_loss:0.07878308743238449, soft_orth_loss:0.0028579686768352985, local_consistency_loss:0.0010521654039621353, proto_loss:0.17858172953128815
2026-01-29 15:08:46.053 | INFO     | __main__:main_worker:429 - [51/100], remain:0d.00h.18m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.1027, total_loss:tensor([0.1027], device='cuda:0'), ce_loss:0.5904369354248047, cluster_loss:0.08427955210208893, sep_loss:0.0632970929145813, soft_orth_loss:0.002847213763743639, local_consistency_loss:0.0005615164991468191, proto_loss:0.15098537504673004
2026-01-29 15:08:50.790 | INFO     | __main__:main_worker:429 - [51/100], remain:0d.00h.18m, It:[40/54], Max-Mem:11247M, Data-Time:0.347, LR:0.0001, Train_Loss:-0.3704, total_loss:tensor([-0.3704], device='cuda:0'), ce_loss:0.29163050651550293, cluster_loss:0.07605084031820297, sep_loss:0.04896218702197075, soft_orth_loss:0.0028392146341502666, local_consistency_loss:0.0005077950772829354, proto_loss:0.12836003303527832
2026-01-29 15:08:54.825 | INFO     | __main__:main_worker:429 - [51/100], remain:0d.00h.18m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0001, Train_Loss:-0.0633, total_loss:tensor([-0.0633], device='cuda:0'), ce_loss:0.5069008469581604, cluster_loss:0.06592194736003876, sep_loss:0.05820998549461365, soft_orth_loss:0.002830668818205595, local_consistency_loss:0.0009023090824484825, proto_loss:0.12786491215229034
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 15:09:04.313 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [51/100], Top1:85.684, Top3:100.000, Test_precision:0.7627,Test_recall:0.8283,Test_f1:0.7884,,Test_specificity:0.9275 Test_loss:0.387121
2026-01-29 15:09:04.314 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:09:04.314 | INFO     | __main__:main_worker:355 - ---> start train epoch52
acc1: 85.6838, acc3: 100.0000, Precision: 0.7627, Recall: 0.8283, F1-Score: 0.7884, Specificity: 0.9275
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:09:13.577 | INFO     | __main__:main_worker:429 - [52/100], remain:0d.00h.21m, It:[10/54], Max-Mem:11247M, Data-Time:1.466, LR:0.0001, Train_Loss:-0.2233, total_loss:tensor([-0.2233], device='cuda:0'), ce_loss:0.3965952694416046, cluster_loss:0.0703670009970665, sep_loss:0.05339393764734268, soft_orth_loss:0.0028175460174679756, local_consistency_loss:0.0004865664232056588, proto_loss:0.127065047621727
2026-01-29 15:09:18.189 | INFO     | __main__:main_worker:429 - [52/100], remain:0d.00h.20m, It:[20/54], Max-Mem:11247M, Data-Time:1.189, LR:0.0001, Train_Loss:-0.2306, total_loss:tensor([-0.2306], device='cuda:0'), ce_loss:0.386900931596756, cluster_loss:0.06748417764902115, sep_loss:0.05953516811132431, soft_orth_loss:0.002808214398100972, local_consistency_loss:0.0007015166920609772, proto_loss:0.13052907586097717
2026-01-29 15:09:22.822 | INFO     | __main__:main_worker:429 - [52/100], remain:0d.00h.20m, It:[30/54], Max-Mem:11247M, Data-Time:1.225, LR:0.0001, Train_Loss:0.1140, total_loss:tensor([0.1140], device='cuda:0'), ce_loss:0.6073249578475952, cluster_loss:0.07543215155601501, sep_loss:0.06629902124404907, soft_orth_loss:0.0027987551875412464, local_consistency_loss:0.0006476024282164872, proto_loss:0.14517752826213837
2026-01-29 15:09:28.235 | INFO     | __main__:main_worker:429 - [52/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:1.902, LR:0.0001, Train_Loss:0.0101, total_loss:tensor([0.0101], device='cuda:0'), ce_loss:0.6422744989395142, cluster_loss:0.00021749462757725269, sep_loss:0.06392517685890198, soft_orth_loss:0.0027880712877959013, local_consistency_loss:0.0007708522025495768, proto_loss:0.06770160049200058
2026-01-29 15:09:32.114 | INFO     | __main__:main_worker:429 - [52/100], remain:0d.00h.19m, It:[50/54], Max-Mem:11247M, Data-Time:0.490, LR:0.0001, Train_Loss:0.8023, total_loss:tensor([0.8023], device='cuda:0'), ce_loss:0.9804405570030212, cluster_loss:0.1409485787153244, sep_loss:0.07886737585067749, soft_orth_loss:0.0027763324324041605, local_consistency_loss:0.0003016214759554714, proto_loss:0.22289390861988068
Evaluating: 100%|| 15/15 [00:07<00:00,  1.89it/s]
2026-01-29 15:09:41.335 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [52/100], Top1:86.325, Top3:100.000, Test_precision:0.7767,Test_recall:0.8427,Test_f1:0.8025,,Test_specificity:0.9334 Test_loss:0.403515
2026-01-29 15:09:41.336 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:09:41.336 | INFO     | __main__:main_worker:355 - ---> start train epoch53
acc1: 86.3248, acc3: 100.0000, Precision: 0.7767, Recall: 0.8427, F1-Score: 0.8025, Specificity: 0.9334
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:09:50.522 | INFO     | __main__:main_worker:429 - [53/100], remain:0d.00h.22m, It:[10/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:0.6523, total_loss:tensor([0.6523], device='cuda:0'), ce_loss:0.9037826657295227, cluster_loss:0.12425092607736588, sep_loss:0.07519960403442383, soft_orth_loss:0.0027611355762928724, local_consistency_loss:0.0006136022275313735, proto_loss:0.20282526314258575
2026-01-29 15:09:55.326 | INFO     | __main__:main_worker:429 - [53/100], remain:0d.00h.21m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0001, Train_Loss:-0.2035, total_loss:tensor([-0.2035], device='cuda:0'), ce_loss:0.4113672971725464, cluster_loss:0.06868677586317062, sep_loss:0.055629611015319824, soft_orth_loss:0.0027519315481185913, local_consistency_loss:0.0002205267082899809, proto_loss:0.1272888332605362
2026-01-29 15:09:59.493 | INFO     | __main__:main_worker:429 - [53/100], remain:0d.00h.20m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0001, Train_Loss:-0.0936, total_loss:tensor([-0.0936], device='cuda:0'), ce_loss:0.47161898016929626, cluster_loss:0.07312440872192383, sep_loss:0.06303560733795166, soft_orth_loss:0.0027407759334892035, local_consistency_loss:0.0003753207274712622, proto_loss:0.13927610218524933
2026-01-29 15:10:04.511 | INFO     | __main__:main_worker:429 - [53/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:0.019, LR:0.0000, Train_Loss:0.2167, total_loss:tensor([0.2167], device='cuda:0'), ce_loss:0.6525101661682129, cluster_loss:0.08783823996782303, sep_loss:0.07419613003730774, soft_orth_loss:0.002730096923187375, local_consistency_loss:0.0003823570441454649, proto_loss:0.1651468276977539
2026-01-29 15:10:09.625 | INFO     | __main__:main_worker:429 - [53/100], remain:0d.00h.20m, It:[50/54], Max-Mem:11247M, Data-Time:0.008, LR:0.0000, Train_Loss:0.1918, total_loss:tensor([0.1918], device='cuda:0'), ce_loss:0.6229794025421143, cluster_loss:0.10048139095306396, sep_loss:0.07027597725391388, soft_orth_loss:0.0027189040556550026, local_consistency_loss:0.0005460745887830853, proto_loss:0.1740223467350006
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
acc1: 85.2564, acc3: 100.0000, Precision: 0.7715, Recall: 0.8362, F1-Score: 0.7977, Specificity: 0.9218
2026-01-29 15:10:19.365 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [53/100], Top1:85.256, Top3:100.000, Test_precision:0.7715,Test_recall:0.8362,Test_f1:0.7977,,Test_specificity:0.9218 Test_loss:0.412708
2026-01-29 15:10:19.366 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:10:19.366 | INFO     | __main__:main_worker:355 - ---> start train epoch54
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:10:28.612 | INFO     | __main__:main_worker:429 - [54/100], remain:0d.00h.17m, It:[10/54], Max-Mem:11247M, Data-Time:0.836, LR:0.0000, Train_Loss:0.0329, total_loss:tensor([0.0329], device='cuda:0'), ce_loss:0.545131504535675, cluster_loss:0.08153137564659119, sep_loss:0.06591519713401794, soft_orth_loss:0.0027061726432293653, local_consistency_loss:0.00023021773085929453, proto_loss:0.15038296580314636
2026-01-29 15:10:33.043 | INFO     | __main__:main_worker:429 - [54/100], remain:0d.00h.18m, It:[20/54], Max-Mem:11247M, Data-Time:1.016, LR:0.0000, Train_Loss:0.0626, total_loss:tensor([0.0626], device='cuda:0'), ce_loss:0.5702216029167175, cluster_loss:0.07790999859571457, sep_loss:0.06632484495639801, soft_orth_loss:0.002696513431146741, local_consistency_loss:0.00046264324919320643, proto_loss:0.14739398658275604
2026-01-29 15:10:37.453 | INFO     | __main__:main_worker:429 - [54/100], remain:0d.00h.17m, It:[30/54], Max-Mem:11247M, Data-Time:0.342, LR:0.0000, Train_Loss:0.8277, total_loss:tensor([0.8277], device='cuda:0'), ce_loss:1.0011435747146606, cluster_loss:0.13685302436351776, sep_loss:0.08177007734775543, soft_orth_loss:0.00268814736045897, local_consistency_loss:0.00039086080505512655, proto_loss:0.22170211374759674
2026-01-29 15:10:42.084 | INFO     | __main__:main_worker:429 - [54/100], remain:0d.00h.18m, It:[40/54], Max-Mem:11247M, Data-Time:1.054, LR:0.0000, Train_Loss:0.0893, total_loss:tensor([0.0893], device='cuda:0'), ce_loss:0.58510422706604, cluster_loss:0.0842033103108406, sep_loss:0.06291072070598602, soft_orth_loss:0.0026798145845532417, local_consistency_loss:0.0005099321715533733, proto_loss:0.15030378103256226
2026-01-29 15:10:47.272 | INFO     | __main__:main_worker:429 - [54/100], remain:0d.00h.18m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.0969, total_loss:tensor([-0.0969], device='cuda:0'), ce_loss:0.47703245282173157, cluster_loss:0.07532279938459396, sep_loss:0.05633755773305893, soft_orth_loss:0.0026718000881373882, local_consistency_loss:0.00033672628342173994, proto_loss:0.13466887176036835
Evaluating: 100%|| 15/15 [00:08<00:00,  1.79it/s]
acc1: 86.5385, acc3: 100.0000, Precision: 0.7666, Recall: 0.8481, F1-Score: 0.7937, Specificity: 0.9367
2026-01-29 15:10:58.702 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [54/100], Top1:86.538, Top3:100.000, Test_precision:0.7666,Test_recall:0.8481,Test_f1:0.7937,,Test_specificity:0.9367 Test_loss:0.419935
2026-01-29 15:10:58.703 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:10:58.704 | INFO     | __main__:main_worker:355 - ---> start train epoch55
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:11:07.003 | INFO     | __main__:main_worker:429 - [55/100], remain:0d.00h.19m, It:[10/54], Max-Mem:11247M, Data-Time:0.458, LR:0.0000, Train_Loss:0.0720, total_loss:tensor([0.0720], device='cuda:0'), ce_loss:0.5584022402763367, cluster_loss:0.0955522283911705, sep_loss:0.06246548146009445, soft_orth_loss:0.002657837001606822, local_consistency_loss:0.0004257425607647747, proto_loss:0.16110128164291382
2026-01-29 15:11:13.055 | INFO     | __main__:main_worker:429 - [55/100], remain:0d.00h.21m, It:[20/54], Max-Mem:11247M, Data-Time:1.805, LR:0.0000, Train_Loss:0.4017, total_loss:tensor([0.4017], device='cuda:0'), ce_loss:0.7488763928413391, cluster_loss:0.13054893910884857, sep_loss:0.05557658523321152, soft_orth_loss:0.0026483230758458376, local_consistency_loss:0.0009242657688446343, proto_loss:0.18969810009002686
2026-01-29 15:11:17.929 | INFO     | __main__:main_worker:429 - [55/100], remain:0d.00h.21m, It:[30/54], Max-Mem:11247M, Data-Time:1.424, LR:0.0000, Train_Loss:0.6520, total_loss:tensor([0.6520], device='cuda:0'), ce_loss:0.8964803814888, cluster_loss:0.13254420459270477, sep_loss:0.07376657426357269, soft_orth_loss:0.002639294834807515, local_consistency_loss:0.0002861603570636362, proto_loss:0.2092362344264984
2026-01-29 15:11:22.356 | INFO     | __main__:main_worker:429 - [55/100], remain:0d.00h.20m, It:[40/54], Max-Mem:11247M, Data-Time:0.772, LR:0.0000, Train_Loss:0.2628, total_loss:tensor([0.2628], device='cuda:0'), ce_loss:0.6651082038879395, cluster_loss:0.11632645130157471, sep_loss:0.06108042597770691, soft_orth_loss:0.002630673348903656, local_consistency_loss:0.0004106250707991421, proto_loss:0.18044818937778473
2026-01-29 15:11:27.371 | INFO     | __main__:main_worker:429 - [55/100], remain:0d.00h.19m, It:[50/54], Max-Mem:11247M, Data-Time:1.621, LR:0.0000, Train_Loss:1.3991, total_loss:tensor([1.3991], device='cuda:0'), ce_loss:1.3492436408996582, cluster_loss:0.174584299325943, sep_loss:0.07898667454719543, soft_orth_loss:0.002622424392029643, local_consistency_loss:0.0024333931505680084, proto_loss:0.258626788854599
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 15:11:36.722 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [55/100], Top1:84.829, Top3:100.000, Test_precision:0.7640,Test_recall:0.8229,Test_f1:0.7878,,Test_specificity:0.9155 Test_loss:0.411534
2026-01-29 15:11:36.723 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
acc1: 84.8291, acc3: 100.0000, Precision: 0.7640, Recall: 0.8229, F1-Score: 0.7878, Specificity: 0.9155
2026-01-29 15:11:46.870 | INFO     | __main__:main_worker:355 - ---> start train epoch56
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:11:54.997 | INFO     | __main__:main_worker:429 - [56/100], remain:0d.00h.17m, It:[10/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.0343, total_loss:tensor([-0.0343], device='cuda:0'), ce_loss:0.5268179774284363, cluster_loss:0.06335550546646118, sep_loss:0.0647258460521698, soft_orth_loss:0.002608053619042039, local_consistency_loss:0.00040859795990400016, proto_loss:0.13109801709651947
2026-01-29 15:11:58.699 | INFO     | __main__:main_worker:429 - [56/100], remain:0d.00h.15m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.2148, total_loss:tensor([0.2148], device='cuda:0'), ce_loss:0.6483737230300903, cluster_loss:0.09297112375497818, sep_loss:0.07262890785932541, soft_orth_loss:0.002599058672785759, local_consistency_loss:0.0005405779229477048, proto_loss:0.1687396764755249
2026-01-29 15:12:04.017 | INFO     | __main__:main_worker:429 - [56/100], remain:0d.00h.17m, It:[30/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:1.0537, total_loss:tensor([1.0537], device='cuda:0'), ce_loss:1.2266623973846436, cluster_loss:0.08490423113107681, sep_loss:0.08465346693992615, soft_orth_loss:0.0025909694377332926, local_consistency_loss:0.0019118551863357425, proto_loss:0.17406050860881805
2026-01-29 15:12:08.621 | INFO     | __main__:main_worker:429 - [56/100], remain:0d.00h.17m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.0408, total_loss:tensor([-0.0408], device='cuda:0'), ce_loss:0.5195597410202026, cluster_loss:0.0641765147447586, sep_loss:0.06635349243879318, soft_orth_loss:0.002583116525784135, local_consistency_loss:0.00033771953894756734, proto_loss:0.13345083594322205
2026-01-29 15:12:13.121 | INFO     | __main__:main_worker:429 - [56/100], remain:0d.00h.17m, It:[50/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0000, Train_Loss:-0.3373, total_loss:tensor([-0.3373], device='cuda:0'), ce_loss:0.33306440711021423, cluster_loss:0.06299887597560883, sep_loss:0.05251014232635498, soft_orth_loss:0.0025748771149665117, local_consistency_loss:0.0008479606476612389, proto_loss:0.1189318522810936
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
2026-01-29 15:12:22.646 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [56/100], Top1:85.043, Top3:100.000, Test_precision:0.7527,Test_recall:0.8378,Test_f1:0.7825,,Test_specificity:0.9303 Test_loss:0.425147
2026-01-29 15:12:22.647 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:12:22.647 | INFO     | __main__:main_worker:355 - ---> start train epoch57
acc1: 85.0427, acc3: 100.0000, Precision: 0.7527, Recall: 0.8378, F1-Score: 0.7825, Specificity: 0.9303
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:12:31.024 | INFO     | __main__:main_worker:429 - [57/100], remain:0d.00h.17m, It:[10/54], Max-Mem:11247M, Data-Time:0.505, LR:0.0000, Train_Loss:0.7387, total_loss:tensor([0.7387], device='cuda:0'), ce_loss:0.9549219012260437, cluster_loss:0.13569603860378265, sep_loss:0.07309411466121674, soft_orth_loss:0.002562515903264284, local_consistency_loss:0.0002258641179651022, proto_loss:0.21157853305339813
2026-01-29 15:12:35.318 | INFO     | __main__:main_worker:429 - [57/100], remain:0d.00h.16m, It:[20/54], Max-Mem:11247M, Data-Time:0.361, LR:0.0000, Train_Loss:2.4293, total_loss:tensor([2.4293], device='cuda:0'), ce_loss:1.9352318048477173, cluster_loss:0.2615719139575958, sep_loss:0.08926194906234741, soft_orth_loss:0.0025544711388647556, local_consistency_loss:0.0010396166471764445, proto_loss:0.3544279634952545
2026-01-29 15:12:40.619 | INFO     | __main__:main_worker:429 - [57/100], remain:0d.00h.18m, It:[30/54], Max-Mem:11247M, Data-Time:1.316, LR:0.0000, Train_Loss:0.9549, total_loss:tensor([0.9549], device='cuda:0'), ce_loss:1.1019647121429443, cluster_loss:0.13191282749176025, sep_loss:0.07931723445653915, soft_orth_loss:0.0025465572252869606, local_consistency_loss:0.0006997923483140767, proto_loss:0.21447642147541046
2026-01-29 15:12:44.333 | INFO     | __main__:main_worker:429 - [57/100], remain:0d.00h.16m, It:[40/54], Max-Mem:11247M, Data-Time:0.333, LR:0.0000, Train_Loss:0.5909, total_loss:tensor([0.5909], device='cuda:0'), ce_loss:0.8779311180114746, cluster_loss:0.11201288551092148, sep_loss:0.07736743986606598, soft_orth_loss:0.0025380586739629507, local_consistency_loss:0.0011668637162074447, proto_loss:0.19308523833751678
2026-01-29 15:12:48.473 | INFO     | __main__:main_worker:429 - [57/100], remain:0d.00h.16m, It:[50/54], Max-Mem:11247M, Data-Time:0.155, LR:0.0000, Train_Loss:0.3213, total_loss:tensor([0.3213], device='cuda:0'), ce_loss:0.7181738615036011, cluster_loss:0.09279423207044601, sep_loss:0.07715864479541779, soft_orth_loss:0.0025310921482741833, local_consistency_loss:0.0004187032754998654, proto_loss:0.1729026734828949
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 87.3932, acc3: 100.0000, Precision: 0.7926, Recall: 0.8312, F1-Score: 0.8097, Specificity: 0.9327
2026-01-29 15:12:57.906 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [57/100], Top1:87.393, Top3:100.000, Test_precision:0.7926,Test_recall:0.8312,Test_f1:0.8097,,Test_specificity:0.9327 Test_loss:0.389699
2026-01-29 15:12:57.907 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:12:57.907 | INFO     | __main__:main_worker:355 - ---> start train epoch58
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:13:08.083 | INFO     | __main__:main_worker:429 - [58/100], remain:0d.00h.21m, It:[10/54], Max-Mem:11247M, Data-Time:2.284, LR:0.0000, Train_Loss:0.1208, total_loss:tensor([0.1208], device='cuda:0'), ce_loss:0.6132649779319763, cluster_loss:0.06994062662124634, sep_loss:0.07520794868469238, soft_orth_loss:0.002522967988625169, local_consistency_loss:0.00033145255292765796, proto_loss:0.1480029970407486
2026-01-29 15:13:12.385 | INFO     | __main__:main_worker:429 - [58/100], remain:0d.00h.18m, It:[20/54], Max-Mem:11247M, Data-Time:0.943, LR:0.0000, Train_Loss:1.8352, total_loss:tensor([1.8352], device='cuda:0'), ce_loss:1.535799264907837, cluster_loss:0.2564958333969116, sep_loss:0.08482780307531357, soft_orth_loss:0.002515140688046813, local_consistency_loss:0.00035688761272467673, proto_loss:0.3441956639289856
2026-01-29 15:13:15.898 | INFO     | __main__:main_worker:429 - [58/100], remain:0d.00h.16m, It:[30/54], Max-Mem:11247M, Data-Time:0.016, LR:0.0000, Train_Loss:0.5013, total_loss:tensor([0.5013], device='cuda:0'), ce_loss:0.8328890204429626, cluster_loss:0.09740882366895676, sep_loss:0.08038514852523804, soft_orth_loss:0.002503980416804552, local_consistency_loss:0.0008855999330990016, proto_loss:0.1811835616827011
2026-01-29 15:13:20.754 | INFO     | __main__:main_worker:429 - [58/100], remain:0d.00h.17m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:0.1100, total_loss:tensor([0.1100], device='cuda:0'), ce_loss:0.5827867388725281, cluster_loss:0.09289643913507462, sep_loss:0.06903128325939178, soft_orth_loss:0.0024937281850725412, local_consistency_loss:0.00035930058220401406, proto_loss:0.16478075087070465
2026-01-29 15:13:25.065 | INFO     | __main__:main_worker:429 - [58/100], remain:0d.00h.16m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.1431, total_loss:tensor([-0.1431], device='cuda:0'), ce_loss:0.4647790491580963, cluster_loss:0.06939513236284256, sep_loss:0.050932224839925766, soft_orth_loss:0.00248494534753263, local_consistency_loss:0.00023195646645035595, proto_loss:0.12304425984621048
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 85.8974, acc3: 100.0000, Precision: 0.7642, Recall: 0.7895, F1-Score: 0.7758, Specificity: 0.9215
2026-01-29 15:13:36.184 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [58/100], Top1:85.897, Top3:100.000, Test_precision:0.7642,Test_recall:0.7895,Test_f1:0.7758,,Test_specificity:0.9215 Test_loss:0.386361
2026-01-29 15:13:36.185 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:13:36.185 | INFO     | __main__:main_worker:355 - ---> start train epoch59
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:13:46.251 | INFO     | __main__:main_worker:429 - [59/100], remain:0d.00h.19m, It:[10/54], Max-Mem:11247M, Data-Time:0.535, LR:0.0000, Train_Loss:-0.1548, total_loss:tensor([-0.1548], device='cuda:0'), ce_loss:0.45440390706062317, cluster_loss:0.06406442075967789, sep_loss:0.057220421731472015, soft_orth_loss:0.0024742749519646168, local_consistency_loss:0.0010318398708477616, proto_loss:0.12479095906019211
2026-01-29 15:13:51.998 | INFO     | __main__:main_worker:429 - [59/100], remain:0d.00h.20m, It:[20/54], Max-Mem:11247M, Data-Time:2.287, LR:0.0000, Train_Loss:-0.0070, total_loss:tensor([-0.0070], device='cuda:0'), ce_loss:0.5292801260948181, cluster_loss:0.07960796356201172, sep_loss:0.06275975704193115, soft_orth_loss:0.0024644199293106794, local_consistency_loss:0.00032240027212537825, proto_loss:0.14515453577041626
2026-01-29 15:13:55.539 | INFO     | __main__:main_worker:429 - [59/100], remain:0d.00h.17m, It:[30/54], Max-Mem:11247M, Data-Time:0.169, LR:0.0000, Train_Loss:0.2111, total_loss:tensor([0.2111], device='cuda:0'), ce_loss:0.6492631435394287, cluster_loss:0.09299852699041367, sep_loss:0.07231175899505615, soft_orth_loss:0.002456170041114092, local_consistency_loss:0.0005454103811644018, proto_loss:0.16831187903881073
2026-01-29 15:14:00.748 | INFO     | __main__:main_worker:429 - [59/100], remain:0d.00h.17m, It:[40/54], Max-Mem:11247M, Data-Time:1.518, LR:0.0000, Train_Loss:0.0663, total_loss:tensor([0.0663], device='cuda:0'), ce_loss:0.5581454634666443, cluster_loss:0.09685003012418747, sep_loss:0.06045806407928467, soft_orth_loss:0.002449014689773321, local_consistency_loss:0.001531223184429109, proto_loss:0.16128835082054138
2026-01-29 15:14:05.834 | INFO     | __main__:main_worker:429 - [59/100], remain:0d.00h.17m, It:[50/54], Max-Mem:11247M, Data-Time:1.715, LR:0.0000, Train_Loss:0.0742, total_loss:tensor([0.0742], device='cuda:0'), ce_loss:0.6973741054534912, cluster_loss:0.00023753021378070116, sep_loss:0.06277171522378922, soft_orth_loss:0.0024417750537395477, local_consistency_loss:0.0006535112042911351, proto_loss:0.06610453873872757
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
acc1: 87.6068, acc3: 100.0000, Precision: 0.7860, Recall: 0.8519, F1-Score: 0.8121, Specificity: 0.9388
2026-01-29 15:14:15.095 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [59/100], Top1:87.607, Top3:100.000, Test_precision:0.7860,Test_recall:0.8519,Test_f1:0.8121,,Test_specificity:0.9388 Test_loss:0.386576
2026-01-29 15:14:15.098 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:14:15.099 | INFO     | __main__:main_worker:355 - ---> start train epoch60
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:14:23.212 | INFO     | __main__:main_worker:429 - [60/100], remain:0d.00h.14m, It:[10/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.2191, total_loss:tensor([0.2191], device='cuda:0'), ce_loss:0.6731173992156982, cluster_loss:0.082740917801857, sep_loss:0.07022090256214142, soft_orth_loss:0.002431204542517662, local_consistency_loss:0.00024315908376593143, proto_loss:0.15563617646694183
2026-01-29 15:14:28.431 | INFO     | __main__:main_worker:429 - [60/100], remain:0d.00h.16m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.4340, total_loss:tensor([0.4340], device='cuda:0'), ce_loss:0.8029565215110779, cluster_loss:0.09099145978689194, sep_loss:0.07627764344215393, soft_orth_loss:0.002423807280138135, local_consistency_loss:0.0004335955891292542, proto_loss:0.1701265126466751
2026-01-29 15:14:32.289 | INFO     | __main__:main_worker:429 - [60/100], remain:0d.00h.15m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.4400, total_loss:tensor([0.4400], device='cuda:0'), ce_loss:0.7913751006126404, cluster_loss:0.09808673709630966, sep_loss:0.08055300265550613, soft_orth_loss:0.0024175166618078947, local_consistency_loss:0.00039806051063351333, proto_loss:0.1814553141593933
2026-01-29 15:14:37.127 | INFO     | __main__:main_worker:429 - [60/100], remain:0d.00h.15m, It:[40/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.0950, total_loss:tensor([-0.0950], device='cuda:0'), ce_loss:0.47393566370010376, cluster_loss:0.08241968601942062, sep_loss:0.05623826012015343, soft_orth_loss:0.0024106132332235575, local_consistency_loss:0.0004993395414203405, proto_loss:0.1415679007768631
2026-01-29 15:14:41.151 | INFO     | __main__:main_worker:429 - [60/100], remain:0d.00h.15m, It:[50/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0000, Train_Loss:0.2809, total_loss:tensor([0.2809], device='cuda:0'), ce_loss:0.6799216866493225, cluster_loss:0.10835390537977219, sep_loss:0.070732980966568, soft_orth_loss:0.002402732614427805, local_consistency_loss:0.0004058280901517719, proto_loss:0.18189546465873718
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 85.8974, acc3: 100.0000, Precision: 0.7629, Recall: 0.8390, F1-Score: 0.7910, Specificity: 0.9343
2026-01-29 15:14:52.315 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [60/100], Top1:85.897, Top3:100.000, Test_precision:0.7629,Test_recall:0.8390,Test_f1:0.7910,,Test_specificity:0.9343 Test_loss:0.411862
2026-01-29 15:14:52.316 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:15:02.616 | INFO     | __main__:main_worker:355 - ---> start train epoch61
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:15:13.364 | INFO     | __main__:main_worker:429 - [61/100], remain:0d.00h.18m, It:[10/54], Max-Mem:11247M, Data-Time:1.669, LR:0.0000, Train_Loss:0.5780, total_loss:tensor([0.5780], device='cuda:0'), ce_loss:0.8452137112617493, cluster_loss:0.1378244161605835, sep_loss:0.07110511511564255, soft_orth_loss:0.0023924089036881924, local_consistency_loss:0.0006539973546750844, proto_loss:0.21197594702243805
2026-01-29 15:15:17.697 | INFO     | __main__:main_worker:429 - [61/100], remain:0d.00h.16m, It:[20/54], Max-Mem:11247M, Data-Time:0.822, LR:0.0000, Train_Loss:-0.0603, total_loss:tensor([-0.0603], device='cuda:0'), ce_loss:0.49100184440612793, cluster_loss:0.07964751124382019, sep_loss:0.06440433859825134, soft_orth_loss:0.0023855797480791807, local_consistency_loss:0.0006351497140713036, proto_loss:0.14707258343696594
2026-01-29 15:15:22.436 | INFO     | __main__:main_worker:429 - [61/100], remain:0d.00h.16m, It:[30/54], Max-Mem:11247M, Data-Time:1.348, LR:0.0000, Train_Loss:0.6641, total_loss:tensor([0.6641], device='cuda:0'), ce_loss:0.9225306510925293, cluster_loss:0.12025266885757446, sep_loss:0.07686091214418411, soft_orth_loss:0.0023793885484337807, local_consistency_loss:0.00042368422145955265, proto_loss:0.19991664588451385
2026-01-29 15:15:26.954 | INFO     | __main__:main_worker:429 - [61/100], remain:0d.00h.16m, It:[40/54], Max-Mem:11247M, Data-Time:1.081, LR:0.0000, Train_Loss:0.2874, total_loss:tensor([0.2874], device='cuda:0'), ce_loss:0.7049140334129333, cluster_loss:0.09361734241247177, sep_loss:0.07108478993177414, soft_orth_loss:0.0023724667262285948, local_consistency_loss:0.0006809551268815994, proto_loss:0.16775555908679962
2026-01-29 15:15:30.544 | INFO     | __main__:main_worker:429 - [61/100], remain:0d.00h.15m, It:[50/54], Max-Mem:11247M, Data-Time:0.183, LR:0.0000, Train_Loss:0.2346, total_loss:tensor([0.2346], device='cuda:0'), ce_loss:0.6905430555343628, cluster_loss:0.07905059307813644, sep_loss:0.06986944377422333, soft_orth_loss:0.0023664613254368305, local_consistency_loss:0.000578204810153693, proto_loss:0.15186470746994019
Evaluating: 100%|| 15/15 [00:07<00:00,  1.89it/s]
acc1: 84.4017, acc3: 100.0000, Precision: 0.7296, Recall: 0.7808, F1-Score: 0.7474, Specificity: 0.9206
2026-01-29 15:15:39.806 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [61/100], Top1:84.402, Top3:100.000, Test_precision:0.7296,Test_recall:0.7808,Test_f1:0.7474,,Test_specificity:0.9206 Test_loss:0.426637
2026-01-29 15:15:39.818 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:15:39.819 | INFO     | __main__:main_worker:355 - ---> start train epoch62
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:15:49.247 | INFO     | __main__:main_worker:429 - [62/100], remain:0d.00h.18m, It:[10/54], Max-Mem:11247M, Data-Time:1.667, LR:0.0000, Train_Loss:1.3449, total_loss:tensor([1.3449], device='cuda:0'), ce_loss:1.3206835985183716, cluster_loss:0.16698335111141205, sep_loss:0.08531878888607025, soft_orth_loss:0.002357935532927513, local_consistency_loss:0.0002981771540362388, proto_loss:0.25495824217796326
2026-01-29 15:15:53.990 | INFO     | __main__:main_worker:429 - [62/100], remain:0d.00h.17m, It:[20/54], Max-Mem:11247M, Data-Time:1.342, LR:0.0000, Train_Loss:0.2320, total_loss:tensor([0.2320], device='cuda:0'), ce_loss:0.6695414185523987, cluster_loss:0.09879545122385025, sep_loss:0.06365623325109482, soft_orth_loss:0.002351333387196064, local_consistency_loss:0.0008624791516922414, proto_loss:0.16566549241542816
2026-01-29 15:15:58.819 | INFO     | __main__:main_worker:429 - [62/100], remain:0d.00h.16m, It:[30/54], Max-Mem:11247M, Data-Time:1.377, LR:0.0000, Train_Loss:0.7805, total_loss:tensor([0.7805], device='cuda:0'), ce_loss:0.9944759607315063, cluster_loss:0.12899687886238098, sep_loss:0.07531380653381348, soft_orth_loss:0.0023450672160834074, local_consistency_loss:0.0002903610875364393, proto_loss:0.20694611966609955
2026-01-29 15:16:03.081 | INFO     | __main__:main_worker:429 - [62/100], remain:0d.00h.16m, It:[40/54], Max-Mem:11247M, Data-Time:0.858, LR:0.0000, Train_Loss:0.0733, total_loss:tensor([0.0733], device='cuda:0'), ce_loss:0.5896753072738647, cluster_loss:0.07487454265356064, sep_loss:0.06627929955720901, soft_orth_loss:0.0023403088562190533, local_consistency_loss:0.0003841692232526839, proto_loss:0.14387831091880798
2026-01-29 15:16:06.869 | INFO     | __main__:main_worker:429 - [62/100], remain:0d.00h.15m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.9581, total_loss:tensor([0.9581], device='cuda:0'), ce_loss:1.0724443197250366, cluster_loss:0.15788231790065765, sep_loss:0.07900688797235489, soft_orth_loss:0.0023350142873823643, local_consistency_loss:0.0005350098363123834, proto_loss:0.23975923657417297
Evaluating: 100%|| 15/15 [00:07<00:00,  1.88it/s]
acc1: 86.1111, acc3: 100.0000, Precision: 0.7765, Recall: 0.8569, F1-Score: 0.8071, Specificity: 0.9302
2026-01-29 15:16:16.507 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [62/100], Top1:86.111, Top3:100.000, Test_precision:0.7765,Test_recall:0.8569,Test_f1:0.8071,,Test_specificity:0.9302 Test_loss:0.398107
2026-01-29 15:16:16.508 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:16:16.508 | INFO     | __main__:main_worker:355 - ---> start train epoch63
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:16:25.354 | INFO     | __main__:main_worker:429 - [63/100], remain:0d.00h.15m, It:[10/54], Max-Mem:11247M, Data-Time:0.756, LR:0.0000, Train_Loss:0.3715, total_loss:tensor([0.3715], device='cuda:0'), ce_loss:0.75035160779953, cluster_loss:0.10565271228551865, sep_loss:0.06837600469589233, soft_orth_loss:0.002326037734746933, local_consistency_loss:0.0014389001298695803, proto_loss:0.17779366672039032
2026-01-29 15:16:30.028 | INFO     | __main__:main_worker:429 - [63/100], remain:0d.00h.15m, It:[20/54], Max-Mem:11247M, Data-Time:0.018, LR:0.0000, Train_Loss:0.1961, total_loss:tensor([0.1961], device='cuda:0'), ce_loss:0.644373893737793, cluster_loss:0.09366649389266968, sep_loss:0.06944036483764648, soft_orth_loss:0.0023178397677838802, local_consistency_loss:0.0007909070700407028, proto_loss:0.16621561348438263
2026-01-29 15:16:35.570 | INFO     | __main__:main_worker:429 - [63/100], remain:0d.00h.16m, It:[30/54], Max-Mem:11247M, Data-Time:0.022, LR:0.0000, Train_Loss:0.4025, total_loss:tensor([0.4025], device='cuda:0'), ce_loss:0.7600651383399963, cluster_loss:0.10567078739404678, sep_loss:0.07796739041805267, soft_orth_loss:0.0023103985004127026, local_consistency_loss:0.0005370377912186086, proto_loss:0.18648561835289001
2026-01-29 15:16:39.064 | INFO     | __main__:main_worker:429 - [63/100], remain:0d.00h.15m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.0959, total_loss:tensor([0.0959], device='cuda:0'), ce_loss:0.5789980888366699, cluster_loss:0.09731137007474899, sep_loss:0.06310462951660156, soft_orth_loss:0.002306093228980899, local_consistency_loss:0.0004335617704782635, proto_loss:0.163155660033226
2026-01-29 15:16:43.342 | INFO     | __main__:main_worker:429 - [63/100], remain:0d.00h.14m, It:[50/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.4677, total_loss:tensor([0.4677], device='cuda:0'), ce_loss:0.7941484451293945, cluster_loss:0.11672480404376984, sep_loss:0.07528110593557358, soft_orth_loss:0.002300368156284094, local_consistency_loss:0.0004594768979586661, proto_loss:0.19476574659347534
Evaluating: 100%|| 15/15 [00:07<00:00,  1.90it/s]
acc1: 86.5385, acc3: 100.0000, Precision: 0.7854, Recall: 0.8174, F1-Score: 0.7990, Specificity: 0.9267
2026-01-29 15:16:52.583 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [63/100], Top1:86.538, Top3:100.000, Test_precision:0.7854,Test_recall:0.8174,Test_f1:0.7990,,Test_specificity:0.9267 Test_loss:0.393326
2026-01-29 15:16:52.584 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:16:52.585 | INFO     | __main__:main_worker:355 - ---> start train epoch64
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:17:02.461 | INFO     | __main__:main_worker:429 - [64/100], remain:0d.00h.16m, It:[10/54], Max-Mem:11247M, Data-Time:1.494, LR:0.0000, Train_Loss:-0.0906, total_loss:tensor([-0.0906], device='cuda:0'), ce_loss:0.5017969608306885, cluster_loss:0.05688166618347168, sep_loss:0.06612328439950943, soft_orth_loss:0.0022930761333554983, local_consistency_loss:0.00047279862337745726, proto_loss:0.12577082216739655
2026-01-29 15:17:07.369 | INFO     | __main__:main_worker:429 - [64/100], remain:0d.00h.16m, It:[20/54], Max-Mem:11247M, Data-Time:1.490, LR:0.0000, Train_Loss:2.1148, total_loss:tensor([2.1148], device='cuda:0'), ce_loss:1.7367746829986572, cluster_loss:0.24913373589515686, sep_loss:0.09010136127471924, soft_orth_loss:0.0022864171769469976, local_consistency_loss:0.0007225157460197806, proto_loss:0.342244029045105
2026-01-29 15:17:11.247 | INFO     | __main__:main_worker:429 - [64/100], remain:0d.00h.14m, It:[30/54], Max-Mem:11247M, Data-Time:0.440, LR:0.0000, Train_Loss:0.0425, total_loss:tensor([0.0425], device='cuda:0'), ce_loss:0.5516011118888855, cluster_loss:0.08739173412322998, sep_loss:0.06650452315807343, soft_orth_loss:0.0022801689337939024, local_consistency_loss:0.00025408054352737963, proto_loss:0.15643051266670227
2026-01-29 15:17:15.673 | INFO     | __main__:main_worker:429 - [64/100], remain:0d.00h.14m, It:[40/54], Max-Mem:11247M, Data-Time:0.585, LR:0.0000, Train_Loss:-0.1251, total_loss:tensor([-0.1251], device='cuda:0'), ce_loss:0.45148521661758423, cluster_loss:0.07541095465421677, sep_loss:0.0663028359413147, soft_orth_loss:0.002273714868351817, local_consistency_loss:0.0005374274333007634, proto_loss:0.1445249319076538
2026-01-29 15:17:19.841 | INFO     | __main__:main_worker:429 - [64/100], remain:0d.00h.14m, It:[50/54], Max-Mem:11247M, Data-Time:0.020, LR:0.0000, Train_Loss:0.7145, total_loss:tensor([0.7145], device='cuda:0'), ce_loss:0.9415934085845947, cluster_loss:0.12664690613746643, sep_loss:0.0834433063864708, soft_orth_loss:0.002267749747261405, local_consistency_loss:0.0005535603850148618, proto_loss:0.21291153132915497
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 15:17:29.955 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [64/100], Top1:85.043, Top3:100.000, Test_precision:0.7508,Test_recall:0.8370,Test_f1:0.7791,,Test_specificity:0.9293 Test_loss:0.459942
2026-01-29 15:17:29.956 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:17:29.956 | INFO     | __main__:main_worker:355 - ---> start train epoch65
acc1: 85.0427, acc3: 100.0000, Precision: 0.7508, Recall: 0.8370, F1-Score: 0.7791, Specificity: 0.9293
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:17:38.417 | INFO     | __main__:main_worker:429 - [65/100], remain:0d.00h.12m, It:[10/54], Max-Mem:11247M, Data-Time:0.580, LR:0.0000, Train_Loss:-0.2032, total_loss:tensor([-0.2032], device='cuda:0'), ce_loss:0.4315283000469208, cluster_loss:0.06010090187191963, sep_loss:0.0572052001953125, soft_orth_loss:0.002259912434965372, local_consistency_loss:0.0006953405099920928, proto_loss:0.12026134878396988
2026-01-29 15:17:42.776 | INFO     | __main__:main_worker:429 - [65/100], remain:0d.00h.13m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.1817, total_loss:tensor([0.1817], device='cuda:0'), ce_loss:0.6484224200248718, cluster_loss:0.0829828679561615, sep_loss:0.07150708138942719, soft_orth_loss:0.0022545605897903442, local_consistency_loss:0.0004673534131143242, proto_loss:0.15721186995506287
2026-01-29 15:17:47.161 | INFO     | __main__:main_worker:429 - [65/100], remain:0d.00h.13m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:1.5096, total_loss:tensor([1.5096], device='cuda:0'), ce_loss:1.6601903438568115, cluster_loss:0.00037698421510867774, sep_loss:0.09081210196018219, soft_orth_loss:0.002248260658234358, local_consistency_loss:0.0048769875429570675, proto_loss:0.0983143299818039
2026-01-29 15:17:51.492 | INFO     | __main__:main_worker:429 - [65/100], remain:0d.00h.13m, It:[40/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0000, Train_Loss:0.2892, total_loss:tensor([0.2892], device='cuda:0'), ce_loss:0.6958176493644714, cluster_loss:0.10205230861902237, sep_loss:0.07223498076200485, soft_orth_loss:0.00224109529517591, local_consistency_loss:0.0004301436711102724, proto_loss:0.17695851624011993
2026-01-29 15:17:56.519 | INFO     | __main__:main_worker:429 - [65/100], remain:0d.00h.13m, It:[50/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0000, Train_Loss:0.6003, total_loss:tensor([0.6003], device='cuda:0'), ce_loss:0.8608114123344421, cluster_loss:0.1437528133392334, sep_loss:0.06752732396125793, soft_orth_loss:0.0022364214528352022, local_consistency_loss:0.0005383140523917973, proto_loss:0.2140548825263977
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 15:18:05.855 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [65/100], Top1:85.897, Top3:100.000, Test_precision:0.7630,Test_recall:0.8558,Test_f1:0.7937,,Test_specificity:0.9340 Test_loss:0.442121
2026-01-29 15:18:05.855 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
acc1: 85.8974, acc3: 100.0000, Precision: 0.7630, Recall: 0.8558, F1-Score: 0.7937, Specificity: 0.9340
2026-01-29 15:18:15.812 | INFO     | __main__:main_worker:355 - ---> start train epoch66
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:18:24.712 | INFO     | __main__:main_worker:429 - [66/100], remain:0d.00h.14m, It:[10/54], Max-Mem:11247M, Data-Time:0.439, LR:0.0000, Train_Loss:0.4413, total_loss:tensor([0.4413], device='cuda:0'), ce_loss:0.7842049598693848, cluster_loss:0.11376108974218369, sep_loss:0.07354014366865158, soft_orth_loss:0.002229503123089671, local_consistency_loss:0.00028528092661872506, proto_loss:0.18981601297855377
2026-01-29 15:18:29.229 | INFO     | __main__:main_worker:429 - [66/100], remain:0d.00h.14m, It:[20/54], Max-Mem:11247M, Data-Time:0.818, LR:0.0000, Train_Loss:-0.0262, total_loss:tensor([-0.0262], device='cuda:0'), ce_loss:0.5287502408027649, cluster_loss:0.07012882083654404, sep_loss:0.06697823852300644, soft_orth_loss:0.0022236297372728586, local_consistency_loss:0.0002701475459616631, proto_loss:0.13960082828998566
2026-01-29 15:18:34.088 | INFO     | __main__:main_worker:429 - [66/100], remain:0d.00h.14m, It:[30/54], Max-Mem:11247M, Data-Time:0.584, LR:0.0000, Train_Loss:1.1208, total_loss:tensor([1.1208], device='cuda:0'), ce_loss:1.155051827430725, cluster_loss:0.1801498681306839, sep_loss:0.08074590563774109, soft_orth_loss:0.0022188795264810324, local_consistency_loss:0.000244267750531435, proto_loss:0.2633589208126068
2026-01-29 15:18:38.125 | INFO     | __main__:main_worker:429 - [66/100], remain:0d.00h.13m, It:[40/54], Max-Mem:11247M, Data-Time:0.162, LR:0.0000, Train_Loss:0.0370, total_loss:tensor([0.0370], device='cuda:0'), ce_loss:0.5942642688751221, cluster_loss:0.048595089465379715, sep_loss:0.07351385056972504, soft_orth_loss:0.0022137663327157497, local_consistency_loss:0.0003548700478859246, proto_loss:0.12467757612466812
2026-01-29 15:18:43.181 | INFO     | __main__:main_worker:429 - [66/100], remain:0d.00h.13m, It:[50/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:0.3618, total_loss:tensor([0.3618], device='cuda:0'), ce_loss:0.7472007274627686, cluster_loss:0.10006103664636612, sep_loss:0.07436233758926392, soft_orth_loss:0.0022082296200096607, local_consistency_loss:0.0003272372705396265, proto_loss:0.1769588440656662
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 15:18:52.879 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [66/100], Top1:86.325, Top3:100.000, Test_precision:0.7673,Test_recall:0.8465,Test_f1:0.7962,,Test_specificity:0.9349 Test_loss:0.451641
2026-01-29 15:18:52.881 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:18:52.882 | INFO     | __main__:main_worker:355 - ---> start train epoch67
acc1: 86.3248, acc3: 100.0000, Precision: 0.7673, Recall: 0.8465, F1-Score: 0.7962, Specificity: 0.9349
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:19:02.463 | INFO     | __main__:main_worker:429 - [67/100], remain:0d.00h.14m, It:[10/54], Max-Mem:11247M, Data-Time:0.016, LR:0.0000, Train_Loss:0.1865, total_loss:tensor([0.1865], device='cuda:0'), ce_loss:0.6454359889030457, cluster_loss:0.07972544431686401, sep_loss:0.08022348582744598, soft_orth_loss:0.002200240967795253, local_consistency_loss:0.00029175449162721634, proto_loss:0.1624409258365631
2026-01-29 15:19:06.544 | INFO     | __main__:main_worker:429 - [67/100], remain:0d.00h.13m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.1522, total_loss:tensor([-0.1522], device='cuda:0'), ce_loss:0.4543457627296448, cluster_loss:0.0622161403298378, sep_loss:0.06553822010755539, soft_orth_loss:0.002194697503000498, local_consistency_loss:0.0003759887476917356, proto_loss:0.130325049161911
2026-01-29 15:19:11.236 | INFO     | __main__:main_worker:429 - [67/100], remain:0d.00h.13m, It:[30/54], Max-Mem:11247M, Data-Time:0.764, LR:0.0000, Train_Loss:0.2504, total_loss:tensor([0.2504], device='cuda:0'), ce_loss:0.6758875250816345, cluster_loss:0.09637586772441864, sep_loss:0.07342711836099625, soft_orth_loss:0.00218910607509315, local_consistency_loss:0.0006112761911936104, proto_loss:0.17260336875915527
2026-01-29 15:19:15.714 | INFO     | __main__:main_worker:429 - [67/100], remain:0d.00h.13m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:1.1298, total_loss:tensor([1.1298], device='cuda:0'), ce_loss:1.202255368232727, cluster_loss:0.14879922568798065, sep_loss:0.08368878811597824, soft_orth_loss:0.0021846548188477755, local_consistency_loss:0.000340791855705902, proto_loss:0.2350134551525116
2026-01-29 15:19:19.836 | INFO     | __main__:main_worker:429 - [67/100], remain:0d.00h.12m, It:[50/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.7414, total_loss:tensor([0.7414], device='cuda:0'), ce_loss:0.9778262972831726, cluster_loss:0.1113704964518547, sep_loss:0.08811664581298828, soft_orth_loss:0.0021797989029437304, local_consistency_loss:0.00023848477576393634, proto_loss:0.20190542936325073
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 15:19:30.013 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [67/100], Top1:86.752, Top3:100.000, Test_precision:0.7818,Test_recall:0.8474,Test_f1:0.8079,,Test_specificity:0.9301 Test_loss:0.411963
acc1: 86.7521, acc3: 100.0000, Precision: 0.7818, Recall: 0.8474, F1-Score: 0.8079, Specificity: 0.9301
2026-01-29 15:19:30.014 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:19:30.015 | INFO     | __main__:main_worker:355 - ---> start train epoch68
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:19:40.339 | INFO     | __main__:main_worker:429 - [68/100], remain:0d.00h.15m, It:[10/54], Max-Mem:11247M, Data-Time:1.852, LR:0.0000, Train_Loss:0.1197, total_loss:tensor([0.1197], device='cuda:0'), ce_loss:0.6047298908233643, cluster_loss:0.08239412307739258, sep_loss:0.07258135080337524, soft_orth_loss:0.0021729080472141504, local_consistency_loss:0.0014544903533533216, proto_loss:0.15860286355018616
2026-01-29 15:19:44.534 | INFO     | __main__:main_worker:429 - [68/100], remain:0d.00h.13m, It:[20/54], Max-Mem:11247M, Data-Time:0.830, LR:0.0000, Train_Loss:0.0228, total_loss:tensor([0.0228], device='cuda:0'), ce_loss:0.5546247363090515, cluster_loss:0.0739971324801445, sep_loss:0.06987453252077103, soft_orth_loss:0.0021680621430277824, local_consistency_loss:0.0002650334208738059, proto_loss:0.14630475640296936
2026-01-29 15:19:48.577 | INFO     | __main__:main_worker:429 - [68/100], remain:0d.00h.12m, It:[30/54], Max-Mem:11247M, Data-Time:0.659, LR:0.0000, Train_Loss:-0.1157, total_loss:tensor([-0.1157], device='cuda:0'), ce_loss:0.4725475311279297, cluster_loss:0.07421747595071793, sep_loss:0.05755692720413208, soft_orth_loss:0.002164125442504883, local_consistency_loss:0.0020631959196180105, proto_loss:0.13600172102451324
2026-01-29 15:19:52.512 | INFO     | __main__:main_worker:429 - [68/100], remain:0d.00h.12m, It:[40/54], Max-Mem:11247M, Data-Time:0.581, LR:0.0000, Train_Loss:2.5781, total_loss:tensor([2.5781], device='cuda:0'), ce_loss:2.0547502040863037, cluster_loss:0.2533319890499115, sep_loss:0.09117910265922546, soft_orth_loss:0.0021594499703496695, local_consistency_loss:0.0012464652536436915, proto_loss:0.34791699051856995
2026-01-29 15:19:55.987 | INFO     | __main__:main_worker:429 - [68/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.027, LR:0.0000, Train_Loss:1.9671, total_loss:tensor([1.9671], device='cuda:0'), ce_loss:1.7446593046188354, cluster_loss:0.16890573501586914, sep_loss:0.09271353483200073, soft_orth_loss:0.002155240625143051, local_consistency_loss:0.0018361179390922189, proto_loss:0.26561063528060913
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 88.0342, acc3: 100.0000, Precision: 0.8039, Recall: 0.8610, F1-Score: 0.8281, Specificity: 0.9369
2026-01-29 15:20:05.502 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [68/100], Top1:88.034, Top3:100.000, Test_precision:0.8039,Test_recall:0.8610,Test_f1:0.8281,,Test_specificity:0.9369 Test_loss:0.395844
2026-01-29 15:20:05.503 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:20:05.503 | INFO     | __main__:main_worker:355 - ---> start train epoch69
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:20:14.372 | INFO     | __main__:main_worker:429 - [69/100], remain:0d.00h.13m, It:[10/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.5461, total_loss:tensor([0.5461], device='cuda:0'), ce_loss:0.8367344737052917, cluster_loss:0.1242927834391594, sep_loss:0.07862643152475357, soft_orth_loss:0.002149586332961917, local_consistency_loss:0.0003709464508574456, proto_loss:0.2054397463798523
2026-01-29 15:20:19.540 | INFO     | __main__:main_worker:429 - [69/100], remain:0d.00h.13m, It:[20/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.1716, total_loss:tensor([0.1716], device='cuda:0'), ce_loss:0.6328364610671997, cluster_loss:0.09777393192052841, sep_loss:0.06457951664924622, soft_orth_loss:0.002145899925380945, local_consistency_loss:0.000315934419631958, proto_loss:0.164815291762352
2026-01-29 15:20:23.372 | INFO     | __main__:main_worker:429 - [69/100], remain:0d.00h.12m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.1221, total_loss:tensor([-0.1221], device='cuda:0'), ce_loss:0.4789552688598633, cluster_loss:0.06560070067644119, sep_loss:0.06061359494924545, soft_orth_loss:0.0021415995433926582, local_consistency_loss:0.00034648634027689695, proto_loss:0.12870237231254578
2026-01-29 15:20:27.222 | INFO     | __main__:main_worker:429 - [69/100], remain:0d.00h.12m, It:[40/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.1921, total_loss:tensor([0.1921], device='cuda:0'), ce_loss:0.6434754133224487, cluster_loss:0.09679227322340012, sep_loss:0.06835736334323883, soft_orth_loss:0.0021372006740421057, local_consistency_loss:0.00021123750775586814, proto_loss:0.16749806702136993
2026-01-29 15:20:31.540 | INFO     | __main__:main_worker:429 - [69/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.5353, total_loss:tensor([0.5353], device='cuda:0'), ce_loss:0.8466277718544006, cluster_loss:0.110958993434906, sep_loss:0.08017916977405548, soft_orth_loss:0.0021335568744689226, local_consistency_loss:0.0001633859792491421, proto_loss:0.19343511760234833
Evaluating: 100%|| 15/15 [00:07<00:00,  1.89it/s]
acc1: 86.9658, acc3: 100.0000, Precision: 0.7770, Recall: 0.8188, F1-Score: 0.7949, Specificity: 0.9281
2026-01-29 15:20:41.622 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [69/100], Top1:86.966, Top3:100.000, Test_precision:0.7770,Test_recall:0.8188,Test_f1:0.7949,,Test_specificity:0.9281 Test_loss:0.402394
2026-01-29 15:20:41.623 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:20:41.624 | INFO     | __main__:main_worker:355 - ---> start train epoch70
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:20:49.963 | INFO     | __main__:main_worker:429 - [70/100], remain:0d.00h.10m, It:[10/54], Max-Mem:11247M, Data-Time:0.522, LR:0.0000, Train_Loss:1.6108, total_loss:tensor([1.6108], device='cuda:0'), ce_loss:1.497399926185608, cluster_loss:0.1766195297241211, sep_loss:0.08478682488203049, soft_orth_loss:0.002129128435626626, local_consistency_loss:0.001079791458323598, proto_loss:0.2646152973175049
2026-01-29 15:20:54.051 | INFO     | __main__:main_worker:429 - [70/100], remain:0d.00h.10m, It:[20/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.3231, total_loss:tensor([0.3231], device='cuda:0'), ce_loss:0.7176026701927185, cluster_loss:0.10400935262441635, sep_loss:0.07351098209619522, soft_orth_loss:0.002125179162248969, local_consistency_loss:0.0003307990846224129, proto_loss:0.17997631430625916
2026-01-29 15:20:58.608 | INFO     | __main__:main_worker:429 - [70/100], remain:0d.00h.11m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.0043, total_loss:tensor([-0.0043], device='cuda:0'), ce_loss:0.527878999710083, cluster_loss:0.08657774329185486, sep_loss:0.06360699981451035, soft_orth_loss:0.0021209833212196827, local_consistency_loss:0.00017962120182346553, proto_loss:0.15248535573482513
2026-01-29 15:21:03.241 | INFO     | __main__:main_worker:429 - [70/100], remain:0d.00h.11m, It:[40/54], Max-Mem:11247M, Data-Time:0.016, LR:0.0000, Train_Loss:0.0575, total_loss:tensor([0.0575], device='cuda:0'), ce_loss:0.5718178153038025, cluster_loss:0.0907839685678482, sep_loss:0.05881212651729584, soft_orth_loss:0.00211767153814435, local_consistency_loss:0.00034653878537938, proto_loss:0.15206031501293182
2026-01-29 15:21:07.342 | INFO     | __main__:main_worker:429 - [70/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:-0.0086, total_loss:tensor([-0.0086], device='cuda:0'), ce_loss:0.5343964099884033, cluster_loss:0.0754125639796257, sep_loss:0.06821852177381516, soft_orth_loss:0.0021136743016541004, local_consistency_loss:0.00022216152865439653, proto_loss:0.14596691727638245
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
acc1: 87.8205, acc3: 100.0000, Precision: 0.7976, Recall: 0.8478, F1-Score: 0.8191, Specificity: 0.9359
2026-01-29 15:21:17.335 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [70/100], Top1:87.821, Top3:100.000, Test_precision:0.7976,Test_recall:0.8478,Test_f1:0.8191,,Test_specificity:0.9359 Test_loss:0.395520
2026-01-29 15:21:17.336 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:21:27.238 | INFO     | __main__:main_worker:355 - ---> start train epoch71
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:21:36.563 | INFO     | __main__:main_worker:429 - [71/100], remain:0d.00h.12m, It:[10/54], Max-Mem:11247M, Data-Time:1.407, LR:0.0000, Train_Loss:-0.1575, total_loss:tensor([-0.1575], device='cuda:0'), ce_loss:0.45654430985450745, cluster_loss:0.06939303874969482, sep_loss:0.055833667516708374, soft_orth_loss:0.002107632113620639, local_consistency_loss:0.00030163335031829774, proto_loss:0.12763597071170807
2026-01-29 15:21:40.638 | INFO     | __main__:main_worker:429 - [71/100], remain:0d.00h.11m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.2148, total_loss:tensor([-0.2148], device='cuda:0'), ce_loss:0.4235824644565582, cluster_loss:0.06702282279729843, sep_loss:0.053180158138275146, soft_orth_loss:0.00210333033464849, local_consistency_loss:0.00043190416181460023, proto_loss:0.12273821234703064
2026-01-29 15:21:45.303 | INFO     | __main__:main_worker:429 - [71/100], remain:0d.00h.11m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:2.2397, total_loss:tensor([2.2397], device='cuda:0'), ce_loss:1.8224302530288696, cluster_loss:0.2509710490703583, sep_loss:0.09180214256048203, soft_orth_loss:0.002099560108035803, local_consistency_loss:0.00042623162153176963, proto_loss:0.34529900550842285
2026-01-29 15:21:51.392 | INFO     | __main__:main_worker:429 - [71/100], remain:0d.00h.12m, It:[40/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:1.9011, total_loss:tensor([1.9011], device='cuda:0'), ce_loss:1.655098795890808, cluster_loss:0.202111154794693, sep_loss:0.09221184253692627, soft_orth_loss:0.002095363801345229, local_consistency_loss:0.0002961998980026692, proto_loss:0.29671457409858704
2026-01-29 15:21:55.361 | INFO     | __main__:main_worker:429 - [71/100], remain:0d.00h.12m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.2363, total_loss:tensor([0.2363], device='cuda:0'), ce_loss:0.6751664876937866, cluster_loss:0.09784311801195145, sep_loss:0.06728827953338623, soft_orth_loss:0.0020913199987262487, local_consistency_loss:0.00045058270916342735, proto_loss:0.1676732897758484
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 15:22:05.397 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [71/100], Top1:87.393, Top3:100.000, Test_precision:0.7986,Test_recall:0.8178,Test_f1:0.8076,,Test_specificity:0.9257 Test_loss:0.392008
2026-01-29 15:22:05.398 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:22:05.398 | INFO     | __main__:main_worker:355 - ---> start train epoch72
acc1: 87.3932, acc3: 100.0000, Precision: 0.7986, Recall: 0.8178, F1-Score: 0.8076, Specificity: 0.9257
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:22:15.239 | INFO     | __main__:main_worker:429 - [72/100], remain:0d.00h.13m, It:[10/54], Max-Mem:11247M, Data-Time:1.123, LR:0.0000, Train_Loss:0.7288, total_loss:tensor([0.7288], device='cuda:0'), ce_loss:0.953273355960846, cluster_loss:0.12613633275032043, sep_loss:0.08546783030033112, soft_orth_loss:0.002085871296003461, local_consistency_loss:0.0005107542965561152, proto_loss:0.21420077979564667
2026-01-29 15:22:19.286 | INFO     | __main__:main_worker:429 - [72/100], remain:0d.00h.11m, It:[20/54], Max-Mem:11247M, Data-Time:0.241, LR:0.0000, Train_Loss:0.3006, total_loss:tensor([0.3006], device='cuda:0'), ce_loss:0.8440634608268738, cluster_loss:0.0002041748957708478, sep_loss:0.07840453088283539, soft_orth_loss:0.0020822961814701557, local_consistency_loss:0.0003626154793892056, proto_loss:0.08105361461639404
2026-01-29 15:22:23.896 | INFO     | __main__:main_worker:429 - [72/100], remain:0d.00h.11m, It:[30/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.7240, total_loss:tensor([0.7240], device='cuda:0'), ce_loss:0.964012861251831, cluster_loss:0.11517789214849472, sep_loss:0.08662453293800354, soft_orth_loss:0.002078787423670292, local_consistency_loss:0.0005721561028622091, proto_loss:0.20445337891578674
2026-01-29 15:22:28.852 | INFO     | __main__:main_worker:429 - [72/100], remain:0d.00h.11m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.0761, total_loss:tensor([0.0761], device='cuda:0'), ce_loss:0.5886502265930176, cluster_loss:0.0810701847076416, sep_loss:0.0665852501988411, soft_orth_loss:0.002074649091809988, local_consistency_loss:0.0003083896590396762, proto_loss:0.1500384658575058
2026-01-29 15:22:33.702 | INFO     | __main__:main_worker:429 - [72/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:-0.1657, total_loss:tensor([-0.1657], device='cuda:0'), ce_loss:0.4343836307525635, cluster_loss:0.07524176687002182, sep_loss:0.06213266775012016, soft_orth_loss:0.0020697438158094883, local_consistency_loss:0.0002593024692032486, proto_loss:0.13970346748828888
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
2026-01-29 15:22:43.993 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [72/100], Top1:88.248, Top3:100.000, Test_precision:0.8084,Test_recall:0.8561,Test_f1:0.8290,,Test_specificity:0.9384 Test_loss:0.399917
acc1: 88.2479, acc3: 100.0000, Precision: 0.8084, Recall: 0.8561, F1-Score: 0.8290, Specificity: 0.9384
2026-01-29 15:22:43.994 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:22:43.994 | INFO     | __main__:main_worker:355 - ---> start train epoch73
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:22:53.065 | INFO     | __main__:main_worker:429 - [73/100], remain:0d.00h.12m, It:[10/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.1890, total_loss:tensor([-0.1890], device='cuda:0'), ce_loss:0.431299090385437, cluster_loss:0.06760301440954208, sep_loss:0.06066549941897392, soft_orth_loss:0.0020642781164497137, local_consistency_loss:0.0001734258112264797, proto_loss:0.13050620257854462
2026-01-29 15:22:57.290 | INFO     | __main__:main_worker:429 - [73/100], remain:0d.00h.11m, It:[20/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:-0.1432, total_loss:tensor([-0.1432], device='cuda:0'), ce_loss:0.45241960883140564, cluster_loss:0.07942382246255875, sep_loss:0.05649232119321823, soft_orth_loss:0.002060870174318552, local_consistency_loss:0.0002459593233652413, proto_loss:0.13822297751903534
2026-01-29 15:23:01.488 | INFO     | __main__:main_worker:429 - [73/100], remain:0d.00h.10m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.2526, total_loss:tensor([0.2526], device='cuda:0'), ce_loss:0.6648493409156799, cluster_loss:0.11306165903806686, sep_loss:0.06783822178840637, soft_orth_loss:0.0020576450042426586, local_consistency_loss:0.00039845603168942034, proto_loss:0.18335598707199097
2026-01-29 15:23:06.068 | INFO     | __main__:main_worker:429 - [73/100], remain:0d.00h.10m, It:[40/54], Max-Mem:11247M, Data-Time:0.023, LR:0.0000, Train_Loss:-0.0831, total_loss:tensor([-0.0831], device='cuda:0'), ce_loss:0.4883520305156708, cluster_loss:0.07963909208774567, sep_loss:0.060656122863292694, soft_orth_loss:0.0020551022607833147, local_consistency_loss:0.0002730816777329892, proto_loss:0.1426233947277069
2026-01-29 15:23:11.900 | INFO     | __main__:main_worker:429 - [73/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:-0.0946, total_loss:tensor([-0.0946], device='cuda:0'), ce_loss:0.48166167736053467, cluster_loss:0.08083903044462204, sep_loss:0.058464378118515015, soft_orth_loss:0.002052685944363475, local_consistency_loss:0.0003415348764974624, proto_loss:0.14169763028621674
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
acc1: 86.3248, acc3: 100.0000, Precision: 0.7589, Recall: 0.8308, F1-Score: 0.7821, Specificity: 0.9352
2026-01-29 15:23:23.169 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [73/100], Top1:86.325, Top3:100.000, Test_precision:0.7589,Test_recall:0.8308,Test_f1:0.7821,,Test_specificity:0.9352 Test_loss:0.444290
2026-01-29 15:23:23.170 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:23:23.170 | INFO     | __main__:main_worker:355 - ---> start train epoch74
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:23:31.865 | INFO     | __main__:main_worker:429 - [74/100], remain:0d.00h.11m, It:[10/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.1767, total_loss:tensor([-0.1767], device='cuda:0'), ce_loss:0.4370131492614746, cluster_loss:0.06749794632196426, sep_loss:0.06245177239179611, soft_orth_loss:0.0020480751991271973, local_consistency_loss:0.0008596681291237473, proto_loss:0.13285745680332184
2026-01-29 15:23:35.714 | INFO     | __main__:main_worker:429 - [74/100], remain:0d.00h.10m, It:[20/54], Max-Mem:11247M, Data-Time:0.016, LR:0.0000, Train_Loss:-0.2361, total_loss:tensor([-0.2361], device='cuda:0'), ce_loss:0.4262084364891052, cluster_loss:0.05587030574679375, sep_loss:0.05282559245824814, soft_orth_loss:0.002044353634119034, local_consistency_loss:0.0006772064953111112, proto_loss:0.11141745001077652
2026-01-29 15:23:41.441 | INFO     | __main__:main_worker:429 - [74/100], remain:0d.00h.11m, It:[30/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:-0.0935, total_loss:tensor([-0.0935], device='cuda:0'), ce_loss:0.47574275732040405, cluster_loss:0.08052005618810654, sep_loss:0.06377898156642914, soft_orth_loss:0.0020407435949891806, local_consistency_loss:0.00019147561397403479, proto_loss:0.14653125405311584
2026-01-29 15:23:47.081 | INFO     | __main__:main_worker:429 - [74/100], remain:0d.00h.11m, It:[40/54], Max-Mem:11247M, Data-Time:0.026, LR:0.0000, Train_Loss:-0.0339, total_loss:tensor([-0.0339], device='cuda:0'), ce_loss:0.5183660387992859, cluster_loss:0.07743346691131592, sep_loss:0.0660824179649353, soft_orth_loss:0.0020372718572616577, local_consistency_loss:0.0003798158431891352, proto_loss:0.14593297243118286
2026-01-29 15:23:51.011 | INFO     | __main__:main_worker:429 - [74/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.405, LR:0.0000, Train_Loss:2.2644, total_loss:tensor([2.2644], device='cuda:0'), ce_loss:1.8762292861938477, cluster_loss:0.2238134890794754, sep_loss:0.09246798604726791, soft_orth_loss:0.0020340278279036283, local_consistency_loss:0.002206274541094899, proto_loss:0.3205217719078064
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 86.5385, acc3: 100.0000, Precision: 0.7739, Recall: 0.8555, F1-Score: 0.8016, Specificity: 0.9325
2026-01-29 15:24:00.443 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [74/100], Top1:86.538, Top3:100.000, Test_precision:0.7739,Test_recall:0.8555,Test_f1:0.8016,,Test_specificity:0.9325 Test_loss:0.422514
2026-01-29 15:24:00.443 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:24:00.444 | INFO     | __main__:main_worker:355 - ---> start train epoch75
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:24:09.514 | INFO     | __main__:main_worker:429 - [75/100], remain:0d.00h.12m, It:[10/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.4569, total_loss:tensor([0.4569], device='cuda:0'), ce_loss:0.7932730913162231, cluster_loss:0.11863993853330612, sep_loss:0.0729089304804802, soft_orth_loss:0.0020289532840251923, local_consistency_loss:0.0002605163608677685, proto_loss:0.19383834302425385
2026-01-29 15:24:13.706 | INFO     | __main__:main_worker:429 - [75/100], remain:0d.00h.11m, It:[20/54], Max-Mem:11247M, Data-Time:0.498, LR:0.0000, Train_Loss:0.0754, total_loss:tensor([0.0754], device='cuda:0'), ce_loss:0.5737404823303223, cluster_loss:0.08983325213193893, sep_loss:0.06861831992864609, soft_orth_loss:0.0020258291624486446, local_consistency_loss:0.00035579397808760405, proto_loss:0.1608331948518753
2026-01-29 15:24:19.396 | INFO     | __main__:main_worker:429 - [75/100], remain:0d.00h.11m, It:[30/54], Max-Mem:11247M, Data-Time:0.802, LR:0.0000, Train_Loss:0.1319, total_loss:tensor([0.1319], device='cuda:0'), ce_loss:0.597985565662384, cluster_loss:0.09929818660020828, sep_loss:0.06995151937007904, soft_orth_loss:0.002022653818130493, local_consistency_loss:0.00029825055389665067, proto_loss:0.17157061398029327
2026-01-29 15:24:24.588 | INFO     | __main__:main_worker:429 - [75/100], remain:0d.00h.11m, It:[40/54], Max-Mem:11247M, Data-Time:1.615, LR:0.0000, Train_Loss:0.0894, total_loss:tensor([0.0894], device='cuda:0'), ce_loss:0.5933613777160645, cluster_loss:0.08885719627141953, sep_loss:0.06284116953611374, soft_orth_loss:0.002020403742790222, local_consistency_loss:0.0003950654936488718, proto_loss:0.15411382913589478
2026-01-29 15:24:28.826 | INFO     | __main__:main_worker:429 - [75/100], remain:0d.00h.11m, It:[50/54], Max-Mem:11247M, Data-Time:0.811, LR:0.0000, Train_Loss:1.0458, total_loss:tensor([1.0458], device='cuda:0'), ce_loss:1.149945616722107, cluster_loss:0.1536886990070343, sep_loss:0.07649131119251251, soft_orth_loss:0.0020186337642371655, local_consistency_loss:0.0003359595430083573, proto_loss:0.23253460228443146
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
acc1: 86.5385, acc3: 100.0000, Precision: 0.7669, Recall: 0.8462, F1-Score: 0.7944, Specificity: 0.9356
2026-01-29 15:24:38.314 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [75/100], Top1:86.538, Top3:100.000, Test_precision:0.7669,Test_recall:0.8462,Test_f1:0.7944,,Test_specificity:0.9356 Test_loss:0.426858
2026-01-29 15:24:38.315 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:24:54.444 | INFO     | __main__:main_worker:355 - ---> start train epoch76
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:25:03.061 | INFO     | __main__:main_worker:429 - [76/100], remain:0d.00h.10m, It:[10/54], Max-Mem:11247M, Data-Time:0.087, LR:0.0000, Train_Loss:0.6608, total_loss:tensor([0.6608], device='cuda:0'), ce_loss:1.08999764919281, cluster_loss:0.0002612053067423403, sep_loss:0.08365403115749359, soft_orth_loss:0.002014987403526902, local_consistency_loss:0.0006138768512755632, proto_loss:0.08654409646987915
2026-01-29 15:25:07.897 | INFO     | __main__:main_worker:429 - [76/100], remain:0d.00h.10m, It:[20/54], Max-Mem:11247M, Data-Time:0.143, LR:0.0000, Train_Loss:-0.2461, total_loss:tensor([-0.2461], device='cuda:0'), ce_loss:0.48989081382751465, cluster_loss:0.00018097581050824374, sep_loss:0.0602208636701107, soft_orth_loss:0.0020117568783462048, local_consistency_loss:0.0002869391755666584, proto_loss:0.0627005323767662
2026-01-29 15:25:13.280 | INFO     | __main__:main_worker:429 - [76/100], remain:0d.00h.10m, It:[30/54], Max-Mem:11247M, Data-Time:1.048, LR:0.0000, Train_Loss:0.2769, total_loss:tensor([0.2769], device='cuda:0'), ce_loss:0.7031808495521545, cluster_loss:0.10371015220880508, sep_loss:0.06302305310964584, soft_orth_loss:0.0020090292673557997, local_consistency_loss:0.0004287066403776407, proto_loss:0.16917094588279724
2026-01-29 15:25:17.884 | INFO     | __main__:main_worker:429 - [76/100], remain:0d.00h.10m, It:[40/54], Max-Mem:11247M, Data-Time:0.723, LR:0.0000, Train_Loss:-0.2233, total_loss:tensor([-0.2233], device='cuda:0'), ce_loss:0.396663635969162, cluster_loss:0.08288127928972244, sep_loss:0.05391029641032219, soft_orth_loss:0.0020066939759999514, local_consistency_loss:0.00019908540707547218, proto_loss:0.13899734616279602
2026-01-29 15:25:22.494 | INFO     | __main__:main_worker:429 - [76/100], remain:0d.00h.10m, It:[50/54], Max-Mem:11247M, Data-Time:0.630, LR:0.0000, Train_Loss:1.2983, total_loss:tensor([1.2983], device='cuda:0'), ce_loss:1.2854777574539185, cluster_loss:0.17043302953243256, sep_loss:0.0879008024930954, soft_orth_loss:0.0020040806848555803, local_consistency_loss:0.0009956291178241372, proto_loss:0.26133355498313904
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
2026-01-29 15:25:33.056 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [76/100], Top1:87.821, Top3:100.000, Test_precision:0.7977,Test_recall:0.8297,Test_f1:0.8105,,Test_specificity:0.9381 Test_loss:0.359685
2026-01-29 15:25:33.057 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:25:33.057 | INFO     | __main__:main_worker:355 - ---> start train epoch77
acc1: 87.8205, acc3: 100.0000, Precision: 0.7977, Recall: 0.8297, F1-Score: 0.8105, Specificity: 0.9381
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:25:42.597 | INFO     | __main__:main_worker:429 - [77/100], remain:0d.00h.09m, It:[10/54], Max-Mem:11247M, Data-Time:1.259, LR:0.0000, Train_Loss:-0.0948, total_loss:tensor([-0.0948], device='cuda:0'), ce_loss:0.4984843134880066, cluster_loss:0.07716836780309677, sep_loss:0.05125102028250694, soft_orth_loss:0.002000251552090049, local_consistency_loss:0.0003478618455119431, proto_loss:0.13076750934123993
2026-01-29 15:25:47.362 | INFO     | __main__:main_worker:429 - [77/100], remain:0d.00h.09m, It:[20/54], Max-Mem:11247M, Data-Time:1.273, LR:0.0000, Train_Loss:1.3879, total_loss:tensor([1.3879], device='cuda:0'), ce_loss:1.365171194076538, cluster_loss:0.16177530586719513, sep_loss:0.08499734103679657, soft_orth_loss:0.0019972475711256266, local_consistency_loss:0.0007232818170450628, proto_loss:0.24949318170547485
2026-01-29 15:25:51.435 | INFO     | __main__:main_worker:429 - [77/100], remain:0d.00h.09m, It:[30/54], Max-Mem:11247M, Data-Time:0.669, LR:0.0000, Train_Loss:1.8349, total_loss:tensor([1.8349], device='cuda:0'), ce_loss:1.6228619813919067, cluster_loss:0.19146743416786194, sep_loss:0.09403984993696213, soft_orth_loss:0.0019940503407269716, local_consistency_loss:0.00031913822749629617, proto_loss:0.2878204882144928
2026-01-29 15:25:55.684 | INFO     | __main__:main_worker:429 - [77/100], remain:0d.00h.09m, It:[40/54], Max-Mem:11247M, Data-Time:0.661, LR:0.0000, Train_Loss:0.6346, total_loss:tensor([0.6346], device='cuda:0'), ce_loss:0.9027639031410217, cluster_loss:0.1221214160323143, sep_loss:0.08005576580762863, soft_orth_loss:0.0019913995638489723, local_consistency_loss:0.0004746511986013502, proto_loss:0.20464323461055756
2026-01-29 15:26:00.648 | INFO     | __main__:main_worker:429 - [77/100], remain:0d.00h.09m, It:[50/54], Max-Mem:11247M, Data-Time:1.589, LR:0.0000, Train_Loss:-0.1037, total_loss:tensor([-0.1037], device='cuda:0'), ce_loss:0.49624621868133545, cluster_loss:0.06645804643630981, sep_loss:0.05927368253469467, soft_orth_loss:0.0019893446005880833, local_consistency_loss:0.0003734075871761888, proto_loss:0.12809449434280396
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
acc1: 87.1795, acc3: 100.0000, Precision: 0.7844, Recall: 0.8389, F1-Score: 0.8072, Specificity: 0.9326
2026-01-29 15:26:10.323 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [77/100], Top1:87.179, Top3:100.000, Test_precision:0.7844,Test_recall:0.8389,Test_f1:0.8072,,Test_specificity:0.9326 Test_loss:0.405257
2026-01-29 15:26:10.324 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:26:10.324 | INFO     | __main__:main_worker:355 - ---> start train epoch78
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:26:18.794 | INFO     | __main__:main_worker:429 - [78/100], remain:0d.00h.08m, It:[10/54], Max-Mem:11247M, Data-Time:0.444, LR:0.0000, Train_Loss:0.1321, total_loss:tensor([0.1321], device='cuda:0'), ce_loss:0.6164539456367493, cluster_loss:0.08941859006881714, sep_loss:0.06758787482976913, soft_orth_loss:0.0019856065046042204, local_consistency_loss:0.0003105269279330969, proto_loss:0.15930260717868805
2026-01-29 15:26:23.873 | INFO     | __main__:main_worker:429 - [78/100], remain:0d.00h.09m, It:[20/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.5481, total_loss:tensor([0.5481], device='cuda:0'), ce_loss:0.8546140789985657, cluster_loss:0.11337178200483322, sep_loss:0.08055140823125839, soft_orth_loss:0.0019825634080916643, local_consistency_loss:0.0002551936195231974, proto_loss:0.1961609572172165
2026-01-29 15:26:28.513 | INFO     | __main__:main_worker:429 - [78/100], remain:0d.00h.09m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.1919, total_loss:tensor([0.1919], device='cuda:0'), ce_loss:0.6443598866462708, cluster_loss:0.09191632270812988, sep_loss:0.07498156279325485, soft_orth_loss:0.001980168977752328, local_consistency_loss:0.00020461557141970843, proto_loss:0.16908268630504608
2026-01-29 15:26:32.132 | INFO     | __main__:main_worker:429 - [78/100], remain:0d.00h.08m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.0940, total_loss:tensor([0.0940], device='cuda:0'), ce_loss:0.6304471492767334, cluster_loss:0.06031620129942894, sep_loss:0.0685260072350502, soft_orth_loss:0.001978192012757063, local_consistency_loss:0.00028454544371925294, proto_loss:0.1311049461364746
2026-01-29 15:26:35.640 | INFO     | __main__:main_worker:429 - [78/100], remain:0d.00h.08m, It:[50/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:0.4429, total_loss:tensor([0.4429], device='cuda:0'), ce_loss:0.7886289954185486, cluster_loss:0.11027010530233383, sep_loss:0.0784093365073204, soft_orth_loss:0.001976404106244445, local_consistency_loss:0.00033822745899669826, proto_loss:0.19099406898021698
Evaluating: 100%|| 15/15 [00:08<00:00,  1.86it/s]
2026-01-29 15:26:46.303 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [78/100], Top1:86.325, Top3:100.000, Test_precision:0.7686,Test_recall:0.8297,Test_f1:0.7930,,Test_specificity:0.9328 Test_loss:0.405057
2026-01-29 15:26:46.304 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:26:46.305 | INFO     | __main__:main_worker:355 - ---> start train epoch79
acc1: 86.3248, acc3: 100.0000, Precision: 0.7686, Recall: 0.8297, F1-Score: 0.7930, Specificity: 0.9328
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:26:55.220 | INFO     | __main__:main_worker:429 - [79/100], remain:0d.00h.08m, It:[10/54], Max-Mem:11247M, Data-Time:0.692, LR:0.0000, Train_Loss:-0.0361, total_loss:tensor([-0.0361], device='cuda:0'), ce_loss:0.509732186794281, cluster_loss:0.08232580870389938, sep_loss:0.06662456691265106, soft_orth_loss:0.0019738737028092146, local_consistency_loss:0.0009916425915434957, proto_loss:0.15191587805747986
2026-01-29 15:26:59.254 | INFO     | __main__:main_worker:429 - [79/100], remain:0d.00h.08m, It:[20/54], Max-Mem:11247M, Data-Time:0.215, LR:0.0000, Train_Loss:0.1520, total_loss:tensor([0.1520], device='cuda:0'), ce_loss:0.7500836253166199, cluster_loss:0.00019757867266889662, sep_loss:0.0731307864189148, soft_orth_loss:0.00197144434787333, local_consistency_loss:0.0009064603946171701, proto_loss:0.076206274330616
2026-01-29 15:27:05.004 | INFO     | __main__:main_worker:429 - [79/100], remain:0d.00h.09m, It:[30/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.3394, total_loss:tensor([0.3394], device='cuda:0'), ce_loss:0.7450286746025085, cluster_loss:0.09734503924846649, sep_loss:0.07138294726610184, soft_orth_loss:0.0019692042842507362, local_consistency_loss:0.0003517668228596449, proto_loss:0.17104896903038025
2026-01-29 15:27:09.600 | INFO     | __main__:main_worker:429 - [79/100], remain:0d.00h.08m, It:[40/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:2.2866, total_loss:tensor([2.2866], device='cuda:0'), ce_loss:1.9101622104644775, cluster_loss:0.2139655202627182, sep_loss:0.09145966172218323, soft_orth_loss:0.001967440592125058, local_consistency_loss:0.000705492973793298, proto_loss:0.30809807777404785
2026-01-29 15:27:13.797 | INFO     | __main__:main_worker:429 - [79/100], remain:0d.00h.08m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.0533, total_loss:tensor([0.0533], device='cuda:0'), ce_loss:0.5779926776885986, cluster_loss:0.07966670393943787, sep_loss:0.06612442433834076, soft_orth_loss:0.0019653155468404293, local_consistency_loss:0.00028564222157001495, proto_loss:0.14804208278656006
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
2026-01-29 15:27:24.641 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [79/100], Top1:87.607, Top3:100.000, Test_precision:0.8033,Test_recall:0.8249,Test_f1:0.8131,,Test_specificity:0.9303 Test_loss:0.380590
acc1: 87.6068, acc3: 100.0000, Precision: 0.8033, Recall: 0.8249, F1-Score: 0.8131, Specificity: 0.9303
2026-01-29 15:27:24.642 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:27:24.642 | INFO     | __main__:main_worker:355 - ---> start train epoch80
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:27:34.282 | INFO     | __main__:main_worker:429 - [80/100], remain:0d.00h.09m, It:[10/54], Max-Mem:11247M, Data-Time:1.307, LR:0.0000, Train_Loss:-0.2563, total_loss:tensor([-0.2563], device='cuda:0'), ce_loss:0.3788670003414154, cluster_loss:0.07247277349233627, sep_loss:0.06122353672981262, soft_orth_loss:0.0019616137724369764, local_consistency_loss:0.0002869660092983395, proto_loss:0.1359449028968811
2026-01-29 15:27:38.196 | INFO     | __main__:main_worker:429 - [80/100], remain:0d.00h.08m, It:[20/54], Max-Mem:11247M, Data-Time:0.492, LR:0.0000, Train_Loss:0.1219, total_loss:tensor([0.1219], device='cuda:0'), ce_loss:0.6487058997154236, cluster_loss:0.055084336549043655, sep_loss:0.07448746263980865, soft_orth_loss:0.001959514571353793, local_consistency_loss:0.0007806820794939995, proto_loss:0.13231199979782104
2026-01-29 15:27:42.270 | INFO     | __main__:main_worker:429 - [80/100], remain:0d.00h.07m, It:[30/54], Max-Mem:11247M, Data-Time:0.712, LR:0.0000, Train_Loss:1.0275, total_loss:tensor([1.0275], device='cuda:0'), ce_loss:1.1271029710769653, cluster_loss:0.15053454041481018, sep_loss:0.08727212250232697, soft_orth_loss:0.0019575958140194416, local_consistency_loss:0.0005132025107741356, proto_loss:0.2402774542570114
2026-01-29 15:27:46.810 | INFO     | __main__:main_worker:429 - [80/100], remain:0d.00h.07m, It:[40/54], Max-Mem:11247M, Data-Time:0.859, LR:0.0000, Train_Loss:2.5111, total_loss:tensor([2.5111], device='cuda:0'), ce_loss:2.024120807647705, cluster_loss:0.24089811742305756, sep_loss:0.09422724694013596, soft_orth_loss:0.0019556013867259026, local_consistency_loss:0.0011699742171913385, proto_loss:0.33825093507766724
2026-01-29 15:27:52.031 | INFO     | __main__:main_worker:429 - [80/100], remain:0d.00h.08m, It:[50/54], Max-Mem:11247M, Data-Time:0.830, LR:0.0000, Train_Loss:1.7787, total_loss:tensor([1.7787], device='cuda:0'), ce_loss:1.5983530282974243, cluster_loss:0.18360905349254608, sep_loss:0.09196861833333969, soft_orth_loss:0.001953614642843604, local_consistency_loss:0.0005392823368310928, proto_loss:0.2780705392360687
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
acc1: 88.4615, acc3: 100.0000, Precision: 0.8042, Recall: 0.8438, F1-Score: 0.8213, Specificity: 0.9413
2026-01-29 15:28:01.634 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [80/100], Top1:88.462, Top3:100.000, Test_precision:0.8042,Test_recall:0.8438,Test_f1:0.8213,,Test_specificity:0.9413 Test_loss:0.395487
2026-01-29 15:28:01.634 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:28:20.340 | INFO     | __main__:main_worker:355 - ---> start train epoch81
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:28:30.112 | INFO     | __main__:main_worker:429 - [81/100], remain:0d.00h.08m, It:[10/54], Max-Mem:11247M, Data-Time:1.302, LR:0.0000, Train_Loss:0.0718, total_loss:tensor([0.0718], device='cuda:0'), ce_loss:0.6983925104141235, cluster_loss:0.0002517510438337922, sep_loss:0.07099644094705582, soft_orth_loss:0.001950184698216617, local_consistency_loss:0.0002924230939242989, proto_loss:0.07349079102277756
2026-01-29 15:28:34.087 | INFO     | __main__:main_worker:429 - [81/100], remain:0d.00h.07m, It:[20/54], Max-Mem:11247M, Data-Time:0.554, LR:0.0000, Train_Loss:0.0339, total_loss:tensor([0.0339], device='cuda:0'), ce_loss:0.57135409116745, cluster_loss:0.07308483123779297, sep_loss:0.06816016882658005, soft_orth_loss:0.001948245451785624, local_consistency_loss:0.0002644602791406214, proto_loss:0.14345772564411163
2026-01-29 15:28:39.438 | INFO     | __main__:main_worker:429 - [81/100], remain:0d.00h.08m, It:[30/54], Max-Mem:11247M, Data-Time:1.894, LR:0.0000, Train_Loss:0.4804, total_loss:tensor([0.4804], device='cuda:0'), ce_loss:0.8200353980064392, cluster_loss:0.10594838857650757, sep_loss:0.07954932749271393, soft_orth_loss:0.0019463782664388418, local_consistency_loss:0.0003139165055472404, proto_loss:0.18775801360607147
2026-01-29 15:28:44.618 | INFO     | __main__:main_worker:429 - [81/100], remain:0d.00h.08m, It:[40/54], Max-Mem:11247M, Data-Time:1.747, LR:0.0000, Train_Loss:1.8733, total_loss:tensor([1.8733], device='cuda:0'), ce_loss:1.6565355062484741, cluster_loss:0.18954715132713318, sep_loss:0.09165062010288239, soft_orth_loss:0.0019448359962552786, local_consistency_loss:0.0006033828831277788, proto_loss:0.28374600410461426
2026-01-29 15:28:48.191 | INFO     | __main__:main_worker:429 - [81/100], remain:0d.00h.07m, It:[50/54], Max-Mem:11247M, Data-Time:0.166, LR:0.0000, Train_Loss:0.2933, total_loss:tensor([0.2933], device='cuda:0'), ce_loss:0.7083826065063477, cluster_loss:0.09664254635572433, sep_loss:0.07559511065483093, soft_orth_loss:0.0019430486718192697, local_consistency_loss:0.0002816567139234394, proto_loss:0.17446237802505493
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
2026-01-29 15:28:57.658 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [81/100], Top1:87.607, Top3:100.000, Test_precision:0.7911,Test_recall:0.8420,Test_f1:0.8119,,Test_specificity:0.9396 Test_loss:0.408577
2026-01-29 15:28:57.659 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:28:57.659 | INFO     | __main__:main_worker:355 - ---> start train epoch82
acc1: 87.6068, acc3: 100.0000, Precision: 0.7911, Recall: 0.8420, F1-Score: 0.8119, Specificity: 0.9396
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:29:07.840 | INFO     | __main__:main_worker:429 - [82/100], remain:0d.00h.09m, It:[10/54], Max-Mem:11247M, Data-Time:1.589, LR:0.0000, Train_Loss:2.0060, total_loss:tensor([2.0060], device='cuda:0'), ce_loss:1.7104116678237915, cluster_loss:0.21746869385242462, sep_loss:0.0908631682395935, soft_orth_loss:0.0019405351486057043, local_consistency_loss:0.0006124164210632443, proto_loss:0.3108848035335541
2026-01-29 15:29:13.060 | INFO     | __main__:main_worker:429 - [82/100], remain:0d.00h.08m, It:[20/54], Max-Mem:11247M, Data-Time:1.232, LR:0.0000, Train_Loss:-0.0647, total_loss:tensor([-0.0647], device='cuda:0'), ce_loss:0.4960719645023346, cluster_loss:0.08818642050027847, sep_loss:0.057661913335323334, soft_orth_loss:0.0019386402564123273, local_consistency_loss:0.00019020395120605826, proto_loss:0.14797717332839966
2026-01-29 15:29:17.479 | INFO     | __main__:main_worker:429 - [82/100], remain:0d.00h.08m, It:[30/54], Max-Mem:11247M, Data-Time:0.993, LR:0.0000, Train_Loss:-0.0210, total_loss:tensor([-0.0210], device='cuda:0'), ce_loss:0.6340013742446899, cluster_loss:0.0001784886117093265, sep_loss:0.07089421153068542, soft_orth_loss:0.0019367452478036284, local_consistency_loss:0.00038408214459195733, proto_loss:0.07339353114366531
2026-01-29 15:29:21.618 | INFO     | __main__:main_worker:429 - [82/100], remain:0d.00h.07m, It:[40/54], Max-Mem:11247M, Data-Time:0.768, LR:0.0000, Train_Loss:0.0766, total_loss:tensor([0.0766], device='cuda:0'), ce_loss:0.5855302810668945, cluster_loss:0.08351986855268478, sep_loss:0.06866496801376343, soft_orth_loss:0.0019346193876117468, local_consistency_loss:0.0004283167072571814, proto_loss:0.154547780752182
2026-01-29 15:29:26.228 | INFO     | __main__:main_worker:429 - [82/100], remain:0d.00h.07m, It:[50/54], Max-Mem:11247M, Data-Time:1.195, LR:0.0000, Train_Loss:0.2908, total_loss:tensor([0.2908], device='cuda:0'), ce_loss:0.6800859570503235, cluster_loss:0.11607847362756729, sep_loss:0.07484334707260132, soft_orth_loss:0.0019328686175867915, local_consistency_loss:0.0001946676493389532, proto_loss:0.193049356341362
Evaluating: 100%|| 15/15 [00:08<00:00,  1.79it/s]
2026-01-29 15:29:35.918 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [82/100], Top1:88.034, Top3:100.000, Test_precision:0.8119,Test_recall:0.8267,Test_f1:0.8173,,Test_specificity:0.9346 Test_loss:0.376777
acc1: 88.0342, acc3: 100.0000, Precision: 0.8119, Recall: 0.8267, F1-Score: 0.8173, Specificity: 0.9346
2026-01-29 15:29:35.919 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:29:35.920 | INFO     | __main__:main_worker:355 - ---> start train epoch83
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:29:45.090 | INFO     | __main__:main_worker:429 - [83/100], remain:0d.00h.08m, It:[10/54], Max-Mem:11247M, Data-Time:0.883, LR:0.0000, Train_Loss:0.6718, total_loss:tensor([0.6718], device='cuda:0'), ce_loss:0.957590639591217, cluster_loss:0.10548414289951324, sep_loss:0.07763108611106873, soft_orth_loss:0.001931261271238327, local_consistency_loss:0.000388741580536589, proto_loss:0.1854352355003357
2026-01-29 15:29:49.292 | INFO     | __main__:main_worker:429 - [83/100], remain:0d.00h.07m, It:[20/54], Max-Mem:11247M, Data-Time:0.652, LR:0.0000, Train_Loss:-0.1658, total_loss:tensor([-0.1658], device='cuda:0'), ce_loss:0.4614632725715637, cluster_loss:0.06550122797489166, sep_loss:0.05540779232978821, soft_orth_loss:0.0019303088774904609, local_consistency_loss:0.00019034613796975464, proto_loss:0.1230296790599823
2026-01-29 15:29:53.395 | INFO     | __main__:main_worker:429 - [83/100], remain:0d.00h.06m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.2531, total_loss:tensor([0.2531], device='cuda:0'), ce_loss:0.8195165991783142, cluster_loss:0.00020369677804410458, sep_loss:0.07534462958574295, soft_orth_loss:0.0019288914045318961, local_consistency_loss:0.00042962684528902173, proto_loss:0.07790684700012207
2026-01-29 15:29:58.969 | INFO     | __main__:main_worker:429 - [83/100], remain:0d.00h.07m, It:[40/54], Max-Mem:11247M, Data-Time:0.017, LR:0.0000, Train_Loss:1.1400, total_loss:tensor([1.1400], device='cuda:0'), ce_loss:1.1917932033538818, cluster_loss:0.15793387591838837, sep_loss:0.09000431001186371, soft_orth_loss:0.0019277059473097324, local_consistency_loss:0.0004937605117447674, proto_loss:0.2503596544265747
2026-01-29 15:30:03.611 | INFO     | __main__:main_worker:429 - [83/100], remain:0d.00h.07m, It:[50/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:1.0187, total_loss:tensor([1.0187], device='cuda:0'), ce_loss:1.104805588722229, cluster_loss:0.16506041586399078, sep_loss:0.08439212292432785, soft_orth_loss:0.0019267033785581589, local_consistency_loss:0.0004676531534641981, proto_loss:0.25184687972068787
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 15:30:14.012 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [83/100], Top1:87.393, Top3:100.000, Test_precision:0.7802,Test_recall:0.8293,Test_f1:0.8010,,Test_specificity:0.9355 Test_loss:0.392576
2026-01-29 15:30:14.024 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
acc1: 87.3932, acc3: 100.0000, Precision: 0.7802, Recall: 0.8293, F1-Score: 0.8010, Specificity: 0.9355
2026-01-29 15:30:14.025 | INFO     | __main__:main_worker:355 - ---> start train epoch84
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:30:25.224 | INFO     | __main__:main_worker:429 - [84/100], remain:0d.00h.08m, It:[10/54], Max-Mem:11247M, Data-Time:1.327, LR:0.0000, Train_Loss:0.1185, total_loss:tensor([0.1185], device='cuda:0'), ce_loss:0.6066079139709473, cluster_loss:0.09194301813840866, sep_loss:0.06640370935201645, soft_orth_loss:0.0019253920763731003, local_consistency_loss:0.00021373304480221123, proto_loss:0.16048584878444672
2026-01-29 15:30:30.170 | INFO     | __main__:main_worker:429 - [84/100], remain:0d.00h.07m, It:[20/54], Max-Mem:11247M, Data-Time:1.489, LR:0.0000, Train_Loss:0.2167, total_loss:tensor([0.2167], device='cuda:0'), ce_loss:0.6591840386390686, cluster_loss:0.10556496679782867, sep_loss:0.06376616656780243, soft_orth_loss:0.001924391952343285, local_consistency_loss:0.00041147094452753663, proto_loss:0.17166699469089508
2026-01-29 15:30:33.727 | INFO     | __main__:main_worker:429 - [84/100], remain:0d.00h.06m, It:[30/54], Max-Mem:11247M, Data-Time:0.130, LR:0.0000, Train_Loss:0.7455, total_loss:tensor([0.7455], device='cuda:0'), ce_loss:0.9754804968833923, cluster_loss:0.1211443766951561, sep_loss:0.08560268580913544, soft_orth_loss:0.0019233820494264364, local_consistency_loss:0.00027240393683314323, proto_loss:0.20894284546375275
2026-01-29 15:30:39.595 | INFO     | __main__:main_worker:429 - [84/100], remain:0d.00h.07m, It:[40/54], Max-Mem:11247M, Data-Time:2.451, LR:0.0000, Train_Loss:-0.0819, total_loss:tensor([-0.0819], device='cuda:0'), ce_loss:0.5155543088912964, cluster_loss:0.06511690467596054, sep_loss:0.05907702445983887, soft_orth_loss:0.001921904506161809, local_consistency_loss:0.0002665619249455631, proto_loss:0.12638239562511444
2026-01-29 15:30:43.556 | INFO     | __main__:main_worker:429 - [84/100], remain:0d.00h.06m, It:[50/54], Max-Mem:11247M, Data-Time:0.553, LR:0.0000, Train_Loss:1.0609, total_loss:tensor([1.0609], device='cuda:0'), ce_loss:1.1759415864944458, cluster_loss:0.13393719494342804, sep_loss:0.08686928451061249, soft_orth_loss:0.0019206629367545247, local_consistency_loss:0.0002775849716272205, proto_loss:0.22300472855567932
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 87.3932, acc3: 100.0000, Precision: 0.7811, Recall: 0.8307, F1-Score: 0.8017, Specificity: 0.9381
2026-01-29 15:30:53.068 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [84/100], Top1:87.393, Top3:100.000, Test_precision:0.7811,Test_recall:0.8307,Test_f1:0.8017,,Test_specificity:0.9381 Test_loss:0.389697
2026-01-29 15:30:53.071 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:30:53.071 | INFO     | __main__:main_worker:355 - ---> start train epoch85
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:31:03.240 | INFO     | __main__:main_worker:429 - [85/100], remain:0d.00h.06m, It:[10/54], Max-Mem:11247M, Data-Time:1.335, LR:0.0000, Train_Loss:1.7689, total_loss:tensor([1.7689], device='cuda:0'), ce_loss:1.5816326141357422, cluster_loss:0.19301119446754456, sep_loss:0.08944082260131836, soft_orth_loss:0.0019192525651305914, local_consistency_loss:0.0008864206611178815, proto_loss:0.2852576673030853
2026-01-29 15:31:06.757 | INFO     | __main__:main_worker:429 - [85/100], remain:0d.00h.05m, It:[20/54], Max-Mem:11247M, Data-Time:0.019, LR:0.0000, Train_Loss:0.2395, total_loss:tensor([0.2395], device='cuda:0'), ce_loss:0.6738590598106384, cluster_loss:0.10404203087091446, sep_loss:0.06649579107761383, soft_orth_loss:0.0019182316027581692, local_consistency_loss:0.00022221766994334757, proto_loss:0.17267827689647675
2026-01-29 15:31:11.458 | INFO     | __main__:main_worker:429 - [85/100], remain:0d.00h.05m, It:[30/54], Max-Mem:11247M, Data-Time:0.224, LR:0.0000, Train_Loss:0.4262, total_loss:tensor([0.4262], device='cuda:0'), ce_loss:0.7673273682594299, cluster_loss:0.13253983855247498, sep_loss:0.0637541115283966, soft_orth_loss:0.0019170442828908563, local_consistency_loss:0.00025157417985610664, proto_loss:0.198462575674057
2026-01-29 15:31:15.526 | INFO     | __main__:main_worker:429 - [85/100], remain:0d.00h.05m, It:[40/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:2.0286, total_loss:tensor([2.0286], device='cuda:0'), ce_loss:1.6981476545333862, cluster_loss:0.24477382004261017, sep_loss:0.0829697847366333, soft_orth_loss:0.0019156273920089006, local_consistency_loss:0.0008536901441402733, proto_loss:0.3305129110813141
2026-01-29 15:31:19.066 | INFO     | __main__:main_worker:429 - [85/100], remain:0d.00h.05m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.1671, total_loss:tensor([-0.1671], device='cuda:0'), ce_loss:0.4624089300632477, cluster_loss:0.06425245851278305, sep_loss:0.055496882647275925, soft_orth_loss:0.0019139921059831977, local_consistency_loss:0.00036538575659506023, proto_loss:0.12202871590852737
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 15:31:29.872 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [85/100], Top1:87.393, Top3:100.000, Test_precision:0.7913,Test_recall:0.8191,Test_f1:0.8037,,Test_specificity:0.9316 Test_loss:0.383121
acc1: 87.3932, acc3: 100.0000, Precision: 0.7913, Recall: 0.8191, F1-Score: 0.8037, Specificity: 0.9316
2026-01-29 15:31:29.874 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:31:44.658 | INFO     | __main__:main_worker:355 - ---> start train epoch86
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:31:52.797 | INFO     | __main__:main_worker:429 - [86/100], remain:0d.00h.06m, It:[10/54], Max-Mem:11247M, Data-Time:0.504, LR:0.0000, Train_Loss:0.2948, total_loss:tensor([0.2948], device='cuda:0'), ce_loss:0.7268568873405457, cluster_loss:0.08279769867658615, sep_loss:0.07764389365911484, soft_orth_loss:0.0019123097881674767, local_consistency_loss:0.00043709922465495765, proto_loss:0.16279099881649017
2026-01-29 15:31:57.775 | INFO     | __main__:main_worker:429 - [86/100], remain:0d.00h.06m, It:[20/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0000, Train_Loss:-0.0391, total_loss:tensor([-0.0391], device='cuda:0'), ce_loss:0.6275902986526489, cluster_loss:0.00018206539971288294, sep_loss:0.06717199087142944, soft_orth_loss:0.001911065191961825, local_consistency_loss:0.0002993483212776482, proto_loss:0.06956446915864944
2026-01-29 15:32:03.024 | INFO     | __main__:main_worker:429 - [86/100], remain:0d.00h.06m, It:[30/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:0.4022, total_loss:tensor([0.4022], device='cuda:0'), ce_loss:0.7751150727272034, cluster_loss:0.11259055137634277, sep_loss:0.06668519973754883, soft_orth_loss:0.0019099959172308445, local_consistency_loss:0.00031013504485599697, proto_loss:0.18149589002132416
2026-01-29 15:32:07.564 | INFO     | __main__:main_worker:429 - [86/100], remain:0d.00h.06m, It:[40/54], Max-Mem:11247M, Data-Time:0.022, LR:0.0000, Train_Loss:-0.1821, total_loss:tensor([-0.1821], device='cuda:0'), ce_loss:0.4233784079551697, cluster_loss:0.08079058676958084, sep_loss:0.05860083922743797, soft_orth_loss:0.0019089732086285949, local_consistency_loss:0.0006162401405163109, proto_loss:0.14191663265228271
2026-01-29 15:32:12.336 | INFO     | __main__:main_worker:429 - [86/100], remain:0d.00h.06m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.2690, total_loss:tensor([0.2690], device='cuda:0'), ce_loss:0.8294062614440918, cluster_loss:0.00023547327145934105, sep_loss:0.07639137655496597, soft_orth_loss:0.0019080910133197904, local_consistency_loss:0.0006116773001849651, proto_loss:0.0791466236114502
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 87.8205, acc3: 100.0000, Precision: 0.7927, Recall: 0.8390, F1-Score: 0.8124, Specificity: 0.9387
2026-01-29 15:32:22.438 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [86/100], Top1:87.821, Top3:100.000, Test_precision:0.7927,Test_recall:0.8390,Test_f1:0.8124,,Test_specificity:0.9387 Test_loss:0.378055
2026-01-29 15:32:22.439 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:32:22.440 | INFO     | __main__:main_worker:355 - ---> start train epoch87
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:32:30.830 | INFO     | __main__:main_worker:429 - [87/100], remain:0d.00h.05m, It:[10/54], Max-Mem:11247M, Data-Time:0.763, LR:0.0000, Train_Loss:0.5432, total_loss:tensor([0.5432], device='cuda:0'), ce_loss:0.8585841655731201, cluster_loss:0.12549827992916107, sep_loss:0.06408753991127014, soft_orth_loss:0.001906860969029367, local_consistency_loss:0.0005465775029733777, proto_loss:0.19203925132751465
2026-01-29 15:32:35.584 | INFO     | __main__:main_worker:429 - [87/100], remain:0d.00h.05m, It:[20/54], Max-Mem:11247M, Data-Time:1.270, LR:0.0000, Train_Loss:-0.2393, total_loss:tensor([-0.2393], device='cuda:0'), ce_loss:0.41232216358184814, cluster_loss:0.06751066446304321, sep_loss:0.05230936035513878, soft_orth_loss:0.0019058416364714503, local_consistency_loss:0.00016123060777317733, proto_loss:0.12188710272312164
2026-01-29 15:32:39.686 | INFO     | __main__:main_worker:429 - [87/100], remain:0d.00h.05m, It:[30/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:2.1132, total_loss:tensor([2.1132], device='cuda:0'), ce_loss:1.7951284646987915, cluster_loss:0.2102820873260498, sep_loss:0.09166227281093597, soft_orth_loss:0.001904790406115353, local_consistency_loss:0.00045306398533284664, proto_loss:0.3043022155761719
2026-01-29 15:32:44.878 | INFO     | __main__:main_worker:429 - [87/100], remain:0d.00h.05m, It:[40/54], Max-Mem:11247M, Data-Time:0.021, LR:0.0000, Train_Loss:2.1396, total_loss:tensor([2.1396], device='cuda:0'), ce_loss:1.822642207145691, cluster_loss:0.20210771262645721, sep_loss:0.09357329457998276, soft_orth_loss:0.0019037391757592559, local_consistency_loss:0.0004975950578227639, proto_loss:0.2980823516845703
2026-01-29 15:32:49.906 | INFO     | __main__:main_worker:429 - [87/100], remain:0d.00h.05m, It:[50/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0000, Train_Loss:0.7538, total_loss:tensor([0.7538], device='cuda:0'), ce_loss:0.9823554754257202, cluster_loss:0.1249823197722435, sep_loss:0.08129975199699402, soft_orth_loss:0.0019027970265597105, local_consistency_loss:0.0002886798174586147, proto_loss:0.2084735631942749
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
2026-01-29 15:32:59.825 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [87/100], Top1:88.248, Top3:100.000, Test_precision:0.7993,Test_recall:0.8399,Test_f1:0.8170,,Test_specificity:0.9396 Test_loss:0.394229
2026-01-29 15:32:59.827 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:32:59.828 | INFO     | __main__:main_worker:355 - ---> start train epoch88
acc1: 88.2479, acc3: 100.0000, Precision: 0.7993, Recall: 0.8399, F1-Score: 0.8170, Specificity: 0.9396
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:33:09.566 | INFO     | __main__:main_worker:429 - [88/100], remain:0d.00h.05m, It:[10/54], Max-Mem:11247M, Data-Time:1.080, LR:0.0000, Train_Loss:0.6817, total_loss:tensor([0.6817], device='cuda:0'), ce_loss:0.9463685750961304, cluster_loss:0.1198110356926918, sep_loss:0.07649962604045868, soft_orth_loss:0.0019018666353076696, local_consistency_loss:0.00024122395552694798, proto_loss:0.19845375418663025
2026-01-29 15:33:13.242 | INFO     | __main__:main_worker:429 - [88/100], remain:0d.00h.04m, It:[20/54], Max-Mem:11247M, Data-Time:0.217, LR:0.0000, Train_Loss:-0.0230, total_loss:tensor([-0.0230], device='cuda:0'), ce_loss:0.5300830602645874, cluster_loss:0.08513914793729782, sep_loss:0.057850342243909836, soft_orth_loss:0.001901225303299725, local_consistency_loss:0.00033462487044744194, proto_loss:0.14522533118724823
2026-01-29 15:33:17.343 | INFO     | __main__:main_worker:429 - [88/100], remain:0d.00h.04m, It:[30/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:-0.1402, total_loss:tensor([-0.1402], device='cuda:0'), ce_loss:0.4675126373767853, cluster_loss:0.06469457596540451, sep_loss:0.06504294276237488, soft_orth_loss:0.0019005582435056567, local_consistency_loss:0.0001283561869058758, proto_loss:0.1317664384841919
2026-01-29 15:33:22.094 | INFO     | __main__:main_worker:429 - [88/100], remain:0d.00h.04m, It:[40/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0000, Train_Loss:-0.0165, total_loss:tensor([-0.0165], device='cuda:0'), ce_loss:0.5316540598869324, cluster_loss:0.08174583315849304, sep_loss:0.06337674707174301, soft_orth_loss:0.0018997673178091645, local_consistency_loss:0.0003032579552382231, proto_loss:0.14732560515403748
2026-01-29 15:33:26.311 | INFO     | __main__:main_worker:429 - [88/100], remain:0d.00h.04m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.2848, total_loss:tensor([-0.2848], device='cuda:0'), ce_loss:0.38152632117271423, cluster_loss:0.06944864988327026, sep_loss:0.049612902104854584, soft_orth_loss:0.0018991503166034818, local_consistency_loss:0.00028899009339511395, proto_loss:0.12124969810247421
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 88.2479, acc3: 100.0000, Precision: 0.7975, Recall: 0.8338, F1-Score: 0.8135, Specificity: 0.9386
2026-01-29 15:33:36.886 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [88/100], Top1:88.248, Top3:100.000, Test_precision:0.7975,Test_recall:0.8338,Test_f1:0.8135,,Test_specificity:0.9386 Test_loss:0.385401
2026-01-29 15:33:36.887 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:33:36.888 | INFO     | __main__:main_worker:355 - ---> start train epoch89
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:33:46.690 | INFO     | __main__:main_worker:429 - [89/100], remain:0d.00h.06m, It:[10/54], Max-Mem:11247M, Data-Time:0.016, LR:0.0000, Train_Loss:0.6633, total_loss:tensor([0.6633], device='cuda:0'), ce_loss:0.8934930562973022, cluster_loss:0.14530175924301147, sep_loss:0.07860462367534637, soft_orth_loss:0.0018983558984473348, local_consistency_loss:0.0004601182008627802, proto_loss:0.2262648642063141
2026-01-29 15:33:50.629 | INFO     | __main__:main_worker:429 - [89/100], remain:0d.00h.05m, It:[20/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:0.1881, total_loss:tensor([0.1881], device='cuda:0'), ce_loss:0.6365453004837036, cluster_loss:0.10843417793512344, sep_loss:0.06315319985151291, soft_orth_loss:0.0018978300504386425, local_consistency_loss:0.0004118063661735505, proto_loss:0.17389701306819916
2026-01-29 15:33:55.280 | INFO     | __main__:main_worker:429 - [89/100], remain:0d.00h.04m, It:[30/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.1951, total_loss:tensor([0.1951], device='cuda:0'), ce_loss:0.6452102661132812, cluster_loss:0.10975072532892227, sep_loss:0.05922439321875572, soft_orth_loss:0.0018971501849591732, local_consistency_loss:0.00043461492168717086, proto_loss:0.17130689322948456
2026-01-29 15:34:00.032 | INFO     | __main__:main_worker:429 - [89/100], remain:0d.00h.04m, It:[40/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.0171, total_loss:tensor([-0.0171], device='cuda:0'), ce_loss:0.5131229162216187, cluster_loss:0.09786871820688248, sep_loss:0.059910621494054794, soft_orth_loss:0.0018965055933222175, local_consistency_loss:0.0002645378408487886, proto_loss:0.15994037687778473
2026-01-29 15:34:04.462 | INFO     | __main__:main_worker:429 - [89/100], remain:0d.00h.04m, It:[50/54], Max-Mem:11247M, Data-Time:0.022, LR:0.0000, Train_Loss:0.0357, total_loss:tensor([0.0357], device='cuda:0'), ce_loss:0.5593427419662476, cluster_loss:0.08423080295324326, sep_loss:0.06688238680362701, soft_orth_loss:0.001895838649943471, local_consistency_loss:0.0005241766921244562, proto_loss:0.1535332053899765
Evaluating: 100%|| 15/15 [00:08<00:00,  1.84it/s]
acc1: 87.3932, acc3: 100.0000, Precision: 0.7847, Recall: 0.8367, F1-Score: 0.8065, Specificity: 0.9362
2026-01-29 15:34:14.930 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [89/100], Top1:87.393, Top3:100.000, Test_precision:0.7847,Test_recall:0.8367,Test_f1:0.8065,,Test_specificity:0.9362 Test_loss:0.395098
2026-01-29 15:34:14.931 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:34:14.932 | INFO     | __main__:main_worker:355 - ---> start train epoch90
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:34:24.844 | INFO     | __main__:main_worker:429 - [90/100], remain:0d.00h.04m, It:[10/54], Max-Mem:11247M, Data-Time:1.550, LR:0.0000, Train_Loss:0.0207, total_loss:tensor([0.0207], device='cuda:0'), ce_loss:0.663029670715332, cluster_loss:0.00017982213466893882, sep_loss:0.07201164960861206, soft_orth_loss:0.0018950637895613909, local_consistency_loss:0.00022630997409578413, proto_loss:0.07431284338235855
2026-01-29 15:34:29.626 | INFO     | __main__:main_worker:429 - [90/100], remain:0d.00h.04m, It:[20/54], Max-Mem:11247M, Data-Time:1.414, LR:0.0000, Train_Loss:-0.2839, total_loss:tensor([-0.2839], device='cuda:0'), ce_loss:0.3929598033428192, cluster_loss:0.05803424119949341, sep_loss:0.05333178490400314, soft_orth_loss:0.0018944231560453773, local_consistency_loss:0.0006164209335111082, proto_loss:0.11387687176465988
2026-01-29 15:34:33.707 | INFO     | __main__:main_worker:429 - [90/100], remain:0d.00h.04m, It:[30/54], Max-Mem:11247M, Data-Time:0.675, LR:0.0000, Train_Loss:-0.1998, total_loss:tensor([-0.1998], device='cuda:0'), ce_loss:0.43431541323661804, cluster_loss:0.07204947620630264, sep_loss:0.051604002714157104, soft_orth_loss:0.0018938040593639016, local_consistency_loss:0.0004605725989677012, proto_loss:0.12600786983966827
2026-01-29 15:34:39.441 | INFO     | __main__:main_worker:429 - [90/100], remain:0d.00h.04m, It:[40/54], Max-Mem:11247M, Data-Time:2.335, LR:0.0000, Train_Loss:-0.1028, total_loss:tensor([-0.1028], device='cuda:0'), ce_loss:0.4647146165370941, cluster_loss:0.09340151399374008, sep_loss:0.05653657764196396, soft_orth_loss:0.0018931698286905885, local_consistency_loss:0.00015278004866559058, proto_loss:0.15198403596878052
2026-01-29 15:34:43.403 | INFO     | __main__:main_worker:429 - [90/100], remain:0d.00h.04m, It:[50/54], Max-Mem:11247M, Data-Time:0.514, LR:0.0000, Train_Loss:0.0140, total_loss:tensor([0.0140], device='cuda:0'), ce_loss:0.5558013319969177, cluster_loss:0.08088573813438416, sep_loss:0.0624660849571228, soft_orth_loss:0.0018925975309684873, local_consistency_loss:0.0002673020353540778, proto_loss:0.1455117166042328
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
acc1: 88.2479, acc3: 100.0000, Precision: 0.8024, Recall: 0.8426, F1-Score: 0.8197, Specificity: 0.9403
2026-01-29 15:34:52.944 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [90/100], Top1:88.248, Top3:100.000, Test_precision:0.8024,Test_recall:0.8426,Test_f1:0.8197,,Test_specificity:0.9403 Test_loss:0.385901
2026-01-29 15:34:52.945 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:35:02.965 | INFO     | __main__:main_worker:355 - ---> start train epoch91
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:35:12.329 | INFO     | __main__:main_worker:429 - [91/100], remain:0d.00h.03m, It:[10/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0000, Train_Loss:0.3379, total_loss:tensor([0.3379], device='cuda:0'), ce_loss:0.7201248407363892, cluster_loss:0.11866939067840576, sep_loss:0.06765179336071014, soft_orth_loss:0.0018917082343250513, local_consistency_loss:0.00048811547458171844, proto_loss:0.18870100378990173
2026-01-29 15:35:17.310 | INFO     | __main__:main_worker:429 - [91/100], remain:0d.00h.04m, It:[20/54], Max-Mem:11247M, Data-Time:0.886, LR:0.0000, Train_Loss:0.0904, total_loss:tensor([0.0904], device='cuda:0'), ce_loss:0.5784549713134766, cluster_loss:0.09939543157815933, sep_loss:0.06526502221822739, soft_orth_loss:0.0018911194056272507, local_consistency_loss:0.0003370880731381476, proto_loss:0.16688866913318634
2026-01-29 15:35:21.976 | INFO     | __main__:main_worker:429 - [91/100], remain:0d.00h.03m, It:[30/54], Max-Mem:11247M, Data-Time:1.149, LR:0.0000, Train_Loss:0.0981, total_loss:tensor([0.0981], device='cuda:0'), ce_loss:0.5891621112823486, cluster_loss:0.09510856121778488, sep_loss:0.06566713005304337, soft_orth_loss:0.0018907123012468219, local_consistency_loss:0.0004986986168660223, proto_loss:0.1631651073694229
2026-01-29 15:35:25.707 | INFO     | __main__:main_worker:429 - [91/100], remain:0d.00h.03m, It:[40/54], Max-Mem:11247M, Data-Time:0.021, LR:0.0000, Train_Loss:0.3828, total_loss:tensor([0.3828], device='cuda:0'), ce_loss:0.7577694654464722, cluster_loss:0.10967297852039337, sep_loss:0.07184009253978729, soft_orth_loss:0.0018903031013906002, local_consistency_loss:0.0009912020759657025, proto_loss:0.18439456820487976
2026-01-29 15:35:30.247 | INFO     | __main__:main_worker:429 - [91/100], remain:0d.00h.03m, It:[50/54], Max-Mem:11247M, Data-Time:0.301, LR:0.0000, Train_Loss:0.4552, total_loss:tensor([0.4552], device='cuda:0'), ce_loss:0.793185293674469, cluster_loss:0.11766817420721054, sep_loss:0.07442827522754669, soft_orth_loss:0.001889862702228129, local_consistency_loss:0.0009480500011704862, proto_loss:0.19493436813354492
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 15:35:41.077 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [91/100], Top1:88.034, Top3:100.000, Test_precision:0.7957,Test_recall:0.8253,Test_f1:0.8086,,Test_specificity:0.9374 Test_loss:0.377232
2026-01-29 15:35:41.079 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:35:41.079 | INFO     | __main__:main_worker:355 - ---> start train epoch92
acc1: 88.0342, acc3: 100.0000, Precision: 0.7957, Recall: 0.8253, F1-Score: 0.8086, Specificity: 0.9374
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:35:51.012 | INFO     | __main__:main_worker:429 - [92/100], remain:0d.00h.04m, It:[10/54], Max-Mem:11247M, Data-Time:1.800, LR:0.0000, Train_Loss:-0.0025, total_loss:tensor([-0.0025], device='cuda:0'), ce_loss:0.5563215017318726, cluster_loss:0.07482080906629562, sep_loss:0.06014005467295647, soft_orth_loss:0.0018891713116317987, local_consistency_loss:0.00032972925691865385, proto_loss:0.13717976212501526
2026-01-29 15:35:55.050 | INFO     | __main__:main_worker:429 - [92/100], remain:0d.00h.03m, It:[20/54], Max-Mem:11247M, Data-Time:0.627, LR:0.0000, Train_Loss:1.4323, total_loss:tensor([1.4323], device='cuda:0'), ce_loss:1.382240653038025, cluster_loss:0.1689273864030838, sep_loss:0.08803354948759079, soft_orth_loss:0.0018887595506384969, local_consistency_loss:0.0016063436632975936, proto_loss:0.26045602560043335
2026-01-29 15:35:58.988 | INFO     | __main__:main_worker:429 - [92/100], remain:0d.00h.03m, It:[30/54], Max-Mem:11247M, Data-Time:0.289, LR:0.0000, Train_Loss:1.3673, total_loss:tensor([1.3673], device='cuda:0'), ce_loss:1.3657116889953613, cluster_loss:0.15830977261066437, sep_loss:0.07988600432872772, soft_orth_loss:0.0018883835291489959, local_consistency_loss:0.0002892316842917353, proto_loss:0.2403733879327774
2026-01-29 15:36:03.880 | INFO     | __main__:main_worker:429 - [92/100], remain:0d.00h.03m, It:[40/54], Max-Mem:11247M, Data-Time:0.465, LR:0.0000, Train_Loss:-0.1411, total_loss:tensor([-0.1411], device='cuda:0'), ce_loss:0.457684725522995, cluster_loss:0.0773649662733078, sep_loss:0.05876743793487549, soft_orth_loss:0.0018879832932725549, local_consistency_loss:0.0003277938812971115, proto_loss:0.13834817707538605
2026-01-29 15:36:08.563 | INFO     | __main__:main_worker:429 - [92/100], remain:0d.00h.03m, It:[50/54], Max-Mem:11247M, Data-Time:0.055, LR:0.0000, Train_Loss:1.5233, total_loss:tensor([1.5233], device='cuda:0'), ce_loss:1.4021109342575073, cluster_loss:0.19709937274456024, sep_loss:0.09141760319471359, soft_orth_loss:0.0018876068061217666, local_consistency_loss:0.00043575229938142, proto_loss:0.2908403277397156
Evaluating: 100%|| 15/15 [00:08<00:00,  1.82it/s]
2026-01-29 15:36:18.400 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [92/100], Top1:87.393, Top3:100.000, Test_precision:0.7836,Test_recall:0.8293,Test_f1:0.8029,,Test_specificity:0.9369 Test_loss:0.383331
acc1: 87.3932, acc3: 100.0000, Precision: 0.7836, Recall: 0.8293, F1-Score: 0.8029, Specificity: 0.9369
2026-01-29 15:36:18.401 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:36:18.401 | INFO     | __main__:main_worker:355 - ---> start train epoch93
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:36:28.257 | INFO     | __main__:main_worker:429 - [93/100], remain:0d.00h.03m, It:[10/54], Max-Mem:11247M, Data-Time:1.492, LR:0.0000, Train_Loss:0.0791, total_loss:tensor([0.0791], device='cuda:0'), ce_loss:0.5973262786865234, cluster_loss:0.08714716881513596, sep_loss:0.05905386805534363, soft_orth_loss:0.001887045451439917, local_consistency_loss:0.00029623115551657975, proto_loss:0.14838431775569916
2026-01-29 15:36:32.617 | INFO     | __main__:main_worker:429 - [93/100], remain:0d.00h.03m, It:[20/54], Max-Mem:11247M, Data-Time:0.910, LR:0.0000, Train_Loss:0.0835, total_loss:tensor([0.0835], device='cuda:0'), ce_loss:0.5885255336761475, cluster_loss:0.09023730456829071, sep_loss:0.06405460089445114, soft_orth_loss:0.0018866994651034474, local_consistency_loss:0.00043081477633677423, proto_loss:0.1566094011068344
2026-01-29 15:36:37.323 | INFO     | __main__:main_worker:429 - [93/100], remain:0d.00h.03m, It:[30/54], Max-Mem:11247M, Data-Time:1.293, LR:0.0000, Train_Loss:-0.3200, total_loss:tensor([-0.3200], device='cuda:0'), ce_loss:0.34729132056236267, cluster_loss:0.07312598079442978, sep_loss:0.05300404876470566, soft_orth_loss:0.0018862276338040829, local_consistency_loss:0.00016281129501294345, proto_loss:0.12817907333374023
2026-01-29 15:36:42.617 | INFO     | __main__:main_worker:429 - [93/100], remain:0d.00h.03m, It:[40/54], Max-Mem:11247M, Data-Time:1.825, LR:0.0000, Train_Loss:0.8704, total_loss:tensor([0.8704], device='cuda:0'), ce_loss:1.0543110370635986, cluster_loss:0.13541018962860107, sep_loss:0.07755570113658905, soft_orth_loss:0.0018858963157981634, local_consistency_loss:0.0004614470526576042, proto_loss:0.21531322598457336
2026-01-29 15:36:46.264 | INFO     | __main__:main_worker:429 - [93/100], remain:0d.00h.02m, It:[50/54], Max-Mem:11247M, Data-Time:0.196, LR:0.0000, Train_Loss:0.0617, total_loss:tensor([0.0617], device='cuda:0'), ce_loss:0.5656454563140869, cluster_loss:0.09570156782865524, sep_loss:0.06401985883712769, soft_orth_loss:0.001885534729808569, local_consistency_loss:0.0002876730577554554, proto_loss:0.16189463436603546
Evaluating: 100%|| 15/15 [00:08<00:00,  1.77it/s]
acc1: 86.9658, acc3: 100.0000, Precision: 0.7782, Recall: 0.8271, F1-Score: 0.7986, Specificity: 0.9342
2026-01-29 15:36:56.132 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [93/100], Top1:86.966, Top3:100.000, Test_precision:0.7782,Test_recall:0.8271,Test_f1:0.7986,,Test_specificity:0.9342 Test_loss:0.388275
2026-01-29 15:36:56.133 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:36:56.134 | INFO     | __main__:main_worker:355 - ---> start train epoch94
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:37:04.359 | INFO     | __main__:main_worker:429 - [94/100], remain:0d.00h.02m, It:[10/54], Max-Mem:11247M, Data-Time:0.159, LR:0.0000, Train_Loss:0.6654, total_loss:tensor([0.6654], device='cuda:0'), ce_loss:0.9193229079246521, cluster_loss:0.1347787231206894, sep_loss:0.0724145695567131, soft_orth_loss:0.0018850258784368634, local_consistency_loss:0.00044007133692502975, proto_loss:0.20951838791370392
2026-01-29 15:37:08.015 | INFO     | __main__:main_worker:429 - [94/100], remain:0d.00h.02m, It:[20/54], Max-Mem:11247M, Data-Time:0.273, LR:0.0000, Train_Loss:2.3539, total_loss:tensor([2.3539], device='cuda:0'), ce_loss:1.8812214136123657, cluster_loss:0.2628645598888397, sep_loss:0.09612926095724106, soft_orth_loss:0.0018846493912860751, local_consistency_loss:0.0006463502068072557, proto_loss:0.3615248203277588
2026-01-29 15:37:12.820 | INFO     | __main__:main_worker:429 - [94/100], remain:0d.00h.02m, It:[30/54], Max-Mem:11247M, Data-Time:0.737, LR:0.0000, Train_Loss:0.2483, total_loss:tensor([0.2483], device='cuda:0'), ce_loss:0.6665564775466919, cluster_loss:0.10415514558553696, sep_loss:0.07593453675508499, soft_orth_loss:0.0018842457793653011, local_consistency_loss:0.0005122674629092216, proto_loss:0.18248620629310608
2026-01-29 15:37:17.805 | INFO     | __main__:main_worker:429 - [94/100], remain:0d.00h.02m, It:[40/54], Max-Mem:11247M, Data-Time:1.068, LR:0.0000, Train_Loss:-0.0045, total_loss:tensor([-0.0045], device='cuda:0'), ce_loss:0.5440520644187927, cluster_loss:0.07524175941944122, sep_loss:0.06740666180849075, soft_orth_loss:0.0018839065451174974, local_consistency_loss:0.00024434944498352706, proto_loss:0.14477668702602386
2026-01-29 15:37:23.266 | INFO     | __main__:main_worker:429 - [94/100], remain:0d.00h.02m, It:[50/54], Max-Mem:11247M, Data-Time:1.781, LR:0.0000, Train_Loss:-0.0470, total_loss:tensor([-0.0470], device='cuda:0'), ce_loss:0.5179533958435059, cluster_loss:0.07923796027898788, sep_loss:0.060223065316677094, soft_orth_loss:0.0018836276140064, local_consistency_loss:0.0009496069396845996, proto_loss:0.1422942578792572
Evaluating: 100%|| 15/15 [00:08<00:00,  1.83it/s]
acc1: 87.3932, acc3: 100.0000, Precision: 0.7844, Recall: 0.8279, F1-Score: 0.8031, Specificity: 0.9351
2026-01-29 15:37:32.857 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [94/100], Top1:87.393, Top3:100.000, Test_precision:0.7844,Test_recall:0.8279,Test_f1:0.8031,,Test_specificity:0.9351 Test_loss:0.390647
2026-01-29 15:37:32.858 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:37:32.859 | INFO     | __main__:main_worker:355 - ---> start train epoch95
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:37:41.371 | INFO     | __main__:main_worker:429 - [95/100], remain:0d.00h.02m, It:[10/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.3050, total_loss:tensor([0.3050], device='cuda:0'), ce_loss:0.7094723582267761, cluster_loss:0.10598617047071457, sep_loss:0.07190635800361633, soft_orth_loss:0.001883284654468298, local_consistency_loss:0.00045443433918990195, proto_loss:0.1802302598953247
2026-01-29 15:37:46.182 | INFO     | __main__:main_worker:429 - [95/100], remain:0d.00h.02m, It:[20/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.0315, total_loss:tensor([-0.0315], device='cuda:0'), ce_loss:0.5265383720397949, cluster_loss:0.07633393257856369, sep_loss:0.06540586054325104, soft_orth_loss:0.0018830116605386138, local_consistency_loss:0.0002310973359271884, proto_loss:0.14385390281677246
2026-01-29 15:37:50.923 | INFO     | __main__:main_worker:429 - [95/100], remain:0d.00h.02m, It:[30/54], Max-Mem:11247M, Data-Time:0.235, LR:0.0000, Train_Loss:-0.0705, total_loss:tensor([-0.0705], device='cuda:0'), ce_loss:0.5077641010284424, cluster_loss:0.07469112426042557, sep_loss:0.061055950820446014, soft_orth_loss:0.0018827591557055712, local_consistency_loss:0.00032131592161022127, proto_loss:0.13795115053653717
2026-01-29 15:37:56.323 | INFO     | __main__:main_worker:429 - [95/100], remain:0d.00h.02m, It:[40/54], Max-Mem:11247M, Data-Time:1.936, LR:0.0000, Train_Loss:-0.0400, total_loss:tensor([-0.0400], device='cuda:0'), ce_loss:0.6242433190345764, cluster_loss:0.0001858596078818664, sep_loss:0.06964193284511566, soft_orth_loss:0.001882537268102169, local_consistency_loss:0.00026270869420841336, proto_loss:0.0719730406999588
2026-01-29 15:38:01.025 | INFO     | __main__:main_worker:429 - [95/100], remain:0d.00h.02m, It:[50/54], Max-Mem:11247M, Data-Time:1.283, LR:0.0000, Train_Loss:0.0693, total_loss:tensor([0.0693], device='cuda:0'), ce_loss:0.5903378129005432, cluster_loss:0.08316605538129807, sep_loss:0.06319576501846313, soft_orth_loss:0.0018823490245267749, local_consistency_loss:0.00028797396225854754, proto_loss:0.14853215217590332
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 15:38:10.513 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [95/100], Top1:87.393, Top3:100.000, Test_precision:0.7818,Test_recall:0.8219,Test_f1:0.7991,,Test_specificity:0.9351 Test_loss:0.388550
acc1: 87.3932, acc3: 100.0000, Precision: 0.7818, Recall: 0.8219, F1-Score: 0.7991, Specificity: 0.9351
2026-01-29 15:38:10.515 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:38:20.974 | INFO     | __main__:main_worker:355 - ---> start train epoch96
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:38:29.965 | INFO     | __main__:main_worker:429 - [96/100], remain:0d.00h.01m, It:[10/54], Max-Mem:11247M, Data-Time:0.651, LR:0.0000, Train_Loss:-0.0225, total_loss:tensor([-0.0225], device='cuda:0'), ce_loss:0.5320447087287903, cluster_loss:0.07097681611776352, sep_loss:0.07131176441907883, soft_orth_loss:0.0018820071127265692, local_consistency_loss:0.00023816763132344931, proto_loss:0.14440874755382538
2026-01-29 15:38:33.843 | INFO     | __main__:main_worker:429 - [96/100], remain:0d.00h.01m, It:[20/54], Max-Mem:11247M, Data-Time:0.114, LR:0.0000, Train_Loss:-0.2467, total_loss:tensor([-0.2467], device='cuda:0'), ce_loss:0.3979855477809906, cluster_loss:0.0707048773765564, sep_loss:0.05571529269218445, soft_orth_loss:0.0018818204989656806, local_consistency_loss:0.0003000299329869449, proto_loss:0.1286020278930664
2026-01-29 15:38:38.989 | INFO     | __main__:main_worker:429 - [96/100], remain:0d.00h.01m, It:[30/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.1230, total_loss:tensor([0.1230], device='cuda:0'), ce_loss:0.6053392887115479, cluster_loss:0.09529539942741394, sep_loss:0.06671828031539917, soft_orth_loss:0.0018816277151927352, local_consistency_loss:0.00029310662648640573, proto_loss:0.164188414812088
2026-01-29 15:38:43.400 | INFO     | __main__:main_worker:429 - [96/100], remain:0d.00h.01m, It:[40/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:0.1559, total_loss:tensor([0.1559], device='cuda:0'), ce_loss:0.6359506845474243, cluster_loss:0.08963026106357574, sep_loss:0.06691935658454895, soft_orth_loss:0.0018814317882061005, local_consistency_loss:0.0004586503782775253, proto_loss:0.15888971090316772
2026-01-29 15:38:48.297 | INFO     | __main__:main_worker:429 - [96/100], remain:0d.00h.01m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.1227, total_loss:tensor([-0.1227], device='cuda:0'), ce_loss:0.4663461148738861, cluster_loss:0.0774381086230278, sep_loss:0.06170666217803955, soft_orth_loss:0.0018812516937032342, local_consistency_loss:0.0003603122604545206, proto_loss:0.14138634502887726
Evaluating: 100%|| 15/15 [00:08<00:00,  1.85it/s]
2026-01-29 15:38:58.462 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [96/100], Top1:87.393, Top3:100.000, Test_precision:0.7842,Test_recall:0.8293,Test_f1:0.8034,,Test_specificity:0.9360 Test_loss:0.390425
acc1: 87.3932, acc3: 100.0000, Precision: 0.7842, Recall: 0.8293, F1-Score: 0.8034, Specificity: 0.9360
2026-01-29 15:38:58.462 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:38:58.463 | INFO     | __main__:main_worker:355 - ---> start train epoch97
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:39:07.618 | INFO     | __main__:main_worker:429 - [97/100], remain:0d.00h.01m, It:[10/54], Max-Mem:11247M, Data-Time:1.157, LR:0.0000, Train_Loss:1.1579, total_loss:tensor([1.1579], device='cuda:0'), ce_loss:1.230504035949707, cluster_loss:0.14573192596435547, sep_loss:0.08456511795520782, soft_orth_loss:0.0018810223555192351, local_consistency_loss:0.00047454089508391917, proto_loss:0.23265260457992554
2026-01-29 15:39:11.507 | INFO     | __main__:main_worker:429 - [97/100], remain:0d.00h.01m, It:[20/54], Max-Mem:11247M, Data-Time:0.353, LR:0.0000, Train_Loss:0.5722, total_loss:tensor([0.5722], device='cuda:0'), ce_loss:0.8369994163513184, cluster_loss:0.14129126071929932, sep_loss:0.07800811529159546, soft_orth_loss:0.0018808543682098389, local_consistency_loss:0.00023230347142089158, proto_loss:0.2214125394821167
2026-01-29 15:39:16.180 | INFO     | __main__:main_worker:429 - [97/100], remain:0d.00h.01m, It:[30/54], Max-Mem:11247M, Data-Time:0.042, LR:0.0000, Train_Loss:0.2214, total_loss:tensor([0.2214], device='cuda:0'), ce_loss:0.674208402633667, cluster_loss:0.08201300352811813, sep_loss:0.0798705518245697, soft_orth_loss:0.00188070023432374, local_consistency_loss:0.0003704607079271227, proto_loss:0.16413472592830658
2026-01-29 15:39:20.583 | INFO     | __main__:main_worker:429 - [97/100], remain:0d.00h.01m, It:[40/54], Max-Mem:11247M, Data-Time:0.853, LR:0.0000, Train_Loss:-0.1847, total_loss:tensor([-0.1847], device='cuda:0'), ce_loss:0.44670629501342773, cluster_loss:0.062440287321805954, sep_loss:0.06032021343708038, soft_orth_loss:0.0018805655417963862, local_consistency_loss:0.00028144472162239254, proto_loss:0.12492251396179199
2026-01-29 15:39:24.593 | INFO     | __main__:main_worker:429 - [97/100], remain:0d.00h.01m, It:[50/54], Max-Mem:11247M, Data-Time:0.288, LR:0.0000, Train_Loss:2.4457, total_loss:tensor([2.4457], device='cuda:0'), ce_loss:1.8792643547058105, cluster_loss:0.3142528235912323, sep_loss:0.09037809818983078, soft_orth_loss:0.0018804369028657675, local_consistency_loss:0.0009555347496643662, proto_loss:0.4074668884277344
Evaluating: 100%|| 15/15 [00:08<00:00,  1.82it/s]
acc1: 87.6068, acc3: 100.0000, Precision: 0.7865, Recall: 0.8379, F1-Score: 0.8082, Specificity: 0.9372
2026-01-29 15:39:35.194 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [97/100], Top1:87.607, Top3:100.000, Test_precision:0.7865,Test_recall:0.8379,Test_f1:0.8082,,Test_specificity:0.9372 Test_loss:0.397932
2026-01-29 15:39:35.196 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:39:35.197 | INFO     | __main__:main_worker:355 - ---> start train epoch98
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:39:43.529 | INFO     | __main__:main_worker:429 - [98/100], remain:0d.00h.01m, It:[10/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.9378, total_loss:tensor([0.9378], device='cuda:0'), ce_loss:1.0989856719970703, cluster_loss:0.1320440024137497, sep_loss:0.08281900733709335, soft_orth_loss:0.001880221301689744, local_consistency_loss:0.0003806968161370605, proto_loss:0.21712392568588257
2026-01-29 15:39:48.340 | INFO     | __main__:main_worker:429 - [98/100], remain:0d.00h.01m, It:[20/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0000, Train_Loss:2.2101, total_loss:tensor([2.2101], device='cuda:0'), ce_loss:1.8230125904083252, cluster_loss:0.2397543489933014, sep_loss:0.0901573896408081, soft_orth_loss:0.0018800817197188735, local_consistency_loss:0.00036768015706911683, proto_loss:0.33215948939323425
2026-01-29 15:39:53.114 | INFO     | __main__:main_worker:429 - [98/100], remain:0d.00h.01m, It:[30/54], Max-Mem:11247M, Data-Time:0.014, LR:0.0000, Train_Loss:0.2137, total_loss:tensor([0.2137], device='cuda:0'), ce_loss:0.6646340489387512, cluster_loss:0.09304165840148926, sep_loss:0.07191435992717743, soft_orth_loss:0.001879944815300405, local_consistency_loss:0.00025422676117159426, proto_loss:0.16709019243717194
2026-01-29 15:39:57.361 | INFO     | __main__:main_worker:429 - [98/100], remain:0d.00h.00m, It:[40/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:0.1088, total_loss:tensor([0.1088], device='cuda:0'), ce_loss:0.5926917195320129, cluster_loss:0.09999348968267441, sep_loss:0.06392812728881836, soft_orth_loss:0.001879826420918107, local_consistency_loss:0.00029793428257107735, proto_loss:0.16609938442707062
2026-01-29 15:40:01.990 | INFO     | __main__:main_worker:429 - [98/100], remain:0d.00h.00m, It:[50/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:2.4809, total_loss:tensor([2.4809], device='cuda:0'), ce_loss:1.9517930746078491, cluster_loss:0.2786385715007782, sep_loss:0.09345473349094391, soft_orth_loss:0.0018797144293785095, local_consistency_loss:0.0002467915473971516, proto_loss:0.3742198348045349
Evaluating: 100%|| 15/15 [00:08<00:00,  1.78it/s]
acc1: 88.0342, acc3: 100.0000, Precision: 0.7955, Recall: 0.8415, F1-Score: 0.8152, Specificity: 0.9388
2026-01-29 15:40:12.266 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [98/100], Top1:88.034, Top3:100.000, Test_precision:0.7955,Test_recall:0.8415,Test_f1:0.8152,,Test_specificity:0.9388 Test_loss:0.391078
2026-01-29 15:40:12.267 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:40:12.267 | INFO     | __main__:main_worker:355 - ---> start train epoch99
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:40:21.692 | INFO     | __main__:main_worker:429 - [99/100], remain:0d.00h.00m, It:[10/54], Max-Mem:11247M, Data-Time:1.051, LR:0.0000, Train_Loss:-0.0594, total_loss:tensor([-0.0594], device='cuda:0'), ce_loss:0.49573975801467896, cluster_loss:0.0895000472664833, sep_loss:0.05991826206445694, soft_orth_loss:0.0018795373616740108, local_consistency_loss:0.0004091633891221136, proto_loss:0.1517070084810257
2026-01-29 15:40:25.357 | INFO     | __main__:main_worker:429 - [99/100], remain:0d.00h.00m, It:[20/54], Max-Mem:11247M, Data-Time:0.013, LR:0.0000, Train_Loss:0.0606, total_loss:tensor([0.0606], device='cuda:0'), ce_loss:0.5740883350372314, cluster_loss:0.08168462663888931, sep_loss:0.07167016714811325, soft_orth_loss:0.0018794207135215402, local_consistency_loss:0.0003879627329297364, proto_loss:0.1556221842765808
2026-01-29 15:40:29.545 | INFO     | __main__:main_worker:429 - [99/100], remain:0d.00h.00m, It:[30/54], Max-Mem:11247M, Data-Time:0.009, LR:0.0000, Train_Loss:0.2677, total_loss:tensor([0.2677], device='cuda:0'), ce_loss:0.6879339814186096, cluster_loss:0.10387058556079865, sep_loss:0.07106159627437592, soft_orth_loss:0.0018793254857882857, local_consistency_loss:0.00030395257635973394, proto_loss:0.17711545526981354
2026-01-29 15:40:34.395 | INFO     | __main__:main_worker:429 - [99/100], remain:0d.00h.00m, It:[40/54], Max-Mem:11247M, Data-Time:0.435, LR:0.0000, Train_Loss:0.6726, total_loss:tensor([0.6726], device='cuda:0'), ce_loss:0.9438658356666565, cluster_loss:0.11033760756254196, sep_loss:0.08362376689910889, soft_orth_loss:0.0018792370101436973, local_consistency_loss:0.00020277360454201698, proto_loss:0.19604338705539703
2026-01-29 15:40:38.348 | INFO     | __main__:main_worker:429 - [99/100], remain:0d.00h.00m, It:[50/54], Max-Mem:11247M, Data-Time:0.012, LR:0.0000, Train_Loss:-0.0857, total_loss:tensor([-0.0857], device='cuda:0'), ce_loss:0.4842013418674469, cluster_loss:0.08071160316467285, sep_loss:0.06411415338516235, soft_orth_loss:0.0018791460897773504, local_consistency_loss:0.00025584499235264957, proto_loss:0.14696073532104492
Evaluating: 100%|| 15/15 [00:08<00:00,  1.81it/s]
2026-01-29 15:40:48.674 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [99/100], Top1:87.393, Top3:100.000, Test_precision:0.7818,Test_recall:0.8293,Test_f1:0.8019,,Test_specificity:0.9362 Test_loss:0.390057
2026-01-29 15:40:48.675 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
2026-01-29 15:40:48.676 | INFO     | __main__:main_worker:355 - ---> start train epoch100
acc1: 87.3932, acc3: 100.0000, Precision: 0.7818, Recall: 0.8293, F1-Score: 0.8019, Specificity: 0.9362
/home/backup/lh/KD/mae_lite/exps/timm_imagenet_exp.py:216: UserWarning: Mixup is enabled with multi-prototype head. This may cause training instability. Consider disabling Mixup (mixup=0, cutmix=0) for prototype-based models.
  warnings.warn(
2026-01-29 15:40:57.160 | INFO     | __main__:main_worker:429 - [100/100], remain:0d.00h.00m, It:[10/54], Max-Mem:11247M, Data-Time:0.011, LR:0.0000, Train_Loss:-0.1106, total_loss:tensor([-0.1106], device='cuda:0'), ce_loss:0.4639001190662384, cluster_loss:0.09188689291477203, sep_loss:0.054731689393520355, soft_orth_loss:0.0018790117464959621, local_consistency_loss:0.00047475090832449496, proto_loss:0.14897233247756958
2026-01-29 15:41:01.267 | INFO     | __main__:main_worker:429 - [100/100], remain:0d.00h.00m, It:[20/54], Max-Mem:11247M, Data-Time:0.015, LR:0.0000, Train_Loss:-0.0535, total_loss:tensor([-0.0535], device='cuda:0'), ce_loss:0.5125053524971008, cluster_loss:0.07320594787597656, sep_loss:0.06760715693235397, soft_orth_loss:0.0018789407331496477, local_consistency_loss:0.0002795314940158278, proto_loss:0.14297159016132355
2026-01-29 15:41:05.340 | INFO     | __main__:main_worker:429 - [100/100], remain:0d.00h.00m, It:[30/54], Max-Mem:11247M, Data-Time:0.010, LR:0.0000, Train_Loss:-0.0622, total_loss:tensor([-0.0622], device='cuda:0'), ce_loss:0.5041877031326294, cluster_loss:0.08207172900438309, sep_loss:0.06040105223655701, soft_orth_loss:0.0018788576126098633, local_consistency_loss:0.0001789143861969933, proto_loss:0.1445305496454239
2026-01-29 15:41:10.146 | INFO     | __main__:main_worker:429 - [100/100], remain:0d.00h.00m, It:[40/54], Max-Mem:11247M, Data-Time:0.770, LR:0.0000, Train_Loss:-0.1792, total_loss:tensor([-0.1792], device='cuda:0'), ce_loss:0.4571605622768402, cluster_loss:0.06577878445386887, sep_loss:0.05235445499420166, soft_orth_loss:0.0018787899753078818, local_consistency_loss:0.00036489186459220946, proto_loss:0.12037692219018936
2026-01-29 15:41:15.498 | INFO     | __main__:main_worker:429 - [100/100], remain:0d.00h.00m, It:[50/54], Max-Mem:11247M, Data-Time:0.947, LR:0.0000, Train_Loss:0.2221, total_loss:tensor([0.2221], device='cuda:0'), ce_loss:0.8102418184280396, cluster_loss:0.0002271284320158884, sep_loss:0.06789262592792511, soft_orth_loss:0.001878745504654944, local_consistency_loss:0.00022579518554266542, proto_loss:0.07022430002689362
Evaluating: 100%|| 15/15 [00:08<00:00,  1.87it/s]
2026-01-29 15:41:25.434 | INFO     | __main__:main_worker:496 - 	Eval-Epoch: [100/100], Top1:86.966, Top3:100.000, Test_precision:0.7781,Test_recall:0.8285,Test_f1:0.7989,,Test_specificity:0.9352 Test_loss:0.397116
2026-01-29 15:41:25.436 | INFO     | __main__:main_worker:507 - 	Best Top1 at epoch [39/100], Top1:88.462, Top-3:100.000
acc1: 86.9658, acc3: 100.0000, Precision: 0.7781, Recall: 0.8285, F1-Score: 0.7989, Specificity: 0.9352
2026-01-29 15:41:35.049 | INFO     | __main__:main_worker:547 - Training of experiment: HiFuse_Small_1e-5-0.05/ft_progressive_v4_1eval is done.
2026-01-29 15:41:35.076 | INFO     | __main__:main_worker:549 - 	Best Top1 at epoch [39/100], Top1:88.462, Top3:100.000
/home/backup/lh/KD/mae_lite/tools/train.py:554: DeprecationWarning: The 'stop()' method is deprecated, please use 'remove()' instead
  logger.stop()

Process finished with exit code 0
