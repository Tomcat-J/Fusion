# 最优多原型分类头使用指南

## 一、概述

`head_optimal.py` 是针对你的 CNN+Transformer 融合模型设计的最优多原型分类头，修复了原 `head.py` 中的多个理论和工程问题。

### 核心修复

| 问题 | head.py | head_optimal.py |
|------|---------|-----------------|
| Contrastive Loss | ❌ 推开所有原型（与 Diversity Loss 冲突） | ✅ 只推开异类原型 |
| 门控融合 | ⚠️ 只融合 local_out 和 proto | ✅ 三路 softmax 门控 |
| 动量更新 | ⚠️ 非标准 cache/count 平均 | ✅ 标准 EMA |
| 长尾支持 | ⚠️ 简单 sqrt 加权 | ✅ 可选 Class-Balanced |

---

## 二、与你的模型集成

### 2.1 模型架构回顾

你的 `main_model` 是 ConvNeXt + Swin Transformer 融合模型：
- 特征维度: `conv_dims = [96, 192, 384, 768]`
- 最终输出: 768 维特征
- Head 输入: `(pool_img_features, img_features, labels)`

### 2.2 方式一：直接替换（推荐）

在 `models_mae.py` 中修改 `main_model.__init__`:

```python
# 原始代码
from projects.mae_lite.head import Head
self.head = Head(self.num_classes, conv_dims[-1], num_heads[2], conv_dims[-1])

# 替换为
from projects.mae_lite.head_optimal import HeadOptimal
self.head = HeadOptimal(
    num_classes=self.num_classes,
    emb_dim=conv_dims[-1],           # 768
    num_heads=num_heads[2],          # 12
    img_feat_dim=conv_dims[-1],      # 768
    num_prototypes=5,
    max_prototypes=10,
    use_class_balanced=True,         # 长尾数据建议启用
    cb_beta=0.9999,
)
```

### 2.3 方式二：使用工厂函数

```python
from projects.mae_lite.head_optimal import create_optimal_head_for_main_model

self.head = create_optimal_head_for_main_model(
    num_classes=self.num_classes,
    conv_dims=conv_dims,
    num_heads=num_heads[2],
    use_class_balanced=True,
)
```

### 2.4 方式三：保持兼容接口

如果你不想修改训练代码，可以使用兼容接口：

```python
from projects.mae_lite.head_optimal import Head  # 兼容原有接口

self.head = Head(
    num_classes=self.num_classes,
    emb_dim=conv_dims[-1],
    num_heads=num_heads[2],
    img_feat_dim=conv_dims[-1],
    num_prototypes=5,
)
```

---

## 三、与 Baseline 模型兼容

### 3.1 问题背景

你需要同时运行：
- **main_model**: CNN+Transformer 融合模型，使用多原型分类头
- **Baseline 模型**: CNN, ViT, ConvNeXt 等，使用标准线性分类头

### 3.2 解决方案

`timm_imagenet_exp.py` 中的 `Model` 类已更新，自动检测模型类型：

```python
class Model(nn.Module):
    def __init__(self, args, model):
        # ... 初始化代码 ...
        
        # 自动检测模型类型
        self._use_multi_prototype_head = self._detect_multi_prototype_head()
    
    def _detect_multi_prototype_head(self) -> bool:
        """检测内部模型是否使用多原型分类头"""
        if hasattr(self.model, 'head'):
            head = self.model.head
            if hasattr(head, 'proto_manager'):
                return True
        return False
    
    def forward(self, x, target=None, epoch=None, update_param=False):
        if self.training:
            if self._use_multi_prototype_head:
                # 多原型头: 使用 head 内置损失
                loss, extra_dict = self.model(x, target=target_orig)
            else:
                # 标准线性头: 使用 train_loss_fn
                logits = self.model(x)
                loss = self.train_loss_fn(logits, target)
            # ...
```

### 3.3 使用方式

无需修改训练代码，`Model` 类会自动处理：

```python
# main_model (多原型头) - 自动使用 head 内置损失
model = main_model(num_classes=7)

# Baseline (标准线性头) - 自动使用 train_loss_fn
model = create_model('resnet50', num_classes=7)
model = create_model('vit_base_patch16_224', num_classes=7)
model = create_model('convnext_tiny', num_classes=7)
```

---

## 四、损失函数配置

### 4.1 推荐权重

```python
HeadOptimal(
    clst_scale=0.8,        # 聚类损失（拉近同类）
    sep_scale=0.08,        # 分离损失（推远异类样本）
    div_scale=0.01,        # 多样性损失（同类原型多样化）
    contrastive_scale=0.05, # 对比损失（异类原型分离）
    margin=0.3,            # 分离损失的 margin
    temperature=10.0,      # 温度参数
)
```

### 4.2 长尾数据配置

你的皮肤病数据是长尾分布，建议启用 Class-Balanced 加权：

```python
HeadOptimal(
    use_class_balanced=True,
    cb_beta=0.9999,  # 越接近 1，对尾部类的加权越强
)
```

| β 值 | 效果 |
|------|------|
| 0.9 | 温和平衡 |
| 0.99 | 中等平衡 |
| 0.999 | 较强平衡 |
| 0.9999 | 强平衡（推荐用于严重长尾） |

---

## 五、返回格式说明

### 5.1 HeadOptimal 返回格式

```python
# 训练时: (logits, total_loss, loss_dict)
logits, total_loss, loss_dict = head(pool_features, img_features, labels)
# loss_dict 包含: ce_loss, cluster_loss, sep_loss, div_loss, contrastive_loss, proto_loss, total_loss

# 推理时: (logits, 0.0, {})
logits, _, _ = head(pool_features, img_features)
```

### 5.2 兼容接口 Head 返回格式

```python
# 训练时: (logits, loss) - 与原 head.py 一致
logits, loss = head(pool_features, img_features, labels)

# 推理时: (logits, 0.0)
logits, _ = head(pool_features, img_features)
```

### 5.3 main_model 返回格式

`main_model.forward` 已更新，自动处理两种 head 返回格式：

```python
# 训练时: (loss, extra_dict)
loss, extra_dict = model(images, target=labels)
# extra_dict 包含详细的损失分解:
# - total_loss: 总损失
# - ce_loss: 交叉熵损失
# - cluster_loss: 聚类损失
# - sep_loss: 分离损失
# - div_loss: 多样性损失
# - contrastive_loss: 对比损失
# - proto_loss: 原型损失总和

# 推理时: (logits, head_loss)
logits, _ = model(images)
```

---

## 六、完整示例

```python
import torch
from projects.mae_lite.models_mae import main_model
from projects.mae_lite.head_optimal import HeadOptimal

# 创建模型
model = main_model(num_classes=7)

# 替换 head 为最优版本
model.head = HeadOptimal(
    num_classes=7,
    emb_dim=768,
    num_heads=12,
    img_feat_dim=768,
    num_prototypes=5,
    max_prototypes=10,
    use_class_balanced=True,
)

# 训练
model.train()
images = torch.randn(16, 3, 224, 224)
labels = torch.randint(0, 7, (16,))

loss, extra_dict = model(images, labels)
loss.backward()

# 推理
model.eval()
with torch.no_grad():
    logits, _ = model(images)
    predictions = logits.argmax(dim=-1)
```

---

## 七、常见问题

### Q1: 为什么移除了 Abstention Loss？

Abstention Loss 用于不确定性估计，但你的任务不需要这个功能。移除后：
- 代码更简洁
- 减少超参数
- 训练更稳定

如果将来需要不确定性估计，可以参考 ProtoASNet 论文重新添加。

### Q2: Baseline 模型如何使用 CB_loss？

`timm_imagenet_exp.py` 中已有 `CB_loss` 函数，但目前 `Model.forward` 使用的是 `train_loss_fn`。

如果你想让 Baseline 模型也使用 CB_loss，可以修改 `Model.__init__`:

```python
# 在 __init__ 中
if args.use_cb_loss:  # 添加一个配置项
    self.train_loss_fn = lambda logits, target: CB_loss(
        target, logits, 
        samples_per_cls=[...],  # 你的类别样本数
        no_of_classes=args.num_classes,
        loss_type="focal",
        beta=0.9999,
        gamma=0.5
    )
```

### Q3: 如何选择原型数量？

| 数据特点 | 推荐原型数 |
|----------|-----------|
| 类内变化小 | 3-5 |
| 类内变化中等 | 5-8 |
| 类内变化大 | 8-10 |

你的皮肤病数据类内变化较大，建议 5-8 个原型。

---

## 八、文件说明

| 文件 | 说明 |
|------|------|
| `head.py` | 原始实现，保留作为备份 |
| `head_optimal.py` | **最优版本，推荐使用** |
| `timm_imagenet_exp.py` | 训练脚本，已更新支持多原型头和标准头 |

---

## 九、API 参考

### HeadOptimal

```python
HeadOptimal(
    num_classes: int,           # 类别数
    emb_dim: int,               # 嵌入维度
    num_heads: int,             # 注意力头数
    img_feat_dim: int,          # 输入特征维度
    num_prototypes: int = 5,    # 每类初始原型数
    max_prototypes: int = 10,   # 每类最大原型数
    dropout_rate: float = 0.1,
    momentum: float = 0.9,      # EMA 动量
    margin: float = 0.3,        # 分离损失 margin
    temperature: float = 10.0,  # 温度参数
    clst_scale: float = 0.8,    # 聚类损失权重
    sep_scale: float = 0.08,    # 分离损失权重
    div_scale: float = 0.01,    # 多样性损失权重
    contrastive_scale: float = 0.05,  # 对比损失权重
    use_class_balanced: bool = False,  # 是否使用 CB 加权
    cb_beta: float = 0.9999,    # CB 加权的 beta
)
```

### 工厂函数

```python
# 通用工厂函数
create_optimal_head(
    num_classes: int,
    emb_dim: int,
    num_heads: int = 8,
    num_prototypes: int = 5,
    use_class_balanced: bool = False,
    **kwargs
) -> HeadOptimal

# main_model 专用工厂函数
create_optimal_head_for_main_model(
    num_classes: int,
    conv_dims: List[int] = None,  # 如 [96, 192, 384, 768]
    emb_dim: int = 768,
    num_heads: int = 12,
    num_prototypes: int = 5,
    use_class_balanced: bool = False,
    **kwargs
) -> HeadOptimal
```

### 辅助函数

```python
# 检测模型是否使用多原型头
has_multi_prototype_head(model: nn.Module) -> bool
```
